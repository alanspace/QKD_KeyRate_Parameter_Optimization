{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch with Metal Performance Shaders (MPS) is a better choice than JAX for GPU-accelerated training. Here’s why:\n",
    "\t1.\tNative Support for Apple Silicon GPUs:\n",
    "PyTorch’s MPS backend directly uses the GPU on M2 Pro, making it faster than CPU-bound JAX on macOS.\n",
    "\t2.\tSimpler Workflow:\n",
    "With PyTorch, models can be trained and deployed without needing conversions (e.g., JAX -> TensorFlow -> Core ML).\n",
    "\t3.\tVersatile Ecosystem:\n",
    "PyTorch is widely used, well-documented, and supports almost all ML tasks, including your neural network for QKD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F  # Add this import at the top\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# Get the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Add parent directory to path\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " checking if the MPS (Metal Performance Shaders) backend is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    raise RuntimeError(\"MPS device not available. Check if PyTorch and macOS set up correctly.\")\n",
    "\n",
    "# Set the device to MPS\n",
    "device = torch.device(\"mps\")  # Use GPU on M2 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daai6ga1hou2/anaconda3/envs/qkd-training_set/lib/python3.9/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from QKD_Functions.QKD_Functions import (\n",
    "    calculate_factorial,\n",
    "    calculate_tau_n,\n",
    "    calculate_eta_ch,\n",
    "    calculate_eta_sys,\n",
    "    calculate_D_mu_k,\n",
    "    calculate_n_X_total,\n",
    "    calculate_N,\n",
    "    calculate_n_Z_total,\n",
    "    calculate_e_mu_k,\n",
    "    calculate_e_obs,\n",
    "    calculate_h,\n",
    "    calculate_lambda_EC,\n",
    "    calculate_sqrt_term,\n",
    "    calculate_tau_n,\n",
    "    calculate_n_pm, \n",
    "    calculate_S_0,\n",
    "    calculate_S_1,\n",
    "    calculate_m_mu_k,\n",
    "    calculate_m_pm,\n",
    "    calculate_v_1,\n",
    "    calculate_gamma,\n",
    "    calculate_Phi,\n",
    "    calculate_LastTwoTerm,\n",
    "    calculate_l,\n",
    "    calculate_R,\n",
    "    experimental_parameters,\n",
    "    other_parameters,\n",
    "    calculate_key_rates_and_metrics,\n",
    "    penalty, \n",
    "    objective,\n",
    "    objective_with_logging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Preprocessing\n",
    "\n",
    "\t1.\t e_1 = \\frac{L}{100} \n",
    "\t•\t e_1  represents normalized fiber length.\n",
    "\t•\t L  is the fiber length in km, ranging from 0 to 200 km.\n",
    "\t•\t e_1 \\in [0, 2] , as  L \\in [0, 200] .\n",
    "\t2.\t e_2 = -\\log(Y_0) \n",
    "\t•\t e_2  represents the logarithmic scale of the dark count rate  Y_0 .\n",
    "\t•\t Y_0  ranges from  10^{-7}  to  10^{-5} , so:\n",
    "\t•\t -\\log(10^{-7}) = 7 \n",
    "\t•\t -\\log(10^{-5}) = 5 \n",
    "\t•\t e_2 \\in [5, 7] .\n",
    "\t3.\t e_3 = e_d \\times 100 \n",
    "\t•\t e_3  is a scaled misalignment error probability  e_d , converted to a percentage.\n",
    "\t•\t e_d \\in [0.01, 0.03] , so:\n",
    "\t•\t 0.01 \\times 100 = 1 \n",
    "\t•\t 0.03 \\times 100 = 3 \n",
    "\t•\t e_3 \\in [1, 3] .\n",
    "\t4.\t e_4 = \\log(N) \n",
    "\t•\t e_4  is the logarithmic scale of the number of pulses  N .\n",
    "\t•\t N \\in [10^{11}, 10^{14}] , so:\n",
    "\t•\t \\log(10^{11}) = 11 \n",
    "\t•\t \\log(10^{14}) = 14 \n",
    "\t•\t e_4 \\in [11, 14] .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Neural Network Model\n",
    "\n",
    "Output Size Changed to 6: \\\n",
    "The output layer now has 6 neurons, as shown in  r diagram.\n",
    "\n",
    "Two ReLU Activations: \\\n",
    "ReLU activation is applied after both fc1 and fc2, matching the architecture in the diagram.\n",
    "\n",
    "Output Layer is Linear: \\\n",
    "No activation function is applied to the output layer (fc3), which aligns with the diagram indicating a linear output.\n",
    "\n",
    "Dropout Layers: \\\n",
    "Dropout layers are included after each ReLU activation to reduce overfitting. This is consistent with itr original implementation and is a reasonable addition unless the paper specifies otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BB84NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB84NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,128)\n",
    "        self.fc2 = nn.Linear(128,256)\n",
    "        self.fc3 = nn.Linear(256, 512)  # Change 64 -> 32 to match checkpoint\n",
    "        self.fc4 = nn.Linear(512, 1024)  # Change 64 -> 16 to match checkpoint\n",
    "        self.fc5 = nn.Linear(1024, 512)\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)  # Change 32 -> 16 to match checkpoint\n",
    "        self.fc9 = nn.Linear(64, 5)\n",
    "        # self.dropout1 = nn.Dropout(0.1)  # Dropout for the first layer\n",
    "        # self.dropout2 = nn.Dropout(0.2)  # Dropout for subsequent layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "        # # Applying softmax to ensure P_mu1, P_mu2, and P_X sum to 1\n",
    "        # probabilities = F.softmax(x[:, 2:], dim=1)  # Assuming indices 2, 3, and 4 are probabilities\n",
    "        # P_mu_1, P_mu_2, P_X = probabilities[:, 0], probabilities[:, 1], probabilities[:, 2]\n",
    "\n",
    "        # # Applying constraints for mu values to ensure mu_1 > mu_2\n",
    "        # mu_1 = torch.sigmoid(x[:, 0])   # Sigmoid to bound values between 0 and 1\n",
    "        # mu_2 = mu_1 - torch.sigmoid(x[:, 1]) * 0.5  # Ensuring mu_2 is always less than mu_1\n",
    "        # Apply sigmoid to mu values to ensure they are between 0 and 1\n",
    "        # mu_1 = torch.sigmoid(x[:, 0])\n",
    "        # mu_2 = mu_1 - torch.sigmoid(x[:, 1]) * 0.5  # Ensuring mu_2 < mu_1\n",
    "        # mu_3 = mu_1 - torch.sigmoid(x[:, 2]) * 0.5  # Ensuring mu_3 < mu_1 and mu_2 > mu_3 if mu_2 > mu_3 desired\n",
    "\n",
    "        # # Softmax for probability values to ensure they sum to 1 and are non-negative\n",
    "        # probabilities = F.softmax(x[:, 3:6], dim=1)\n",
    "        # P_mu_1, P_mu_2, P_mu_3 = probabilities[:, 0], probabilities[:, 1], probabilities[:, 2]\n",
    "\n",
    "        # Apply scaled sigmoid to ensure mu values are within specified bounds\n",
    "        # mu_1 = 4e-4 + (torch.sigmoid(x[:, 0]) * (0.9 - 4e-4))  # Bounds (4e-4, 0.9)\n",
    "        # mu_2 = 2e-4 + (torch.sigmoid(x[:, 1]) * (0.5 - 2e-4))  # Bounds (2e-4, 0.5)\n",
    "        # mu_2 = torch.minimum(mu_2, mu_1 - 1e-4)  # Ensure mu_1 > mu_2\n",
    "\n",
    "        # # Softmax for probability values to ensure they sum to 1 and are non-negative\n",
    "        # probabilities = F.softmax(x[:, 2:], dim=1)\n",
    "        # P_mu_1, P_mu_2, P_X = probabilities[:, 0], probabilities[:, 1], probabilities[:, 2]\n",
    "\n",
    "        # # Ensure probabilities do not drop below a very small positive value near zero\n",
    "        # epsilon = 1e-2\n",
    "        # P_mu_1 = torch.clamp(P_mu_1, min=epsilon, max=1-epsilon)\n",
    "        # P_mu_2 = torch.clamp(P_mu_2, min=epsilon, max=1-epsilon)\n",
    "        # # P_mu_3 = torch.clamp(P_mu_3, min=epsilon, max=1-epsilon)\n",
    "        # P_X = torch.clamp(P_X, min=epsilon, max=1-epsilon)\n",
    "\n",
    "\n",
    "        # # Ensure the output values stay within the defined bounds\n",
    "        # mu_1 = torch.sigmoid(x[:, 0]) * (1 - 1e-6) + 1e-6\n",
    "        # mu_2 = torch.sigmoid(x[:, 1]) * (1 - 1e-6) + 1e-6\n",
    "        # P_mu_1 = torch.sigmoid(x[:, 2]) * (1 - 1e-6) + 1e-6\n",
    "        # P_mu_2 = torch.sigmoid(x[:, 3]) * (1 - 1e-6) + 1e-6\n",
    "        # P_X = torch.sigmoid(x[:, 4]) * (1 - 1e-6) + 1e-6\n",
    "\n",
    "        # return x\n",
    "        # return torch.stack([mu_1, mu_2, P_mu_1, P_mu_2, P_X], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the Dataset\n",
    "Load and preprocess training_dataset.json\n",
    "\n",
    "\t•\tL: Represents the fiber length. \\\n",
    "\t•\tn_X: Represents the  n_X  value. \\\n",
    "\t•\tkey_rate: Represents the calculated key rate. \\\n",
    "\t•\toptimal_params: A list of 5 optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall dataset contains 1 entries.\n",
      "The number of entries associated with the first key (100000000.0) is: 2000\n",
      "Filtered dataset contains 2000 entries.\n",
      "\n",
      "Sample entry from the cleaned dataset:\n",
      "{\n",
      "  \"fiber_length\": 0.30000000000000004,\n",
      "  \"e_1\": 0.0030000000000000005,\n",
      "  \"e_2\": 6.221848749616356,\n",
      "  \"e_3\": 0.5,\n",
      "  \"e_4\": 8.0,\n",
      "  \"key_rate\": 0.00846304454761513,\n",
      "  \"optimized_params\": {\n",
      "    \"mu_1\": 0.5079434441820826,\n",
      "    \"mu_2\": 0.34308341181263313,\n",
      "    \"P_mu_1\": 0.16873293654289456,\n",
      "    \"P_mu_2\": 0.7711846884270357,\n",
      "    \"P_X_value\": 0.8250152465726756\n",
      "  }\n",
      "}\n",
      "\n",
      "Number of unique n_X values: 1\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "with open('../Training_Data/single_nx/qkd_grouped_dataset_20250213_110036.json', 'r') as f:\n",
    "    data_by_nx = json.load(f)\n",
    "\n",
    "print(f\"The overall dataset contains {len(data_by_nx)} entries.\")\n",
    "\n",
    "# Verify the length of the list associated with the first key\n",
    "first_key = list(data_by_nx.keys())[0]\n",
    "print(f\"The number of entries associated with the first key ({first_key}) is: {len(data_by_nx[first_key])}\")\n",
    "\n",
    "# Flatten the data structure and filter\n",
    "cleaned_data = []\n",
    "for n_x, entries in data_by_nx.items():\n",
    "    cleaned_data.extend([\n",
    "        item for item in entries\n",
    "# if item[\"key_rate\"] > 0 and \n",
    "if item[\"e_1\"] * 100 <= 200  # Only positive key rates and fiber lengths <= 200 km\n",
    "    ])\n",
    "\n",
    "# Optional: Verify the cleaned dataset\n",
    "if not cleaned_data:\n",
    "    print(\"No valid data after filtering.\")\n",
    "else:\n",
    "    print(f\"Filtered dataset contains {len(cleaned_data)} entries.\")\n",
    "    print(\"\\nSample entry from the cleaned dataset:\")\n",
    "    print(json.dumps(cleaned_data[0], indent=2))\n",
    "    print(\"\\nNumber of unique n_X values:\", len(data_by_nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'data' is your loaded JSON object\n",
    "# number_of_entries = len(data_by_nx[\"10000.0\"])\n",
    "# print(\"Number of entries under the key '10000.0':\", number_of_entries)\n",
    "\n",
    "# number_of_entries = len(data_by_nx[\"100000.0\"])\n",
    "# print(\"Number of entries under the key '100000.0':\", number_of_entries)\n",
    "\n",
    "# number_of_entries = len(data_by_nx[\"1000000.0\"])\n",
    "# print(\"Number of entries under the key '1000000.0':\", number_of_entries)\n",
    "\n",
    "# number_of_entries = len(data_by_nx[\"10000000.0\"])\n",
    "# print(\"Number of entries under the key '10000000.0':\", number_of_entries)\n",
    "\n",
    "# number_of_entries = len(data_by_nx[\"100000000.0\"])\n",
    "# print(\"Number of entries under the key '100000000.0':\", number_of_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X (Inputs): Combines L and n_X as two features per data point.\n",
    "Y (Outputs): Directly uses the optimal_params list as the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding scaling for Y_train and Y_val here ensures that the targets are on a similar scale to the features. This is particularly useful in regression problems because it helps the model converge faster and produce better results.\n",
    "\n",
    "If the target values (Y_train, Y_val) are not scaled and have a much larger or smaller range than the feature values, the model might struggle to predict them accurately.\n",
    "\t•\tScaling makes the targets comparable to the model’s intermediate outputs, improving convergence during training.\n",
    "\n",
    "Use fit_transform on the training set (Y_train) to compute the mean and standard deviation.\n",
    "\t•\tUse transform on the validation set (Y_val) to ensure it uses the same scaling parameters as Y_train. This avoids information leakage from the validation set.\n",
    "\n",
    "After scaling, the shapes of Y_train and Y_val remain unchanged but their values will be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for item in cleaned_data:\n",
    "    mu_1, mu_2, P_mu_1, P_mu_2, P_X = item['optimized_params'].values()\n",
    "    # Constraints applied but not stored in Y\n",
    "    # P_mu_3 = max(1 - (P_mu_1 + P_mu_2), 1e-6)\n",
    "    # P_Z = max(1 - P_X, 1e-6)\n",
    "    \n",
    "    # Store only the first five parameters\n",
    "    Y.append([mu_1, mu_2, P_mu_1, P_mu_2, P_X])\n",
    "\n",
    "Y = np.array(Y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1400, 4), Y_train shape: (1400, 5)\n",
      "X_val shape: (600, 4), Y_val shape: (600, 5)\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and targets (Y)\n",
    "X = np.array([[item['e_1'], item['e_2'], item['e_3'], item['e_4']] for item in cleaned_data], dtype=np.float32)\n",
    "Y = np.array([list(item['optimized_params'].values()) for item in cleaned_data ], dtype=np.float32)  # Flatten dictionary\n",
    "\n",
    "# Shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
    "X_val = scaler.transform(X_val)  # Transform validation data using the same scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_scaler = MinMaxScaler()  # Scale targets to [0, 1]\n",
    "Y_train = y_scaler.fit_transform(Y_train)\n",
    "Y_val = y_scaler.transform(Y_val)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Save StandardScaler\n",
    "joblib.dump(y_scaler, 'y_scaler.pkl')  # Save MinMaxScaler\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, Y_val shape: {Y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training the Model\n",
    "\n",
    "Define the training setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32))\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Initialize model\n",
    "model = BB84NN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Adam optimizer\n",
    "\n",
    "# Learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training loop     \n",
    "\n",
    "Training Step: \\\n",
    "The provided code block runs within the for X_batch, Y_batch in train_loader: loop. \\\n",
    "It performs the forward pass, computes the loss, backpropagates, applies gradient clipping, and updates the model weights.\n",
    "\n",
    "Validation Step: \\\n",
    "Runs after the training loop for the epoch. It evaluates the model using the validation dataset (val_loader), without updating weights (torch.no_grad()).\n",
    "\n",
    "Gradient Clipping: \\\n",
    "This line prevents exploding gradients:\n",
    "\n",
    "Learning Rate Adjustment (Optional): \\\n",
    "If you use a scheduler (e.g., ReduceLROnPlateau), adjust the learning rate after each epoch using:\n",
    "\n",
    "This code block is the core of the training step, so include it inside the loop that iterates through train_loader, as shown in the example above. It ensures the model learns from batches of data during each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_check_constraints(model, val_loader, criterion, device, bounds):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    constraint_violations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, Y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Check constraints\n",
    "            for i, bound in enumerate(bounds):\n",
    "                lower, upper = bound\n",
    "                # Check if any predictions are out of the specified bounds\n",
    "                if (predictions[:, i] < lower).any() or (predictions[:, i] > upper).any():\n",
    "                    constraint_violations += 1\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    if constraint_violations == 0:\n",
    "        print(\"All constraints satisfied.\")\n",
    "    else:\n",
    "        print(f\"Constraints violated in {constraint_violations} batches.\")\n",
    "\n",
    "    return avg_loss, constraint_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# from QKD_Functions.QKD_Functions import calculate_key_rates_and_metrics\n",
    "\n",
    "# # Fixed QKD Parameters (create this OUTSIDE the loss function)\n",
    "# qkd_params = (0.2, 0.1, 1e-5, 1e-10, 1e-15, 1.16, 0.01, 1) #alpha, eta_Bob, P_dc_value, epsilon_sec, epsilon_cor, f_EC, e_mis, P_ap\n",
    "# # def custom_loss(predictions, targets, L_values, n_X, alpha, eta_Bob, P_dc_value, epsilon_sec, epsilon_cor, f_EC, e_mis, P_ap, n_event):\n",
    "# # Revisit custom loss for a test\n",
    "# parameter_criterion = nn.MSELoss()\n",
    "# def custom_loss(predictions, targets,  L_values, n_X, n_event):\n",
    "#     \"\"\"\n",
    "#     Custom loss function combining MSE loss on parameters and key rates.\n",
    "#     Fixed parameters and the correct device\n",
    "#     \"\"\"\n",
    "#     global y_scaler\n",
    "#     # parameter_loss = nn.MSELoss()(predictions, targets) # MSE loss on parameters is better\n",
    "\n",
    "#     # Reverse the data to numpy array before calculating\n",
    "#     predicted_params = y_scaler.inverse_transform(predictions.cpu().detach().numpy())\n",
    "#     target_params = y_scaler.inverse_transform(targets.cpu().detach().numpy())\n",
    "\n",
    "#     # Key Rate Calculation for both\n",
    "#     predicted_key_rates, *_ = calculate_key_rates_and_metrics(predicted_params, L_values, n_X,  *qkd_params) # here there are two params value, one for each\n",
    "#     actual_key_rates, *_ = calculate_key_rates_and_metrics(target_params, L_values, n_X,  *qkd_params)\n",
    "\n",
    "#     # Transfer back after calculating key rates\n",
    "#     predicted_key_rates = torch.tensor(predicted_key_rates, dtype=torch.float32, requires_grad = True)\n",
    "#     actual_key_rates = torch.tensor(actual_key_rates, dtype=torch.float32, requires_grad = True)\n",
    "\n",
    "#     # Calculate the loss\n",
    "#     # return key_rate_criterion(predicted_key_rates, actual_key_rates) # key rate with MSE may improve\n",
    "#     parameter_loss = nn.MSELoss()(predictions, targets) # MSE loss on parameters is better\n",
    "#     key_rate_loss = nn.MSELoss()(predicted_key_rates, actual_key_rates)\n",
    "#     # weighted key rate loss\n",
    "#     total_loss = parameter_loss + 0.5*key_rate_loss # weight\n",
    "#     return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 5000\n",
    "best_loss = float('inf')  # Initialize best loss to infinity\n",
    "patience = 20 # Number of epochs to wait before stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stopping_patience = 100  # Early stopping patience\n",
    "\n",
    "# Initialize placeholders for final outputs\n",
    "final_train_loss = None\n",
    "final_val_loss = None\n",
    "\n",
    "# Bounds for predicted parameters (adjust as needed)\n",
    "bounds = [\n",
    "    (4e-4, 0.9),  \n",
    "    (2e-4, 0.5),  \n",
    "    (1e-12, 1.0 - 1e-12),  \n",
    "    (1e-12, 1.0- 1e-12),  \n",
    "    (1e-12, 1.0- 1e-12),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed QKD Parameters (create this OUTSIDE the loss function)\n",
    "qkd_params = (0.2, 0.1, 6e-7, 1e-10, 1e-15, 1.16, 0.01, 1) #alpha, eta_Bob, P_dc_value, epsilon_sec, \n",
    "\n",
    "# Fixed parameters\n",
    "alpha = 0.2\n",
    "eta_Bob = 0.1\n",
    "P_dc_value = 6e-7\n",
    "epsilon_sec = 1e-10\n",
    "epsilon_cor = 1e-15\n",
    "f_EC = 1.16\n",
    "e_mis = 5e-3\n",
    "P_ap = 4e-2\n",
    "n_event = 1\n",
    "\n",
    "parameter_criterion = nn.MSELoss()\n",
    "\n",
    "def compute_loss(predictions, targets, X_batch, n_X):\n",
    "    # Calculate standard loss (e.g., MSE)\n",
    "    # loss = criterion(predictions, targets)\n",
    "    \n",
    "    parameter_loss = nn.MSELoss()(predictions, targets)\n",
    "    # Add penalties for out-of-bounds predictions\n",
    "    # lower_penalties = torch.sum(torch.relu(1e-4 - predictions[:, :2]))  # For mu_1 and mu_2\n",
    "    # upper_penalties = torch.sum(torch.relu(predictions - 1))            # For mu_1 and mu_2\n",
    "    # loss += 0.1 * (lower_penalties + upper_penalties)\n",
    "    \n",
    "    return parameter_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform validation and calculate average loss.\n",
    "    Args:\n",
    "        model (nn.Module): The model to validate.\n",
    "        val_loader (DataLoader): DataLoader for the validation set.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to perform computation.\n",
    "    Returns:\n",
    "        float: Average validation loss.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, Y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)  # Average validation loss\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # %% [markdown]\n",
    "# # Define the KFold cross-validator\n",
    "# num_folds = 5\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# # %% [markdown]\n",
    "# # Load and preprocess the dataset\n",
    "# with open('../Training_Data/qkd_grouped_dataset_20250206_223840.json', 'r') as f:\n",
    "#     data_by_nx = json.load(f)\n",
    "\n",
    "# # Example of filtering and preparing the data\n",
    "# cleaned_data = []\n",
    "# for n_x, entries in data_by_nx.items():\n",
    "#     for item in entries:\n",
    "#         if item[\"key_rate\"] > 0 and item[\"e_1\"] * 100 <= 200:  # Only positive key rates and fiber lengths <= 200 km\n",
    "#             cleaned_data.append(item)\n",
    "\n",
    "# X = np.array([[item['e_1'], item['e_2'], item['e_3'], item['e_4']] for item in cleaned_data], dtype=np.float32)\n",
    "# Y = np.array([list(item['optimized_params'].values()) for item in cleaned_data ], dtype=np.float32)\n",
    "\n",
    "# # Scaling features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Convert to tensors\n",
    "# X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "# Y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "\n",
    "# # %% [markdown]\n",
    "# # Training setup with cross-validation\n",
    "# fold_results = []\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_tensor), start=1):\n",
    "#     X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]\n",
    "#     Y_train, Y_val = Y_tensor[train_idx], Y_tensor[val_idx]\n",
    "\n",
    "#     model = BB84NN().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     for epoch in range(100):  # Set a reasonable number of epochs\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         predictions = model(X_train)\n",
    "#         loss = criterion(predictions, Y_train)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_predictions = model(X_val)\n",
    "#             val_loss = criterion(val_predictions, Y_val)\n",
    "\n",
    "#         print(f\"Fold {fold}, Epoch {epoch}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "#     fold_results.append(val_loss.item())\n",
    "\n",
    "# print(\"Training complete. Fold results:\", fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3845, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3731,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9038, 0.9357, 0.0311, 0.9371, 0.9742], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4329, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9844,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9281, 0.9442, 0.0106, 0.9892, 0.9947], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8407, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0846, 0.6638, 0.5097, 0.3908, 0.7081], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2095,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8934, 0.9537, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6606,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8986, 0.9359, 0.0124, 0.9694, 0.9909], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1645, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.8684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 2/5000 [00:00<33:50,  2.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000, Train Loss: 0.0161, Val Loss: 0.1602\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2572, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0506, 0.6047, 0.5768, 0.3348, 0.6718], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9671,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9327, 0.9435, 0.0110, 0.9888, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3974,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9069, 0.9347, 0.0291, 0.9398, 0.9760], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9359,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9416, 0.9423, 0.0119, 0.9880, 0.9939], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6796,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8958, 0.9359, 0.0117, 0.9704, 0.9915], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5047,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9283, 0.9351, 0.0200, 0.9602, 0.9846], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4675,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9096, 0.9700, 0.0030, 0.9966, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9723, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5931, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0000,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9242, 0.9448, 0.0102, 0.9896, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.4164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9518, 0.9340, 0.0253, 0.9535, 0.9794], device='mps:0')\n",
      "Epoch 2/5000, Train Loss: 0.0096, Val Loss: 0.0914\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4546, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0183, 0.0802, 0.9621, 0.0273, 0.1888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3585, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9312, 0.9784, 0.0020, 0.9977, 0.9992], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 3/5000 [00:01<24:28,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6581, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0649,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3231, 0.8807, 0.2423, 0.6110, 0.8311], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7238,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([1., 1., 0., 1., 1.], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2996, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0476, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2442, 0.8252, 0.3101, 0.5565, 0.8006], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8216,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8810, 0.9365, 0.0068, 0.9763, 0.9950], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.3169, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 3/5000, Train Loss: 0.0051, Val Loss: 0.0493\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6208, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3498,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8944, 0.9615, 0.0043, 0.9952, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2831,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8885, 0.9392, 0.0396, 0.9256, 0.9663], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0493,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3136, 0.8744, 0.2499, 0.6050, 0.8276], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0424,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3093, 0.8715, 0.2534, 0.6022, 0.8260], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3740,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8964, 0.9631, 0.0041, 0.9955, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4745,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 4/5000 [00:01<19:51,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9109, 0.9706, 0.0029, 0.9967, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2658,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8845, 0.9399, 0.0414, 0.9230, 0.9644], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9983, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7766,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8847, 0.9363, 0.0082, 0.9746, 0.9940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.5013, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 4/5000, Train Loss: 0.0011, Val Loss: 0.0099\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3429, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3498,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8944, 0.9615, 0.0043, 0.9952, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0312, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7082,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.9167e-01, 9.9754e-01, 2.0525e-04, 9.9976e-01, 9.9993e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8389,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8798, 0.9366, 0.0063, 0.9769, 0.9953], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1161, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6173,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9055, 0.9357, 0.0143, 0.9671, 0.9894], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.0251, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2619, 0.8385, 0.2937, 0.5698, 0.8079], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 6/5000 [00:01<15:35,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5000, Train Loss: 0.0005, Val Loss: 0.0049\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5177,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9205, 0.9745, 0.0024, 0.9972, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6407,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9604, 0.9880, 0.0010, 0.9988, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4337,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9468, 0.9343, 0.0242, 0.9549, 0.9805], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4926,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9312, 0.9349, 0.0206, 0.9593, 0.9839], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8373, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6078, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5282, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1628,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8969, 0.9516, 0.0069, 0.9927, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2260,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8741, 0.9416, 0.0460, 0.9168, 0.9596], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9325,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9427, 0.9422, 0.0120, 0.9879, 0.9939], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.1671,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8541, 0.9440, 0.0539, 0.9061, 0.9509], device='mps:0')\n",
      "Epoch 6/5000, Train Loss: 0.0003, Val Loss: 0.0024\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3394, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3203,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8927, 0.9597, 0.0047, 0.9949, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3437,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8996, 0.9368, 0.0336, 0.9336, 0.9719], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 7/5000 [00:01<14:26,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6797, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0857,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3351, 0.8886, 0.2329, 0.6184, 0.8354], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1022,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9043, 0.9489, 0.0080, 0.9917, 0.9962], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8649,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8783, 0.9368, 0.0056, 0.9777, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0442, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2470, 0.8274, 0.3075, 0.5587, 0.8017], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6130, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.2909, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 7/5000, Train Loss: 0.0002, Val Loss: 0.0013\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0225,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9190, 0.9457, 0.0096, 0.9901, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8840,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9586, 0.9403, 0.0135, 0.9864, 0.9930], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0398,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9154, 0.9464, 0.0092, 0.9905, 0.9954], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1879, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1147, 0.7042, 0.4613, 0.4313, 0.7320], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5316, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3316,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8977, 0.9373, 0.0348, 0.9321, 0.9709], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6061,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9470, 0.9837, 0.0015, 0.9983, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2269, 0.8119, 0.3268, 0.5429, 0.7932], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4277, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 9/5000 [00:01<13:16,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7749,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8849, 0.9363, 0.0082, 0.9745, 0.9940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.6797, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 8/5000, Train Loss: 0.0001, Val Loss: 0.0009\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8944,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9550, 0.9407, 0.0132, 0.9867, 0.9932], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3628,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9024, 0.9361, 0.0320, 0.9359, 0.9734], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3013,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8921, 0.9586, 0.0049, 0.9946, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5273, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2070, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0962, 0.6803, 0.4901, 0.4072, 0.7179], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1351, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9351, 0.9348, 0.0215, 0.9582, 0.9831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4563, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0187, 0.0745, 0.9649, 0.0252, 0.1789], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1264, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8649,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8783, 0.9368, 0.0056, 0.9777, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.2883,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8896, 0.9390, 0.0390, 0.9263, 0.9668], device='mps:0')\n",
      "Epoch 9/5000, Train Loss: 0.0001, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3446, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 10/5000 [00:02<12:57,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8477, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1766,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8957, 0.9522, 0.0067, 0.9929, 0.9969], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3524,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9009, 0.9365, 0.0329, 0.9347, 0.9726], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5281,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9231, 0.9754, 0.0023, 0.9973, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4710,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9102, 0.9703, 0.0030, 0.9967, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3602, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1888, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7048, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6312, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.1991,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8940, 0.9532, 0.0063, 0.9933, 0.9971], device='mps:0')\n",
      "Epoch 10/5000, Train Loss: 0.0001, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8814, 0.9365, 0.0070, 0.9761, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8818, 0.9365, 0.0071, 0.9759, 0.9948], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3178, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0111, 0.4828, 0.6975, 0.2348, 0.5914], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9360, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9793, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4580, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0190, 0.0687, 0.9677, 0.0232, 0.1688], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 11/5000 [00:02<12:35,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4624, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1689, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1334, 0.7258, 0.4346, 0.4536, 0.7445], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4771, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0214, 0.0057, 0.9974, 0.0019, 0.0202], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5333,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9244, 0.9759, 0.0023, 0.9974, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.9013,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9526, 0.9410, 0.0130, 0.9870, 0.9933], device='mps:0')\n",
      "Epoch 11/5000, Train Loss: 0.0001, Val Loss: 0.0012\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6182,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9515, 0.9852, 0.0013, 0.9985, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0251, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2619, 0.8385, 0.2937, 0.5698, 0.8079], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4546, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0183, 0.0802, 0.9621, 0.0273, 0.1888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7819, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5602,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9162, 0.9354, 0.0170, 0.9638, 0.9871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3438, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0026, 0.4187, 0.7517, 0.1907, 0.5450], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8217, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3160, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0119, 0.4868, 0.6939, 0.2378, 0.5942], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3913,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8982, 0.9642, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4321, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0124, 0.1545, 0.9241, 0.0555, 0.2955], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.4087, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 13/5000 [00:02<13:08,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6138,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9061, 0.9357, 0.0144, 0.9670, 0.9893], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2572, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0506, 0.6047, 0.5768, 0.3348, 0.6718], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8944,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9550, 0.9407, 0.0132, 0.9867, 0.9932], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2303, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8215, 0.9468, 0.0655, 0.8908, 0.9371], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1480,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8462, 0.9448, 0.0568, 0.9022, 0.9476], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1351,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8999, 0.9503, 0.0074, 0.9923, 0.9965], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5290, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6069,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9073, 0.9357, 0.0148, 0.9666, 0.9890], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2824, 0.8531, 0.2757, 0.5843, 0.8159], device='mps:0')\n",
      "Epoch 13/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9331, 0.9434, 0.0111, 0.9888, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 14/5000 [00:02<12:41,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3273, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9671,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9327, 0.9435, 0.0110, 0.9888, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2987, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0208, 0.5251, 0.6583, 0.2671, 0.6204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3992, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0035, 0.2598, 0.8636, 0.1017, 0.4104], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8580,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8787, 0.9367, 0.0058, 0.9775, 0.9957], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0658,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9103, 0.9474, 0.0087, 0.9910, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2571,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8825, 0.9403, 0.0424, 0.9217, 0.9635], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7783,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8845, 0.9363, 0.0081, 0.9747, 0.9940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.4416,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9050, 0.9679, 0.0033, 0.9963, 0.9987], device='mps:0')\n",
      "Epoch 14/5000, Train Loss: 0.0001, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9013, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1039,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9041, 0.9490, 0.0079, 0.9917, 0.9962], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2572, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0506, 0.6047, 0.5768, 0.3348, 0.6718], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5238,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9239, 0.9352, 0.0189, 0.9615, 0.9855], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6753,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7548e-01, 9.9268e-01, 6.2397e-04, 9.9927e-01, 9.9978e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6303,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9562, 0.9867, 0.0012, 0.9986, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 16/5000 [00:03<12:06,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3377,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8936, 0.9607, 0.0045, 0.9951, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1255,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8359, 0.9457, 0.0605, 0.8974, 0.9432], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5922,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9422, 0.9821, 0.0016, 0.9981, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.3230, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0089, 0.4705, 0.7083, 0.2260, 0.5828], device='mps:0')\n",
      "Epoch 15/5000, Train Loss: 0.0001, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1593,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8973, 0.9514, 0.0070, 0.9927, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3273, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4416,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9050, 0.9679, 0.0033, 0.9963, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0494, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2428, 0.8242, 0.3114, 0.5554, 0.8000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3827, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5230, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3472,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9001, 0.9367, 0.0333, 0.9341, 0.9722], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1221,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8342, 0.9459, 0.0611, 0.8966, 0.9425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0234,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2968, 0.8631, 0.2636, 0.5941, 0.8214], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7074, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.5333,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9244, 0.9759, 0.0023, 0.9974, 0.9991], device='mps:0')\n",
      "Epoch 16/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2589,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 17/5000 [00:03<12:07,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8829, 0.9402, 0.0422, 0.9220, 0.9637], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6095,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9483, 0.9842, 0.0014, 0.9984, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7074, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4468, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3429, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6822,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7873e-01, 9.9367e-01, 5.3722e-04, 9.9937e-01, 9.9981e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0866, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1715, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7438, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9584,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9351, 0.9432, 0.0112, 0.9886, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3302, 0.8854, 0.2367, 0.6154, 0.8336], device='mps:0')\n",
      "Epoch 17/5000, Train Loss: 0.0001, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4745,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9109, 0.9706, 0.0029, 0.9967, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3974,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9069, 0.9347, 0.0291, 0.9398, 0.9760], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9031, 0.9670, 0.0034, 0.9962, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6000, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1844, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1181, 0.7083, 0.4563, 0.4355, 0.7344], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 18/5000 [00:03<12:13,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4563,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9406, 0.9346, 0.0228, 0.9567, 0.9819], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6814,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8956, 0.9359, 0.0116, 0.9704, 0.9915], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0650, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2298, 0.8142, 0.3239, 0.5453, 0.7945], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2824, 0.8531, 0.2757, 0.5843, 0.8159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5013, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.1767, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 18/5000, Train Loss: 0.0001, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4624, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3282, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0070, 0.4580, 0.7192, 0.2171, 0.5739], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1732, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2824, 0.8531, 0.2757, 0.5843, 0.8159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8009,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8826, 0.9364, 0.0074, 0.9755, 0.9945], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0242,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9187, 0.9457, 0.0096, 0.9902, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8840,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9586, 0.9403, 0.0135, 0.9864, 0.9930], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3455, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0023, 0.4142, 0.7553, 0.1878, 0.5416], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1394,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8424, 0.9451, 0.0582, 0.9004, 0.9459], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5229,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9218, 0.9749, 0.0024, 0.9973, 0.9991], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 20/5000 [00:03<12:14,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.3913,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8982, 0.9642, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Epoch 19/5000, Train Loss: 0.0001, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4060,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9550, 0.9338, 0.0260, 0.9527, 0.9786], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8892, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4347, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8875, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3203,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8927, 0.9597, 0.0047, 0.9949, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7611, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4650, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0202, 0.0457, 0.9786, 0.0153, 0.1243], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4545,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9410, 0.9345, 0.0229, 0.9565, 0.9818], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5420, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8961,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9544, 0.9407, 0.0131, 0.9868, 0.9932], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.6390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 20/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8528,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8790, 0.9367, 0.0059, 0.9773, 0.9956], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0537, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 21/5000 [00:03<12:01,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7922, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2744,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8865, 0.9396, 0.0405, 0.9243, 0.9654], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6052, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2329,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8761, 0.9413, 0.0452, 0.9179, 0.9605], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2909, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9013,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9526, 0.9410, 0.0130, 0.9870, 0.9933], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2597,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9563, 0.0055, 0.9941, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5074,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9180, 0.9735, 0.0026, 0.9971, 0.9990], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.7177,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8909, 0.9360, 0.0102, 0.9721, 0.9925], device='mps:0')\n",
      "Epoch 21/5000, Train Loss: 0.0001, Val Loss: 0.0008\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3732, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([8.5354e-05, 3.3776e-01, 8.1227e-01, 1.4207e-01, 4.8061e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1247, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2866, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0284, 0.5501, 0.6338, 0.2874, 0.6369], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2156, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0879, 0.6687, 0.5040, 0.3956, 0.7110], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5567,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9169, 0.9354, 0.0172, 0.9636, 0.9870], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8234,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8809, 0.9365, 0.0067, 0.9763, 0.9950], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 23/5000 [00:04<12:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9238, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0710,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9094, 0.9476, 0.0086, 0.9911, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.3957, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0028, 0.2705, 0.8569, 0.1069, 0.4206], device='mps:0')\n",
      "Epoch 22/5000, Train Loss: 0.0001, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4884, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5567, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3992, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0035, 0.2598, 0.8636, 0.1017, 0.4104], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2885, 0.8574, 0.2705, 0.5885, 0.8183], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4173,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9014, 0.9661, 0.0036, 0.9960, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4814, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2052, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0978, 0.6826, 0.4874, 0.4095, 0.7193], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0216,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2957, 0.8623, 0.2646, 0.5933, 0.8210], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7801,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8844, 0.9363, 0.0081, 0.9747, 0.9941], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.1342, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1671, 0.7602, 0.3916, 0.4894, 0.7642], device='mps:0')\n",
      "Epoch 23/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9290,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9437, 0.9420, 0.0121, 0.9878, 0.9938], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 24/5000 [00:04<12:30,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3169, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0494, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2428, 0.8242, 0.3114, 0.5554, 0.8000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7888, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6529, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0995,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3427, 0.8934, 0.2271, 0.6229, 0.8381], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7238,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([1., 1., 0., 1., 1.], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3957, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0028, 0.2705, 0.8569, 0.1069, 0.4206], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8130, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7056,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8924, 0.9360, 0.0107, 0.9716, 0.9922], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.1767, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 24/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6658,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8978, 0.9359, 0.0122, 0.9697, 0.9910], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5047,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9283, 0.9351, 0.0200, 0.9602, 0.9846], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4225,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9021, 0.9665, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3844,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8974, 0.9638, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 25/5000 [00:04<12:12,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6857,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.8039e-01, 9.9417e-01, 4.9379e-04, 9.9942e-01, 9.9982e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1048, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1947, 0.7853, 0.3601, 0.5155, 0.7784], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7835,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8841, 0.9363, 0.0080, 0.9749, 0.9942], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6000,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9085, 0.9356, 0.0151, 0.9662, 0.9888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9349, 0.9797, 0.0019, 0.9979, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3758, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.5559, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 25/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3741, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2944, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6537, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8389,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8798, 0.9366, 0.0063, 0.9769, 0.9953], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4147, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0074, 0.2106, 0.8930, 0.0791, 0.3604], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3290,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8931, 0.9602, 0.0046, 0.9950, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2858, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7247,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8901, 0.9361, 0.0100, 0.9724, 0.9927], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2043,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 27/5000 [00:04<11:48,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8937, 0.9535, 0.0063, 0.9933, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.1827, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1198, 0.7103, 0.4538, 0.4376, 0.7355], device='mps:0')\n",
      "Epoch 26/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6814, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1550,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8492, 0.9445, 0.0558, 0.9037, 0.9488], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2217, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8751, 0.9414, 0.0456, 0.9173, 0.9601], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1455, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0121,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9214, 0.9453, 0.0099, 0.9899, 0.9951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4182, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0084, 0.1995, 0.8993, 0.0742, 0.3483], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2597,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9563, 0.0055, 0.9941, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8788, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2702, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8215, 0.9468, 0.0655, 0.8908, 0.9371], device='mps:0')\n",
      "Epoch 27/5000, Train Loss: 0.0000, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3533, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5178, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6667, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0805,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 28/5000 [00:04<11:58,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3322, 0.8867, 0.2352, 0.6166, 0.8344], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3039, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0179, 0.5140, 0.6689, 0.2584, 0.6129], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5039,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9172, 0.9732, 0.0026, 0.9971, 0.9990], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8130,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8816, 0.9365, 0.0071, 0.9760, 0.9948], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2952,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8910, 0.9387, 0.0383, 0.9273, 0.9675], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1704, 0.7633, 0.3877, 0.4926, 0.7660], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9034, 0.9357, 0.0137, 0.9678, 0.9898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.0658,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9103, 0.9474, 0.0087, 0.9910, 0.9958], device='mps:0')\n",
      "Epoch 28/5000, Train Loss: 0.0001, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2078,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8935, 0.9537, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8857, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6797, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5454,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9277, 0.9771, 0.0021, 0.9976, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9532,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9365, 0.9430, 0.0114, 0.9884, 0.9942], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6225,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9046, 0.9357, 0.0141, 0.9674, 0.9896], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3913,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8982, 0.9642, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3931, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 30/5000 [00:05<11:43,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6338, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0303, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2579, 0.8355, 0.2974, 0.5669, 0.8062], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.7697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8853, 0.9362, 0.0084, 0.9743, 0.9938], device='mps:0')\n",
      "Epoch 29/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3758, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0658,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9103, 0.9474, 0.0087, 0.9910, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2987, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0208, 0.5251, 0.6583, 0.2671, 0.6204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7186,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.9717e-01, 9.9917e-01, 6.8694e-05, 9.9992e-01, 9.9998e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5247,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9222, 0.9751, 0.0024, 0.9973, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0095,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2873, 0.8565, 0.2716, 0.5877, 0.8178], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7628, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2415,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8784, 0.9409, 0.0442, 0.9193, 0.9616], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3411,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8938, 0.9609, 0.0044, 0.9951, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9879, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.0970,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9051, 0.9487, 0.0081, 0.9916, 0.9961], device='mps:0')\n",
      "Epoch 30/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6675,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8976, 0.9359, 0.0121, 0.9698, 0.9911], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2346,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8766, 0.9412, 0.0450, 0.9182, 0.9607], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 31/5000 [00:05<11:37,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4277, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3021,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8924, 0.9385, 0.0376, 0.9282, 0.9682], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3099,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8923, 0.9591, 0.0048, 0.9948, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5758, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7273, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3282, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0070, 0.4580, 0.7192, 0.2171, 0.5739], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5913,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9101, 0.9356, 0.0155, 0.9657, 0.9884], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5957,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9434, 0.9825, 0.0016, 0.9982, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.0520, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 31/5000, Train Loss: 0.0000, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3177,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8953, 0.9378, 0.0361, 0.9303, 0.9697], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1221,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8342, 0.9459, 0.0611, 0.8966, 0.9425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5663, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4684,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9374, 0.9347, 0.0221, 0.9576, 0.9826], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3108, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0143, 0.4986, 0.6832, 0.2466, 0.6024], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0580,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3190, 0.8780, 0.2456, 0.6084, 0.8296], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2511, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4563, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0187, 0.0745, 0.9649, 0.0252, 0.1789], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 33/5000 [00:05<11:34,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1402,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8993, 0.9506, 0.0073, 0.9924, 0.9966], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.6044, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 32/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6615, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6321, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5091, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8865, 0.9362, 0.0088, 0.9738, 0.9936], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2320,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8924, 0.9549, 0.0059, 0.9937, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1585, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1436, 0.7367, 0.4210, 0.4649, 0.7508], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1628,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8969, 0.9516, 0.0069, 0.9927, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1714,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8961, 0.9519, 0.0068, 0.9929, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3290,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8931, 0.9602, 0.0046, 0.9950, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3931, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.3437,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8996, 0.9368, 0.0336, 0.9336, 0.9719], device='mps:0')\n",
      "Epoch 33/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4849, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3637, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 34/5000 [00:05<12:14,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0771, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2194, 0.8059, 0.3342, 0.5368, 0.7899], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7299,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8895, 0.9361, 0.0098, 0.9727, 0.9929], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6493,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6396e-01, 9.8914e-01, 9.4178e-04, 9.9890e-01, 9.9966e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1178, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2727,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8862, 0.9397, 0.0407, 0.9241, 0.9652], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1663, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5134,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9263, 0.9351, 0.0195, 0.9608, 0.9850], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3766,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9043, 0.9355, 0.0308, 0.9375, 0.9745], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.6796,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8958, 0.9359, 0.0117, 0.9704, 0.9915], device='mps:0')\n",
      "Epoch 34/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9255,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9448, 0.9419, 0.0122, 0.9877, 0.9937], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9584,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9351, 0.9432, 0.0112, 0.9886, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2727,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8862, 0.9397, 0.0407, 0.9241, 0.9652], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4503, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 35/5000 [00:05<12:03,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5229,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9218, 0.9749, 0.0024, 0.9973, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4217, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0094, 0.1883, 0.9056, 0.0694, 0.3358], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1524, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5134,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9263, 0.9351, 0.0195, 0.9608, 0.9850], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6260,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9040, 0.9357, 0.0139, 0.9676, 0.9897], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.3593, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([3.4761e-04, 3.7694e-01, 7.8398e-01, 1.6465e-01, 5.1267e-01],\n",
      "       device='mps:0')\n",
      "Epoch 35/5000, Train Loss: 0.0001, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2087, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0945, 0.6780, 0.4929, 0.4049, 0.7166], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3057, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0170, 0.5102, 0.6725, 0.2554, 0.6103], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5931,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9098, 0.9356, 0.0154, 0.9658, 0.9885], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5282, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3861,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8976, 0.9639, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7386, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6260,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9040, 0.9357, 0.0139, 0.9676, 0.9897], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3394,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8937, 0.9608, 0.0045, 0.9951, 0.9981], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 37/5000 [00:06<11:49,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.6476,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6323e-01, 9.8891e-01, 9.6264e-04, 9.9888e-01, 9.9965e-01],\n",
      "       device='mps:0')\n",
      "Epoch 36/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2329, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0717, 0.6437, 0.5331, 0.3713, 0.6959], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5256, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5836, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0156,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9206, 0.9454, 0.0098, 0.9900, 0.9951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2824, 0.8531, 0.2757, 0.5843, 0.8159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2545,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8918, 0.9560, 0.0055, 0.9940, 0.9975], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6130, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9723,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9313, 0.9437, 0.0109, 0.9889, 0.9945], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4884, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.5308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 37/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3783,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9045, 0.9355, 0.0306, 0.9377, 0.9746], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4606,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9083, 0.9695, 0.0031, 0.9965, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0840, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2134, 0.8010, 0.3404, 0.5317, 0.7871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3619,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 38/5000 [00:06<12:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8953, 0.9623, 0.0042, 0.9954, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4329, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2952,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8910, 0.9387, 0.0383, 0.9273, 0.9675], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7160, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1108,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9031, 0.9493, 0.0078, 0.9919, 0.9963], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0243, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7117, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.1308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1704, 0.7633, 0.3877, 0.4926, 0.7660], device='mps:0')\n",
      "Epoch 38/5000, Train Loss: 0.0001, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9983, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3117,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8924, 0.9592, 0.0048, 0.9948, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1212, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0857,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3351, 0.8886, 0.2329, 0.6184, 0.8354], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7117, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6251,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9541, 0.9860, 0.0012, 0.9986, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0719, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2239, 0.8095, 0.3297, 0.5405, 0.7919], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9331, 0.9434, 0.0111, 0.9888, 0.9944], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 40/5000 [00:06<11:58,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1420, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4831,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9126, 0.9713, 0.0028, 0.9968, 0.9989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.7386, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 39/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9175, 0.9460, 0.0095, 0.9903, 0.9953], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2710, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0396, 0.5800, 0.6031, 0.3129, 0.6563], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4476, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0167, 0.1031, 0.9507, 0.0357, 0.2253], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4459,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9434, 0.9344, 0.0234, 0.9559, 0.9813], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5766,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9371, 0.9804, 0.0018, 0.9979, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3697, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([3.8147e-06, 3.4772e-01, 8.0524e-01, 1.4766e-01, 4.8894e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1645, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2885, 0.8574, 0.2705, 0.5885, 0.8183], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0433,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9147, 0.9465, 0.0092, 0.9906, 0.9955], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.4242,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9024, 0.9666, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Epoch 40/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3637, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 41/5000 [00:06<11:49,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1732,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8960, 0.9520, 0.0067, 0.9929, 0.9969], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3914, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9048, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2632,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9565, 0.0054, 0.9942, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2467,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8798, 0.9407, 0.0436, 0.9201, 0.9622], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6467,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9007, 0.9358, 0.0130, 0.9687, 0.9904], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3965,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8988, 0.9646, 0.0038, 0.9958, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2502,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8807, 0.9406, 0.0432, 0.9207, 0.9626], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3117,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8924, 0.9592, 0.0048, 0.9948, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.3438, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0026, 0.4187, 0.7517, 0.1907, 0.5450], device='mps:0')\n",
      "Epoch 41/5000, Train Loss: 0.0001, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7835,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8841, 0.9363, 0.0080, 0.9749, 0.9942], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0918,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9059, 0.9485, 0.0082, 0.9915, 0.9961], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6052, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8944,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9550, 0.9407, 0.0132, 0.9867, 0.9932], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1273, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1737, 0.7664, 0.3838, 0.4958, 0.7678], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1195,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9019, 0.9497, 0.0077, 0.9920, 0.9963], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8857, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 42/5000 [00:06<12:19,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3030,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8921, 0.9587, 0.0049, 0.9947, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6303,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9562, 0.9867, 0.0012, 0.9986, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6806, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.2243, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0797, 0.6565, 0.5183, 0.3836, 0.7037], device='mps:0')\n",
      "Epoch 42/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3974, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0032, 0.2651, 0.8602, 0.1043, 0.4155], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0927, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2057, 0.7946, 0.3484, 0.5252, 0.7836], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1931,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8637, 0.9429, 0.0503, 0.9110, 0.9550], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7402,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8884, 0.9361, 0.0094, 0.9731, 0.9931], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6070, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4347, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5593, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2539, 0.8325, 0.3011, 0.5639, 0.8046], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5532,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9176, 0.9354, 0.0174, 0.9634, 0.9868], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 44/5000 [00:07<11:54,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.5576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9312, 0.9784, 0.0020, 0.9977, 0.9992], device='mps:0')\n",
      "Epoch 43/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5515,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9179, 0.9354, 0.0174, 0.9633, 0.9868], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6043,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9464, 0.9835, 0.0015, 0.9983, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2909,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8918, 0.9580, 0.0051, 0.9945, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1195,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9019, 0.9497, 0.0077, 0.9920, 0.9963], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5151,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9259, 0.9351, 0.0194, 0.9609, 0.9851], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6312, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9567,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9355, 0.9431, 0.0113, 0.9885, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0242,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9187, 0.9457, 0.0096, 0.9902, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4926,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9312, 0.9349, 0.0206, 0.9593, 0.9839], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7212,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8905, 0.9361, 0.0101, 0.9723, 0.9926], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.7239, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 44/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9312, 0.9784, 0.0020, 0.9977, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2364, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0686, 0.6384, 0.5391, 0.3662, 0.6927], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6502, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5507, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 45/5000 [00:07<11:46,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5169,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9255, 0.9352, 0.0193, 0.9610, 0.9852], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3351, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0048, 0.4409, 0.7336, 0.2053, 0.5614], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1238,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8351, 0.9458, 0.0608, 0.8970, 0.9428], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8753,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9617, 0.9399, 0.0138, 0.9861, 0.9928], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3845, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.2926,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8919, 0.9581, 0.0050, 0.9945, 0.9978], device='mps:0')\n",
      "Epoch 45/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4805, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7264,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8899, 0.9361, 0.0099, 0.9725, 0.9928], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8441,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8795, 0.9367, 0.0062, 0.9771, 0.9954], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3013, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0666,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3241, 0.8814, 0.2415, 0.6116, 0.8315], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0546, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2385, 0.8209, 0.3155, 0.5521, 0.7982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9567,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9355, 0.9431, 0.0113, 0.9885, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2701,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9568, 0.0053, 0.9942, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3775, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 47/5000 [00:07<11:50,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0199, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2659, 0.8413, 0.2902, 0.5727, 0.8094], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.4684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0206, 0.0343, 0.9840, 0.0114, 0.0990], device='mps:0')\n",
      "Epoch 46/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0589,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9116, 0.9471, 0.0088, 0.9909, 0.9957], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4078,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9544, 0.9338, 0.0259, 0.9528, 0.9788], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1922,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8945, 0.9529, 0.0064, 0.9932, 0.9970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0451, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1741, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1283, 0.7201, 0.4417, 0.4477, 0.7413], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6597,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6844e-01, 9.9053e-01, 8.1587e-04, 9.9904e-01, 9.9970e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5654, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0052, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1247, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8528,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8790, 0.9367, 0.0059, 0.9773, 0.9956], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.9325, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 47/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9793, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7611, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 48/5000 [00:07<11:44,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3845, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5654, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4546, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0183, 0.0802, 0.9621, 0.0273, 0.1888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1697, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9203,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9464, 0.9417, 0.0124, 0.9875, 0.9937], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1628,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8969, 0.9516, 0.0069, 0.9927, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4554,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9073, 0.9690, 0.0031, 0.9965, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6009, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.4337,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9468, 0.9343, 0.0242, 0.9549, 0.9805], device='mps:0')\n",
      "Epoch 48/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3775, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7714,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8852, 0.9363, 0.0084, 0.9744, 0.9939], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5480,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9187, 0.9354, 0.0176, 0.9631, 0.9866], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6052, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3697, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([3.8147e-06, 3.4772e-01, 8.0524e-01, 1.4766e-01, 4.8894e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0684,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3252, 0.8821, 0.2407, 0.6123, 0.8318], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8840,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9586, 0.9403, 0.0135, 0.9864, 0.9930], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 50/5000 [00:07<11:37,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6156,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9058, 0.9357, 0.0144, 0.9671, 0.9893], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3031, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4459, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0163, 0.1089, 0.9478, 0.0378, 0.2338], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.0710,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9094, 0.9476, 0.0086, 0.9911, 0.9958], device='mps:0')\n",
      "Epoch 49/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4156, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9151, 0.9355, 0.0167, 0.9641, 0.9874], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8649,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8783, 0.9368, 0.0056, 0.9777, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1143,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9026, 0.9494, 0.0078, 0.9919, 0.9963], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7697, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3862, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1082,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8271, 0.9464, 0.0635, 0.8933, 0.9395], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2598, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5705,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9141, 0.9355, 0.0165, 0.9645, 0.9876], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8113, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.6874,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.8123e-01, 9.9442e-01, 4.7186e-04, 9.9944e-01, 9.9983e-01],\n",
      "       device='mps:0')\n",
      "Epoch 50/5000, Train Loss: 0.0001, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8615, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 51/5000 [00:08<12:07,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3178, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0111, 0.4828, 0.6975, 0.2348, 0.5914], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1689, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1334, 0.7258, 0.4346, 0.4536, 0.7445], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3533, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4537,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9070, 0.9689, 0.0031, 0.9965, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6234, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9584,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9351, 0.9432, 0.0112, 0.9886, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2970, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0219, 0.5288, 0.6548, 0.2700, 0.6228], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1030,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8243, 0.9466, 0.0645, 0.8921, 0.9383], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8753,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9617, 0.9399, 0.0138, 0.9861, 0.9928], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.7021,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8929, 0.9360, 0.0108, 0.9714, 0.9921], device='mps:0')\n",
      "Epoch 51/5000, Train Loss: 0.0001, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1853,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8950, 0.9526, 0.0066, 0.9931, 0.9970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2511, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4337,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9468, 0.9343, 0.0242, 0.9549, 0.9805], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6043,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9464, 0.9835, 0.0015, 0.9983, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9914, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 52/5000 [00:08<12:13,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.9538, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1827, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1198, 0.7103, 0.4538, 0.4376, 0.7355], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1723, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1300, 0.7220, 0.4393, 0.4497, 0.7424], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8974, 0.9513, 0.0070, 0.9926, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3464, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.7628, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 52/5000, Train Loss: 0.0001, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8814, 0.9365, 0.0070, 0.9761, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4623,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9086, 0.9696, 0.0031, 0.9966, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4675,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9096, 0.9700, 0.0030, 0.9966, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8857, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0918,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9059, 0.9485, 0.0082, 0.9915, 0.9961], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0225,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9190, 0.9457, 0.0096, 0.9901, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3429, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4312, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4052,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8998, 0.9652, 0.0037, 0.9959, 0.9985], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 54/5000 [00:08<11:52,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1593,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8973, 0.9514, 0.0070, 0.9927, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.4520, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 53/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7507, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2104,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8694, 0.9422, 0.0480, 0.9141, 0.9575], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2511, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9151,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9481, 0.9415, 0.0125, 0.9874, 0.9936], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9533, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0511,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3147, 0.8752, 0.2490, 0.6057, 0.8280], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6961, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3861,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8976, 0.9639, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1775,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8581, 0.9436, 0.0524, 0.9081, 0.9526], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.4545,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9410, 0.9345, 0.0229, 0.9565, 0.9818], device='mps:0')\n",
      "Epoch 54/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4900,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9141, 0.9719, 0.0027, 0.9969, 0.9989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4008,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9565, 0.9337, 0.0264, 0.9522, 0.9783], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9948, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 55/5000 [00:08<11:46,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6485, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6044, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6650, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0338, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2552, 0.8335, 0.2998, 0.5649, 0.8051], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2563, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0658, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2078,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8935, 0.9537, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.6070, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 55/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4295, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.9538, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2987, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0208, 0.5251, 0.6583, 0.2671, 0.6204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0208, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2996,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8920, 0.9585, 0.0050, 0.9946, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4225,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9021, 0.9665, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0199, 0.0515, 0.9759, 0.0172, 0.1361], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 57/5000 [00:08<11:39,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1654, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1368, 0.7295, 0.4300, 0.4574, 0.7467], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1819, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2885, 0.8574, 0.2705, 0.5885, 0.8183], device='mps:0')\n",
      "Epoch 56/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9238, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2190,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8720, 0.9419, 0.0469, 0.9156, 0.9587], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3965,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8988, 0.9646, 0.0038, 0.9958, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4009, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0039, 0.2544, 0.8669, 0.0992, 0.4051], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8477, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3489,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9004, 0.9366, 0.0332, 0.9343, 0.9723], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8269, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4260,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9026, 0.9667, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9879,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9272, 0.9443, 0.0105, 0.9893, 0.9947], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.0537, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 57/5000, Train Loss: 0.0001, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3809,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8971, 0.9635, 0.0040, 0.9956, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7022, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 58/5000 [00:09<11:35,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2615,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9564, 0.0055, 0.9941, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9351, 0.9348, 0.0215, 0.9582, 0.9831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9518, 0.9340, 0.0253, 0.9535, 0.9794], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1463,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8455, 0.9449, 0.0571, 0.9019, 0.9472], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6242,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9043, 0.9357, 0.0140, 0.9675, 0.9896], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8182,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8812, 0.9365, 0.0069, 0.9761, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4416, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1013,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8234, 0.9467, 0.0648, 0.8917, 0.9379], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.1178, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 58/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9349, 0.9797, 0.0019, 0.9979, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3567, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2519,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8812, 0.9405, 0.0430, 0.9209, 0.9628], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5117,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9267, 0.9351, 0.0196, 0.9607, 0.9849], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3360, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3464, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 59/5000 [00:09<11:37,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8961, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6996,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.8723e-01, 9.9622e-01, 3.1736e-04, 9.9963e-01, 9.9989e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4433,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9053, 0.9681, 0.0033, 0.9963, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.6286,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9555, 0.9865, 0.0012, 0.9986, 0.9996], device='mps:0')\n",
      "Epoch 59/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8754, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8477, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1065,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8262, 0.9465, 0.0639, 0.8929, 0.9391], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3767, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([2.6655e-04, 3.2769e-01, 8.1925e-01, 1.3653e-01, 4.7205e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3039,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8927, 0.9384, 0.0374, 0.9285, 0.9684], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1974,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8941, 0.9532, 0.0064, 0.9932, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7836, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9446, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8199, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5922,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9422, 0.9821, 0.0016, 0.9981, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 61/5000 [00:09<12:02,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2268,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8926, 0.9546, 0.0059, 0.9937, 0.9973], device='mps:0')\n",
      "Epoch 60/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7541,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8869, 0.9362, 0.0089, 0.9737, 0.9935], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2225, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0813, 0.6590, 0.5154, 0.3860, 0.7052], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4615,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9392, 0.9346, 0.0225, 0.9571, 0.9822], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1342, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1671, 0.7602, 0.3916, 0.4894, 0.7642], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2935,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8906, 0.9388, 0.0385, 0.9270, 0.9673], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0511,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3147, 0.8752, 0.2490, 0.6057, 0.8280], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1827,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8600, 0.9434, 0.0517, 0.9091, 0.9534], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1411,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8432, 0.9451, 0.0579, 0.9008, 0.9463], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1533, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1487, 0.7420, 0.4144, 0.4704, 0.7539], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0537, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.2026, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 61/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9619,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9341, 0.9433, 0.0112, 0.9887, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3879,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8978, 0.9640, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4563, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0187, 0.0745, 0.9649, 0.0252, 0.1789], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0580, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 62/5000 [00:09<11:57,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2356, 0.8187, 0.3182, 0.5499, 0.7970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4260, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9082,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9503, 0.9412, 0.0127, 0.9872, 0.9934], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6736, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0545,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3168, 0.8766, 0.2473, 0.6071, 0.8288], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7013, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1732, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.0814, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 62/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2130,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8932, 0.9539, 0.0061, 0.9935, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0130, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2711, 0.8451, 0.2856, 0.5764, 0.8115], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1704, 0.7633, 0.3877, 0.4926, 0.7660], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5767, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5057, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3740,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8964, 0.9631, 0.0041, 0.9955, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8963, 0.9519, 0.0068, 0.9928, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6086,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9070, 0.9357, 0.0147, 0.9667, 0.9891], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 64/5000 [00:09<11:37,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9948,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9255, 0.9446, 0.0103, 0.9895, 0.9948], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.5403,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9263, 0.9766, 0.0022, 0.9975, 0.9992], device='mps:0')\n",
      "Epoch 63/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3948,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8986, 0.9645, 0.0038, 0.9958, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3870, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0013, 0.2968, 0.8400, 0.1202, 0.4450], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1056,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9038, 0.9491, 0.0079, 0.9918, 0.9962], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7212,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8905, 0.9361, 0.0101, 0.9723, 0.9926], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1715, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2373, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4182, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0084, 0.1995, 0.8993, 0.0742, 0.3483], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7126, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.8978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9538, 0.9408, 0.0131, 0.9868, 0.9932], device='mps:0')\n",
      "Epoch 64/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6252, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8251, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5299,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9235, 0.9756, 0.0023, 0.9974, 0.9991], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 65/5000 [00:10<11:52,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9331, 0.9434, 0.0111, 0.9888, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9446, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9300, 0.9350, 0.0203, 0.9597, 0.9842], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2468, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0594, 0.6220, 0.5577, 0.3507, 0.6826], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6017,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9082, 0.9356, 0.0150, 0.9663, 0.9888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1221, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1786, 0.7709, 0.3781, 0.5006, 0.7703], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5515,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9179, 0.9354, 0.0174, 0.9633, 0.9868], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.7801,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8844, 0.9363, 0.0081, 0.9747, 0.9941], device='mps:0')\n",
      "Epoch 65/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2779,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8873, 0.9394, 0.0401, 0.9248, 0.9657], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6788,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7710e-01, 9.9318e-01, 5.8070e-04, 9.9932e-01, 9.9979e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4875, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1507, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5134,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9263, 0.9351, 0.0195, 0.9608, 0.9850], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9151, 0.9355, 0.0167, 0.9641, 0.9874], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5047,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9283, 0.9351, 0.0200, 0.9602, 0.9846], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2935, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 66/5000 [00:10<12:01,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0240, 0.5360, 0.6478, 0.2758, 0.6276], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6286,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9555, 0.9865, 0.0012, 0.9986, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2355, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.0857, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2119, 0.7997, 0.3419, 0.5304, 0.7864], device='mps:0')\n",
      "Epoch 66/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2095,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8934, 0.9537, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4242,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9024, 0.9666, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3905,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9060, 0.9350, 0.0296, 0.9391, 0.9755], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9966, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6866, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4866,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9134, 0.9716, 0.0028, 0.9968, 0.9989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6407, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6009, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3307,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8932, 0.9603, 0.0046, 0.9950, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2286,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8925, 0.9547, 0.0059, 0.9937, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.4555, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 67/5000, Train Loss: 0.0000, Val Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 68/5000 [00:10<11:52,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2987, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0208, 0.5251, 0.6583, 0.2671, 0.6204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4147,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9523, 0.9340, 0.0255, 0.9534, 0.9792], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2606, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0477, 0.5987, 0.5833, 0.3294, 0.6681], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8814, 0.9365, 0.0070, 0.9761, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1376,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8416, 0.9452, 0.0585, 0.9000, 0.9456], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3143, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0127, 0.4908, 0.6904, 0.2407, 0.5970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6918, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9572, 0.0052, 0.9943, 0.9977], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6883,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8947, 0.9359, 0.0113, 0.9708, 0.9917], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9862, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.9844,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9281, 0.9442, 0.0106, 0.9892, 0.9947], device='mps:0')\n",
      "Epoch 68/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5386, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4251,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9493, 0.9341, 0.0248, 0.9542, 0.9799], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3230, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0089, 0.4705, 0.7083, 0.2260, 0.5828], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3870,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9056, 0.9351, 0.0299, 0.9387, 0.9752], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3628,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9024, 0.9361, 0.0320, 0.9359, 0.9734], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7299, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 69/5000 [00:10<12:11,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5671, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6130, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6598, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0285,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3003, 0.8655, 0.2607, 0.5964, 0.8227], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.2935,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8906, 0.9388, 0.0385, 0.9270, 0.9673], device='mps:0')\n",
      "Epoch 69/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3913,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8982, 0.9642, 0.0039, 0.9957, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4459, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0163, 0.1089, 0.9478, 0.0378, 0.2338], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2121,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8699, 0.9421, 0.0478, 0.9144, 0.9578], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2217, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7073,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8922, 0.9360, 0.0106, 0.9717, 0.9923], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0848,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9071, 0.9482, 0.0083, 0.9914, 0.9960], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4286, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0114, 0.1658, 0.9180, 0.0600, 0.3094], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6000,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9085, 0.9356, 0.0151, 0.9662, 0.9888], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9152, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8182,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 71/5000 [00:10<11:49,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8812, 0.9365, 0.0069, 0.9761, 0.9949], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8215, 0.9468, 0.0655, 0.8908, 0.9371], device='mps:0')\n",
      "Epoch 70/5000, Train Loss: 0.0001, Val Loss: 0.0009\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5230, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2511, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4823, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8528,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8790, 0.9367, 0.0059, 0.9773, 0.9956], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6173,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9055, 0.9357, 0.0143, 0.9671, 0.9894], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7611, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5455, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0208, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1334, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4666,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9378, 0.9347, 0.0222, 0.9574, 0.9825], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.4096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0060, 0.2272, 0.8833, 0.0865, 0.3778], device='mps:0')\n",
      "Epoch 71/5000, Train Loss: 0.0001, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3671, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0632,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3221, 0.8801, 0.2431, 0.6104, 0.8307], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4035,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8996, 0.9651, 0.0037, 0.9959, 0.9985], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 72/5000 [00:11<11:43,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3992, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0035, 0.2598, 0.8636, 0.1017, 0.4104], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9175, 0.9460, 0.0095, 0.9903, 0.9953], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6459, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2216,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8928, 0.9543, 0.0060, 0.9936, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5887,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9410, 0.9818, 0.0017, 0.9981, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2824, 0.8531, 0.2757, 0.5843, 0.8159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9446, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.0866, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 72/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1108,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9031, 0.9493, 0.0078, 0.9919, 0.9963], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2848,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8888, 0.9392, 0.0394, 0.9258, 0.9665], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3351, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0048, 0.4409, 0.7336, 0.2053, 0.5614], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6467,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9007, 0.9358, 0.0130, 0.9687, 0.9904], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7125,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8916, 0.9360, 0.0104, 0.9719, 0.9924], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4269, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0109, 0.1715, 0.9149, 0.0624, 0.3162], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8853, 0.9362, 0.0084, 0.9743, 0.9938], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8892, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0216,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|▏         | 74/5000 [00:11<11:33,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2957, 0.8623, 0.2646, 0.5933, 0.8210], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5991,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9446, 0.9829, 0.0015, 0.9982, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.1611, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 73/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5767, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2684, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0381,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9157, 0.9463, 0.0093, 0.9905, 0.9954], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5446, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1056,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9038, 0.9491, 0.0079, 0.9918, 0.9962], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9654,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9331, 0.9434, 0.0111, 0.9888, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9602, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0095, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2737, 0.8469, 0.2833, 0.5782, 0.8125], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6511,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6469e-01, 9.8937e-01, 9.2083e-04, 9.9892e-01, 9.9967e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7308, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.3411,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8938, 0.9609, 0.0044, 0.9951, 0.9981], device='mps:0')\n",
      "Epoch 74/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7065,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.9077e-01, 9.9728e-01, 2.2790e-04, 9.9973e-01, 9.9992e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3965,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8988, 0.9646, 0.0038, 0.9958, 0.9984], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 75/5000 [00:11<11:34,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1697,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8963, 0.9519, 0.0068, 0.9928, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5905, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0424, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2484, 0.8284, 0.3062, 0.5597, 0.8023], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7801,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8844, 0.9363, 0.0081, 0.9747, 0.9941], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2961, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2165, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5532,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9176, 0.9354, 0.0174, 0.9634, 0.9868], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7784, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.5645, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 75/5000, Train Loss: 0.0001, Val Loss: 0.0008\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4875, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4277, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3031, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8320,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8803, 0.9366, 0.0065, 0.9766, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4286, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0114, 0.1658, 0.9180, 0.0600, 0.3094], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9572, 0.0052, 0.9943, 0.9977], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5420, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 76/5000 [00:11<12:06,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2190,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8720, 0.9419, 0.0469, 0.9156, 0.9587], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0701,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3262, 0.8828, 0.2399, 0.6129, 0.8322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0441,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3104, 0.8723, 0.2525, 0.6029, 0.8264], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.3559, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([6.6137e-04, 3.8644e-01, 7.7684e-01, 1.7039e-01, 5.2018e-01],\n",
      "       device='mps:0')\n",
      "Epoch 76/5000, Train Loss: 0.0000, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0832, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1853,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8950, 0.9526, 0.0066, 0.9931, 0.9970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3377,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8936, 0.9607, 0.0045, 0.9951, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5351, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9948, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2545,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8918, 0.9560, 0.0055, 0.9940, 0.9975], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8389,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8798, 0.9366, 0.0063, 0.9769, 0.9953], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5195,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9209, 0.9746, 0.0024, 0.9972, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4987, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6477, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([0.6364, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 78/5000 [00:11<11:42,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2034,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8672, 0.9425, 0.0489, 0.9129, 0.9566], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1844,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8606, 0.9433, 0.0515, 0.9094, 0.9537], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8650, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4684,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9374, 0.9347, 0.0221, 0.9576, 0.9826], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5264,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9226, 0.9753, 0.0023, 0.9973, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3974, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0032, 0.2651, 0.8602, 0.1043, 0.4155], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0373, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2525, 0.8315, 0.3023, 0.5628, 0.8040], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5454,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9277, 0.9771, 0.0021, 0.9976, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9013,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9526, 0.9410, 0.0130, 0.9870, 0.9933], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.8597,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8786, 0.9368, 0.0057, 0.9776, 0.9957], device='mps:0')\n",
      "Epoch 78/5000, Train Loss: 0.0000, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2615, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3039, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0179, 0.5140, 0.6689, 0.2584, 0.6129], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0744,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9088, 0.9478, 0.0085, 0.9912, 0.9959], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5688,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9144, 0.9355, 0.0166, 0.9643, 0.9875], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5533, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 79/5000 [00:12<11:38,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7749, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4918, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5351, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1342, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1671, 0.7602, 0.3916, 0.4894, 0.7642], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2875, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.0978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8215, 0.9468, 0.0655, 0.8908, 0.9371], device='mps:0')\n",
      "Epoch 79/5000, Train Loss: 0.0001, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1931,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8637, 0.9429, 0.0503, 0.9110, 0.9550], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2701,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9568, 0.0053, 0.9942, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7203,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.9811e-01, 9.9945e-01, 4.5836e-05, 9.9995e-01, 9.9998e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4026, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0043, 0.2490, 0.8702, 0.0966, 0.3998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5342,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9216, 0.9353, 0.0183, 0.9622, 0.9860], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2537,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8816, 0.9404, 0.0428, 0.9212, 0.9631], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8751, 0.9414, 0.0456, 0.9173, 0.9601], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6035, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6918, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1619,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8520, 0.9442, 0.0547, 0.9051, 0.9500], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.0675,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9100, 0.9475, 0.0087, 0.9911, 0.9958], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 81/5000 [00:12<11:27,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/5000, Train Loss: 0.0001, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3818,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9050, 0.9353, 0.0303, 0.9381, 0.9749], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4078,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9544, 0.9338, 0.0259, 0.9528, 0.9788], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4555, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1714,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8961, 0.9519, 0.0068, 0.9929, 0.9968], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2173, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0862, 0.6663, 0.5068, 0.3932, 0.7095], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6493,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6396e-01, 9.8914e-01, 9.4178e-04, 9.9890e-01, 9.9966e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4398,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9047, 0.9678, 0.0033, 0.9963, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4164,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9518, 0.9340, 0.0253, 0.9535, 0.9794], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4649,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9383, 0.9347, 0.0223, 0.9573, 0.9824], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4260,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9026, 0.9667, 0.0035, 0.9961, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.7239, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 81/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1871, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0615, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2327, 0.8164, 0.3210, 0.5476, 0.7957], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4191, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2407,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8921, 0.9553, 0.0057, 0.9939, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3879, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 82/5000 [00:12<11:28,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0277, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0338, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2552, 0.8335, 0.2998, 0.5649, 0.8051], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7438, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1412, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1605, 0.7538, 0.3997, 0.4827, 0.7606], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5948,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9095, 0.9356, 0.0153, 0.9659, 0.9886], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.0676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 82/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0087, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6944, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0892,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3370, 0.8898, 0.2314, 0.6195, 0.8361], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2866, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0284, 0.5501, 0.6338, 0.2874, 0.6369], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8078,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8820, 0.9364, 0.0072, 0.9758, 0.9947], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9048, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5403,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9263, 0.9766, 0.0022, 0.9975, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0035, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1688,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8548, 0.9439, 0.0537, 0.9065, 0.9512], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9446,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9390, 0.9426, 0.0116, 0.9882, 0.9941], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-1.1576,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8974, 0.9513, 0.0070, 0.9926, 0.9967], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 84/5000 [00:12<11:57,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/5000, Train Loss: 0.0000, Val Loss: 0.0008\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6476,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6323e-01, 9.8891e-01, 9.6264e-04, 9.9888e-01, 9.9965e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4468, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3472,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9001, 0.9367, 0.0333, 0.9341, 0.9722], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2658, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0436, 0.5895, 0.5932, 0.3212, 0.6623], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6173, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7065,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.9077e-01, 9.9728e-01, 2.2790e-04, 9.9973e-01, 9.9992e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1593, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3585, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0632, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2313, 0.8153, 0.3224, 0.5464, 0.7951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.3316,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8977, 0.9373, 0.0348, 0.9321, 0.9709], device='mps:0')\n",
      "Epoch 84/5000, Train Loss: 0.0001, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8320,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8803, 0.9366, 0.0065, 0.9766, 0.9952], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0078, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2749, 0.8478, 0.2822, 0.5791, 0.8130], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4096, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0060, 0.2272, 0.8833, 0.0865, 0.3778], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 85/5000 [00:12<11:45,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2511, 0.8305, 0.3036, 0.5618, 0.8035], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3809,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8971, 0.9635, 0.0040, 0.9956, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2770,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8917, 0.9572, 0.0052, 0.9943, 0.9977], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6780, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7212,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8905, 0.9361, 0.0101, 0.9723, 0.9926], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8390, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2112,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.9538, 0.0062, 0.9934, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([-0.6294,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9034, 0.9357, 0.0137, 0.9678, 0.9898], device='mps:0')\n",
      "Epoch 85/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8407, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6372,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9589, 0.9876, 0.0011, 0.9987, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6061,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9470, 0.9837, 0.0015, 0.9983, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6978,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.8635e-01, 9.9596e-01, 3.3957e-04, 9.9960e-01, 9.9988e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7256, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5619,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9158, 0.9354, 0.0169, 0.9639, 0.9872], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2676, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0422, 0.5864, 0.5965, 0.3184, 0.6603], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8494, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9498, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 86/5000 [00:13<12:35,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1818,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8953, 0.9524, 0.0066, 0.9930, 0.9969], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.2580, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 86/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6104, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6814,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8956, 0.9359, 0.0116, 0.9704, 0.9915], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1229,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9014, 0.9498, 0.0076, 0.9921, 0.9964], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6554,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8994, 0.9358, 0.0126, 0.9692, 0.9907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1567,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8499, 0.9444, 0.0555, 0.9040, 0.9491], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2026, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0572, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4528, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0180, 0.0859, 0.9593, 0.0294, 0.1983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1974,  0.0000,  0.0000,  0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8941, 0.9532, 0.0064, 0.9932, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0658, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Shape of X_batch: torch.Size([120, 4])\n",
      "Shape of Y_batch: torch.Size([120, 5])\n",
      "Sample from X_batch: tensor([1.2754, 0.0000, 0.0000, 0.0000], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0211, 0.0171, 0.9921, 0.0056, 0.0552], device='mps:0')\n",
      "Epoch 87/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Early stopping triggered. Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_constraints(predictions, bounds):\n",
    "    # \"\"\"Checks if predictions satisfy the given bounds.\"\"\"\n",
    "    # for i, (lower, upper) in enumerate(bounds):\n",
    "    #     if not (torch.all(predictions[:, i] >= lower) and torch.all(predictions[:, i] <= upper)):\n",
    "    #         return False\n",
    "    return True\n",
    "\n",
    "max_retries = 1\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
    "    model.train()\n",
    "    train_loss = 0  # Track training loss for this epoch\n",
    "\n",
    "    # Inside the training\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        print(\"Shape of X_batch:\", X_batch.shape)\n",
    "        print(\"Shape of Y_batch:\", Y_batch.shape)\n",
    "        # Print the first few values to check their range\n",
    "        print(\"Sample from X_batch:\", X_batch[0])\n",
    "        print(\"Sample from Y_batch:\", Y_batch[0])\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(X_batch.to(device))\n",
    "        # batch_loss = compute_loss(predictions, Y_batch.to(device), bounds=bounds)\n",
    "        batch_loss = compute_loss(predictions, Y_batch.to(device), X_batch, 1e8)\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # Gradient clipping to avoid exploding gradients\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += batch_loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation step\n",
    "    current_val_loss = validate(model, val_loader, criterion, device)\n",
    "    # val_loss, violations = validate_and_check_constraints(model, val_loader, criterion, device, bounds)\n",
    "    # Print training and validation loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {current_val_loss:.4f}\")\n",
    "\n",
    "    # # Learning rate adjustment\n",
    "    # scheduler.step(current_val_loss)\n",
    "        \n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        early_stop_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        \n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered. Training complete.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022014221176505088"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_val_loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_6411/3831933047.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for inference\n",
    "model = BB84NN().to(device)\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluation and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predicted Parameters:\n",
      "Fiber Length 0.1 km -> [-0.01176502  0.07864589  1.5325282   0.00606263  0.21017846]\n",
      "Fiber Length 1.1 km -> [-0.01197466  0.07506268  1.5351577   0.0042819   0.20479673]\n",
      "Fiber Length 2.1 km -> [-0.01218727  0.07148459  1.5378349   0.00250106  0.19942799]\n",
      "Fiber Length 3.1 km -> [-1.2332678e-02  6.8181269e-02  1.5402308e+00  1.1092722e-03\n",
      "  1.9441044e-01]\n",
      "Fiber Length 4.1 km -> [-1.2478128e-02  6.4942844e-02  1.5425811e+00 -2.4916232e-04\n",
      "  1.8949771e-01]\n",
      "Fiber Length 5.1 km -> [-0.01261806  0.06173352  1.5449209  -0.0015945   0.18462339]\n",
      "Fiber Length 6.1 km -> [-0.0127532   0.05857014  1.5472367  -0.00292152  0.17981166]\n",
      "Fiber Length 7.1 km -> [-0.01277758  0.05582013  1.5496144  -0.00435607  0.17521739]\n",
      "Fiber Length 8.1 km -> [-0.01280499  0.05309974  1.5519772  -0.0057811   0.17067266]\n",
      "Fiber Length 9.1 km -> [-0.01251709  0.0506947   1.5545566  -0.00731084  0.16633087]\n",
      "Fiber Length 10.1 km -> [-0.0121723   0.04835087  1.5571711  -0.00884339  0.16207361]\n",
      "Fiber Length 11.1 km -> [-0.01181296  0.04602579  1.5597692  -0.0103533   0.15787077]\n",
      "Fiber Length 12.2 km -> [-0.01145882  0.04375501  1.5623441  -0.01183274  0.15377027]\n",
      "Fiber Length 13.2 km -> [-0.01111527  0.04153939  1.5648863  -0.01327807  0.14977086]\n",
      "Fiber Length 14.2 km -> [-0.01079542  0.03939935  1.5673633  -0.01467592  0.14591199]\n",
      "Fiber Length 15.2 km -> [-0.01049156  0.03733207  1.5697815  -0.0160272   0.14219946]\n",
      "Fiber Length 16.2 km -> [-0.01021817  0.03552065  1.5721211  -0.01715116  0.13881916]\n",
      "Fiber Length 17.2 km -> [-0.00997843  0.03406793  1.5743937  -0.01795585  0.13587168]\n",
      "Fiber Length 18.2 km -> [-0.00973888  0.03261574  1.5766659  -0.01876014  0.13292557]\n",
      "Fiber Length 19.2 km -> [-0.00950114  0.03117931  1.5789399  -0.01955827  0.13000658]\n",
      "Fiber Length 20.2 km -> [-0.00917131  0.03034396  1.5807915  -0.01991912  0.12775716]\n",
      "Fiber Length 21.2 km -> [-0.00866244  0.02960872  1.5825179  -0.02028027  0.1258474 ]\n",
      "Fiber Length 22.2 km -> [-0.00819097  0.02893782  1.584188   -0.02061441  0.12405407]\n",
      "Fiber Length 23.2 km -> [-0.00794149  0.02845187  1.5857131  -0.02094105  0.12238517]\n",
      "Fiber Length 24.2 km -> [-0.00772077  0.02797584  1.5871761  -0.0212711   0.12065218]\n",
      "Fiber Length 25.2 km -> [-0.00751747  0.02751889  1.5885987  -0.02159561  0.11897663]\n",
      "Fiber Length 26.2 km -> [-0.00726744  0.02709151  1.590102   -0.02187989  0.1173996 ]\n",
      "Fiber Length 27.2 km -> [-0.00702029  0.02666293  1.591605   -0.02216274  0.11584941]\n",
      "Fiber Length 28.2 km -> [-0.00677779  0.02624169  1.593092   -0.02243979  0.11432711]\n",
      "Fiber Length 29.2 km -> [-0.00654182  0.02586689  1.5945125  -0.02267887  0.11287978]\n",
      "Fiber Length 30.2 km -> [-0.00630031  0.02555195  1.5959184  -0.02284509  0.11149069]\n",
      "Fiber Length 31.2 km -> [-0.00600185  0.02511322  1.5974834  -0.02305486  0.1102713 ]\n",
      "Fiber Length 32.2 km -> [-0.00575275  0.024737    1.5989647  -0.02323809  0.10914867]\n",
      "Fiber Length 33.2 km -> [-0.00558207  0.02442279  1.600285   -0.02337641  0.10815299]\n",
      "Fiber Length 34.3 km -> [-0.00541508  0.02411835  1.601587   -0.02350911  0.10718981]\n",
      "Fiber Length 35.3 km -> [-0.00526042  0.02383569  1.6028807  -0.02364298  0.10623894]\n",
      "Fiber Length 36.3 km -> [-0.00511298  0.0235563   1.604172   -0.02377838  0.1052902 ]\n",
      "Fiber Length 37.3 km -> [-0.00497518  0.02328797  1.6054375  -0.02391294  0.10440203]\n",
      "Fiber Length 38.3 km -> [-0.00483423  0.02301939  1.6067185  -0.02405003  0.10353015]\n",
      "Fiber Length 39.3 km -> [-0.00470564  0.02275541  1.6079664  -0.02417904  0.10270507]\n",
      "Fiber Length 40.3 km -> [-0.00458609  0.02251033  1.6091812  -0.02428477  0.10196235]\n",
      "Fiber Length 41.3 km -> [-0.00446881  0.02227082  1.6103776  -0.02438512  0.1012379 ]\n",
      "Fiber Length 42.3 km -> [-0.00435349  0.02203517  1.611558   -0.02448449  0.10052165]\n",
      "Fiber Length 43.3 km -> [-0.0042407   0.02180587  1.6127241  -0.02458354  0.09982125]\n",
      "Fiber Length 44.3 km -> [-0.00413204  0.02159194  1.6138918  -0.02468173  0.09916199]\n",
      "Fiber Length 45.3 km -> [-0.00402959  0.02139153  1.615057   -0.02477764  0.09853376]\n",
      "Fiber Length 46.3 km -> [-0.00394405  0.0212058   1.6162169  -0.02487516  0.09794236]\n",
      "Fiber Length 47.3 km -> [-0.0038705   0.02101874  1.6173623  -0.02498244  0.09736986]\n",
      "Fiber Length 48.3 km -> [-0.00381763  0.0208567   1.618444   -0.02509123  0.0968523 ]\n",
      "Fiber Length 49.3 km -> [-0.00381267  0.02075961  1.6194713  -0.02519982  0.09649432]\n",
      "Fiber Length 50.3 km -> [-0.00380913  0.02066487  1.6205142  -0.0253064   0.09615307]\n",
      "Fiber Length 51.3 km -> [-0.00380547  0.02057815  1.621558   -0.02540126  0.09582631]\n",
      "Fiber Length 52.3 km -> [-0.00380065  0.02050014  1.6225886  -0.02548184  0.0955138 ]\n",
      "Fiber Length 53.3 km -> [-0.00379595  0.02042211  1.6236196  -0.02556247  0.09520146]\n",
      "Fiber Length 54.3 km -> [-0.0037898   0.02034475  1.6246531  -0.02564445  0.09489126]\n",
      "Fiber Length 55.3 km -> [-0.00378193  0.02026561  1.6257288  -0.02573141  0.09456951]\n",
      "Fiber Length 56.4 km -> [-0.00377073  0.02018555  1.6267285  -0.02581576  0.09423926]\n",
      "Fiber Length 57.4 km -> [-0.00376279  0.02010787  1.6277256  -0.02589909  0.09391927]\n",
      "Fiber Length 58.4 km -> [-0.00375721  0.0200373   1.6287231  -0.02597862  0.09363783]\n",
      "Fiber Length 59.4 km -> [-0.00375203  0.01996725  1.6297164  -0.026058    0.0933576 ]\n",
      "Fiber Length 60.4 km -> [-0.00374687  0.0198972   1.6307096  -0.02613735  0.09307749]\n",
      "Fiber Length 61.4 km -> [-0.00374047  0.01982713  1.6317008  -0.026214    0.09280876]\n",
      "Fiber Length 62.4 km -> [-0.00373459  0.01975887  1.6326954  -0.02628805  0.0925476 ]\n",
      "Fiber Length 63.4 km -> [-0.00372811  0.01969301  1.6336989  -0.02636252  0.09229494]\n",
      "Fiber Length 64.4 km -> [-0.0037226   0.01962971  1.6347001  -0.02643579  0.09204496]\n",
      "Fiber Length 65.4 km -> [-0.00372975  0.01960861  1.6356795  -0.02649013  0.0918688 ]\n",
      "Fiber Length 66.4 km -> [-0.00373796  0.01959032  1.6366491  -0.02654285  0.09170008]\n",
      "Fiber Length 67.4 km -> [-0.00374938  0.01957135  1.6376047  -0.0265926   0.09154222]\n",
      "Fiber Length 68.4 km -> [-0.00376514  0.01955086  1.6385598  -0.02664001  0.09139637]\n",
      "Fiber Length 69.4 km -> [-0.00377917  0.01953131  1.6394463  -0.02668376  0.09125463]\n",
      "Fiber Length 70.4 km -> [-0.00379132  0.01951284  1.6402545  -0.02672332  0.09111857]\n",
      "Fiber Length 71.4 km -> [-0.00380562  0.0194959   1.641068   -0.02676138  0.09099191]\n",
      "Fiber Length 72.4 km -> [-0.00383556  0.01949826  1.6418386  -0.02679505  0.09086641]\n",
      "Fiber Length 73.4 km -> [-0.00386781  0.01950281  1.642617   -0.02682898  0.09074333]\n",
      "Fiber Length 74.4 km -> [-0.00390016  0.01950737  1.6433976  -0.02686307  0.09062045]\n",
      "Fiber Length 75.4 km -> [-0.00393315  0.01951169  1.6441855  -0.02689759  0.09049808]\n",
      "Fiber Length 76.4 km -> [-0.0039662   0.01951597  1.6449757  -0.0269323   0.09037597]\n",
      "Fiber Length 77.4 km -> [-0.00399943  0.0195205   1.6457686  -0.02696709  0.09025415]\n",
      "Fiber Length 78.5 km -> [-0.00403606  0.01952768  1.6465521  -0.02700123  0.09014068]\n",
      "Fiber Length 79.5 km -> [-0.00407623  0.01953949  1.647325   -0.02703429  0.0900347 ]\n",
      "Fiber Length 80.5 km -> [-0.00412012  0.01955736  1.6481252  -0.02706701  0.08993805]\n",
      "Fiber Length 81.5 km -> [-0.0041686   0.01957871  1.6489663  -0.02710284  0.08985101]\n",
      "Fiber Length 82.5 km -> [-0.00421914  0.01960101  1.649826   -0.0271404   0.08976876]\n",
      "Fiber Length 83.5 km -> [-0.0042702   0.01962356  1.6506937  -0.02717827  0.08968727]\n",
      "Fiber Length 84.5 km -> [-0.00432114  0.01964614  1.6515613  -0.02721622  0.08960565]\n",
      "Fiber Length 85.5 km -> [-0.00437216  0.0196686   1.6524286  -0.02725415  0.08952414]\n",
      "Fiber Length 86.5 km -> [-0.00442313  0.01969123  1.653296   -0.02729204  0.08944254]\n",
      "Fiber Length 87.5 km -> [-0.00447416  0.01971395  1.6541634  -0.0273296   0.08936135]\n",
      "Fiber Length 88.5 km -> [-0.00452628  0.0197424   1.6550267  -0.02736127  0.08928711]\n",
      "Fiber Length 89.5 km -> [-0.00457913  0.01977123  1.655901   -0.02739358  0.08921549]\n",
      "Fiber Length 90.5 km -> [-0.00463535  0.01979716  1.6568182  -0.02742983  0.08915041]\n",
      "Fiber Length 91.5 km -> [-0.004692    0.0198213   1.6577406  -0.02746718  0.08908684]\n",
      "Fiber Length 92.5 km -> [-0.00474838  0.01984571  1.658659   -0.02750415  0.08902469]\n",
      "Fiber Length 93.5 km -> [-0.00480484  0.01986985  1.6595812  -0.02754135  0.08896258]\n",
      "Fiber Length 94.5 km -> [-0.0048613   0.01989402  1.6605046  -0.02757853  0.08890053]\n",
      "Fiber Length 95.5 km -> [-0.00491913  0.01991835  1.6614549  -0.02761711  0.08884018]\n",
      "Fiber Length 96.5 km -> [-0.00497715  0.0199422   1.662411   -0.02765603  0.08877937]\n",
      "Fiber Length 97.5 km -> [-0.00503573  0.01996664  1.6633594  -0.02769461  0.08871955]\n",
      "Fiber Length 98.5 km -> [-0.00509426  0.0199911   1.6643076  -0.0277331   0.08865977]\n",
      "Fiber Length 99.5 km -> [-0.00515283  0.02001548  1.665256   -0.0277717   0.08860002]\n"
     ]
    }
   ],
   "source": [
    "# # Load the trained model\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define fiber length range and fixed n_X value\n",
    "fiber_lengths = np.linspace(0.1, 200, 200)  # Fiber lengths from 0.1 km to 200 km\n",
    "P_dc_value = 6e-7  # Example value (adjust as needed)\n",
    "e_mis = 5e-3       # Example misalignment error (adjust as needed)\n",
    "target_nx = 1e8   # Fixed n_X value\n",
    "\n",
    "# Prepare inputs for the neural network\n",
    "predicted_params_list = []\n",
    "\n",
    "for L in fiber_lengths:\n",
    "    e_1 = L / 100  # Normalized fiber length\n",
    "    e_2 = -np.log10(P_dc_value)  # Dark count processing\n",
    "    e_3 = e_mis * 100  # Misalignment error\n",
    "    e_4 = np.log10(target_nx)  # Log-scaled detected events\n",
    "    \n",
    "    # Construct input tensor\n",
    "    X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        params = model(X).cpu().numpy()[0]\n",
    "        predicted_params_list.append(params)\n",
    "\n",
    "# Convert predicted parameters to numpy array\n",
    "predicted_params_array = np.array(predicted_params_list)\n",
    "\n",
    "# Display example predictions\n",
    "print(\"Example Predicted Parameters:\")\n",
    "for i in range(100):\n",
    "    print(f\"Fiber Length {fiber_lengths[i]:.1f} km -> {predicted_params_array[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_params = np.array([0.5728877, 0.38590422, 0.4298571, 0.49344626, 0.41347393])\n",
    "# test_params = [9.978331e-01, 9.870515e-01, 7.910872e-10, 1.000000e+00, 9.658825e-01]\n",
    "# L_test = 0.1  # Use a small fiber length\n",
    "\n",
    "# target_nx = float(target_nx)\n",
    "\n",
    "# key_rate_test = objective(\n",
    "#     test_params, L_test, target_nx,\n",
    "#     alpha=0.2, eta_Bob=0.1, P_dc_value=6e-7,\n",
    "#     epsilon_sec=1e-10, epsilon_cor=1e-15, f_EC=1.16,\n",
    "#     e_mis=5e-3, P_ap=4e-2, n_event=1\n",
    "# )[0]\n",
    "\n",
    "# print(f\"🔍 [DEBUG] Key Rate for L={L_test} km: {key_rate_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted_params_list)):\n",
    "    mu_1, mu_2, P_mu_1, P_mu_2, P_X = predicted_params_list[i]\n",
    "    \n",
    "    # Apply constraint corrections\n",
    "    # mu_3 = 2e-4\n",
    "    # P_mu_3 = max(1 - (P_mu_1 + P_mu_2), 1e-6)  # Ensure non-negative probability\n",
    "    # P_Z = max(1 - P_X, 1e-6)\n",
    "\n",
    "    # predicted_params_list[i] = [mu_1, mu_2, P_mu_1, P_mu_2, P_X, P_mu_3, P_Z]\n",
    "    predicted_params_list[i] = [mu_1, mu_2, P_mu_1, P_mu_2, P_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_6411/1396238752.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_6411/1396238752.py:54: RuntimeWarning: divide by zero encountered in log10\n",
      "  ax1.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_6411/1396238752.py:55: RuntimeWarning: invalid value encountered in log10\n",
      "  ax1.plot(fiber_lengths, np.log10(predicted_key_rates), 'r--', label=\"Predicted Key Rate (NN)\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from QKD_Functions.QKD_Functions import objective\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = BB84NN().to(device)\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"../Training_Data/single_nx/qkd_grouped_dataset_20250213_110036.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Select an n_X value\n",
    "target_nx = 1e8\n",
    "nx_key = str(float(target_nx))\n",
    "if nx_key not in dataset:\n",
    "    raise ValueError(f\"No data found for n_X = {target_nx}\")\n",
    "\n",
    "optimized_data = dataset[nx_key]\n",
    "\n",
    "# Extract fiber lengths, optimized key rates, and parameters\n",
    "fiber_lengths = np.array([entry[\"fiber_length\"] for entry in optimized_data])\n",
    "optimized_key_rates = np.array([entry[\"key_rate\"] for entry in optimized_data])\n",
    "optimized_params_array = np.array([list(entry[\"optimized_params\"].values()) for entry in optimized_data])\n",
    "\n",
    "# Predict parameters and key rates\n",
    "predicted_params_list = []\n",
    "predicted_key_rates = []\n",
    "for L in fiber_lengths:\n",
    "    e_1 = L / 100\n",
    "    e_2 = -np.log10(6e-7)\n",
    "    e_3 = 5e-3 * 100\n",
    "    e_4 = np.log10(target_nx)\n",
    "    X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        params = model(X).cpu().numpy()[0]\n",
    "        predicted_params_list.append(params)\n",
    "        key_rate = objective(params, L, target_nx, alpha=0.2, eta_Bob=0.1, P_dc_value=6e-7, epsilon_sec=1e-10, epsilon_cor=1e-15, f_EC=1.16, e_mis=5e-3, P_ap=4e-2, n_event=1)[0]\n",
    "        predicted_key_rates.append(key_rate)\n",
    "\n",
    "predicted_params_array = np.array(predicted_params_list)\n",
    "predicted_key_rates = np.array(predicted_key_rates)\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot key rates comparison on the left\n",
    "ax1.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
    "ax1.plot(fiber_lengths, np.log10(predicted_key_rates), 'r--', label=\"Predicted Key Rate (NN)\")\n",
    "ax1.set_title('Comparison of Key Rates')\n",
    "ax1.set_xlabel('Fiber Length (km)')\n",
    "ax1.set_ylabel('log10(Key Rate)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot parameters comparison on the right\n",
    "labels = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "for i in range(5):\n",
    "    ax2.plot(fiber_lengths, optimized_params_array[:, i], label=f'Optimized {labels[i]}', color=colors[i], linestyle='-')\n",
    "    ax2.plot(fiber_lengths, predicted_params_array[:, i], label=f'Predicted {labels[i]}', color=colors[i], linestyle='--')\n",
    "\n",
    "ax2.set_title('Comparison of Parameters')\n",
    "ax2.set_xlabel('Fiber Length (km)')\n",
    "ax2.set_ylabel('Parameter Values')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# from QKD_Functions.QKD_Functions import objective\n",
    "\n",
    "# # ✅ Load the trained model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = BB84NN().to(device)\n",
    "# checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "# model.load_state_dict(checkpoint)\n",
    "# model.eval()\n",
    "\n",
    "# # ✅ Load the dataset with optimized key rates\n",
    "# with open(\"../Training_Data/qkd_grouped_dataset_20250206_173005.json\", 'r') as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# # ✅ Select an n_X value to compare (change as needed)\n",
    "# target_nx = 1e6  # Adjust as needed\n",
    "# nx_key = str(float(target_nx))\n",
    "\n",
    "# if nx_key not in dataset:\n",
    "#     raise ValueError(f\"No data found for n_X = {target_nx}\")\n",
    "\n",
    "# optimized_data = dataset[nx_key]  # Extract data for the selected n_X\n",
    "\n",
    "# # ✅ Extract fiber lengths and optimized key rates\n",
    "# fiber_lengths = np.array([entry[\"fiber_length\"] for entry in optimized_data])\n",
    "# optimized_key_rates = np.array([entry[\"key_rate\"] for entry in optimized_data])\n",
    "\n",
    "# # ✅ Predict parameters using the trained model\n",
    "# predicted_params_list = []\n",
    "# predicted_key_rates = []\n",
    "\n",
    "# for L in fiber_lengths:\n",
    "#     e_1 = L / 100  # Normalized fiber length\n",
    "#     e_2 = -np.log10(6e-7)  # Dark count processing (P_dc_value = 6e-7)\n",
    "#     e_3 = 5e-3 * 100  # Misalignment error\n",
    "#     e_4 = np.log10(target_nx)  # Log-transformed detected events\n",
    "\n",
    "#     # Construct input tensor\n",
    "#     X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "\n",
    "#     # Perform prediction\n",
    "#     with torch.no_grad():\n",
    "#         params = model(X).cpu().numpy()[0]\n",
    "#         predicted_params_list.append(params)\n",
    "\n",
    "#     # ✅ Calculate key rate using objective function\n",
    "#     key_rate = objective(\n",
    "#         params,  # Predicted parameters\n",
    "#         L,       # Current fiber length\n",
    "#         target_nx,\n",
    "#         alpha=0.2, eta_Bob=0.1, P_dc_value=6e-7,\n",
    "#         epsilon_sec=1e-10, epsilon_cor=1e-15, f_EC=1.16,\n",
    "#         e_mis=5e-3, P_ap=4e-2, n_event=1\n",
    "#     )[0]  # Extract key rate from the objective output\n",
    "\n",
    "#     predicted_key_rates.append(key_rate)\n",
    "\n",
    "# # ✅ Convert predicted key rates to numpy array\n",
    "# predicted_key_rates = np.array(predicted_key_rates)\n",
    "\n",
    "# # ✅ Plot the comparison\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plt.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
    "# plt.plot(fiber_lengths, np.log10(predicted_key_rates), 'r:', label=\"Predicted Key Rate (NN)\")\n",
    "\n",
    "# plt.xlabel(\"Fiber Length (km)\")\n",
    "# plt.ylabel(\"log10(Key Rate)\")\n",
    "# plt.title(f\"Comparison of Key Rates (n_X = {target_nx:.0e})\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # ✅ Print sample values for debugging\n",
    "# print(\"\\nSample Comparison:\")\n",
    "# print(\"Fiber Length | Optimized Key Rate | Predicted Key Rate\")\n",
    "# print(\"-\" * 60)\n",
    "# for i in range(0, len(fiber_lengths), max(len(fiber_lengths)//10, 1)):  # Print 10 evenly spaced samples\n",
    "#     print(f\"{fiber_lengths[i]:10.2f} km | {optimized_key_rates[i]:.2e} | {predicted_key_rates[i]:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_for_nx(data, target_nx):\n",
    "#     \"\"\"\n",
    "#     Plot results for a specific n_X value, filtering out zero key rates.\n",
    "#     \"\"\"\n",
    "#     # Convert to string for dictionary key lookup\n",
    "#     target_nx_str = str(float(target_nx))  # Ensure it matches JSON key format\n",
    "\n",
    "#     # Retrieve data correctly from grouped dictionary\n",
    "#     if target_nx_str not in data:\n",
    "#         print(f\"No data found for n_X = {target_nx}\")\n",
    "#         return\n",
    "    \n",
    "#     filtered_data = data[target_nx_str]  # Get the list of entries\n",
    "    \n",
    "#     # Filter out key rates that are zero or too small\n",
    "#     filtered_data = [entry for entry in filtered_data if entry[\"key_rate\"] > 1e-30]  # Adjust threshold if needed\n",
    "\n",
    "#     if not filtered_data:\n",
    "#         print(f\"No non-zero key rates found for n_X = {target_nx}\")\n",
    "#         return\n",
    "\n",
    "#     # Extract data\n",
    "#     fiber_lengths = [entry[\"fiber_length\"] for entry in filtered_data]\n",
    "#     key_rates = [entry[\"key_rate\"] for entry in filtered_data]\n",
    "\n",
    "#     # ✅ Improved visualization\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "    \n",
    "#     # ✅ Key Rate vs Fiber Length\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(fiber_lengths, np.log10(key_rates), linestyle='-', color='b', label=\"Key Rate\")\n",
    "#     plt.xlabel(\"Fiber Length (km)\")\n",
    "#     plt.ylabel(\"log10(Key Rate)\")\n",
    "#     plt.title(f\"Key Rate vs Fiber Length (n_X = {target_nx:.0e})\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     # ✅ Optimized Parameters vs Fiber Length\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     params_names = list(filtered_data[0][\"optimized_params\"].keys())\n",
    "#     for param_name in params_names:\n",
    "#         params_values = [entry[\"optimized_params\"][param_name] for entry in filtered_data]\n",
    "#         plt.plot(fiber_lengths, params_values, linestyle='-', label=param_name)\n",
    "    \n",
    "#     plt.xlabel(\"Fiber Length (km)\")\n",
    "#     plt.ylabel(\"Parameter Value\")\n",
    "#     plt.title(f\"Optimized Parameters vs Fiber Length (n_X = {target_nx:.0e})\")\n",
    "#     plt.legend()\n",
    "#     plt.ylim(0.0, 1.0)\n",
    "#     plt.yticks(np.arange(0.0, 1.05, 0.05))\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"qkd_results_nx_{target_nx:.0e}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "# with open(\"../Training_Data/qkd_grouped_dataset_20250206_173005.json\", 'r') as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# # Print available n_X values\n",
    "# print(\"Available n_X values:\", list(dataset.keys())[:5])  # Print first 5 unique n_X values\n",
    "\n",
    "# # List of n_X values to plot\n",
    "# n_X_values = [10**s for s in range(4, 10)]  # Generates [10^4, 10^5, ..., 10^9]\n",
    "\n",
    "# # Loop through n_X values and plot\n",
    "# for n_X in n_X_values:\n",
    "#     print(f\"\\nPlotting results for n_X = {n_X:.0e}\")\n",
    "#     plot_for_nx(dataset, n_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_83114/1342507189.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No data found for n_X = 100000000.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m nx_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(target_nx))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nx_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found for n_X = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_nx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m optimized_data \u001b[38;5;241m=\u001b[39m dataset[nx_key]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Extract fiber lengths and optimized parameters\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: No data found for n_X = 100000000.0"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from QKD_Functions.QKD_Functions import objective\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")  # Adjust based on your device\n",
    "\n",
    "model = BB84NN().to(device)\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load the dataset with optimized key rates and parameters\n",
    "with open(\"../Training_Data/qkd_grouped_dataset_20250206_173005.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Select an n_X value to compare\n",
    "target_nx = 1e8\n",
    "nx_key = str(float(target_nx))\n",
    "\n",
    "if nx_key not in dataset:\n",
    "    raise ValueError(f\"No data found for n_X = {target_nx}\")\n",
    "\n",
    "optimized_data = dataset[nx_key]\n",
    "\n",
    "# Extract fiber lengths and optimized parameters\n",
    "fiber_lengths = np.array([entry[\"fiber_length\"] for entry in optimized_data])\n",
    "optimized_params_array = np.array([list(entry[\"optimized_params\"].values()) for entry in optimized_data])\n",
    "\n",
    "# Predict parameters using the trained model\n",
    "predicted_params_list = []\n",
    "for L in fiber_lengths:\n",
    "    e_1 = L / 100  # Normalized fiber length\n",
    "    e_2 = -np.log10(6e-7)  # Dark count processing\n",
    "    e_3 = 5e-3 * 100  # Misalignment error\n",
    "    e_4 = np.log10(target_nx)  # Log-transformed detected events\n",
    "\n",
    "    X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        params = model(X).cpu().numpy()[0]\n",
    "        predicted_params_list.append(params)\n",
    "\n",
    "predicted_params_array = np.array(predicted_params_list)\n",
    "\n",
    "# Plotting both optimized and predicted parameters\n",
    "plt.figure(figsize=(14, 10))\n",
    "labels = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(fiber_lengths, optimized_params_array[:, i], label=f'Optimized {labels[i]}', linestyle='-', markersize=4)\n",
    "    plt.plot(fiber_lengths, predicted_params_array[:, i], label=f'Predicted {labels[i]}', linestyle='--', markersize=4)\n",
    "\n",
    "plt.title('Comparison of Optimized and Predicted Parameters')\n",
    "plt.xlabel('Fiber Length (km)')\n",
    "plt.ylabel('Parameter Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(predicted_params_list)):\n",
    "#     mu_1, mu_2, P_mu_1, P_mu_2, P_X = predicted_params_list[i]\n",
    "\n",
    "#     # Fixed mu_3 value\n",
    "#     mu_3 = 2e-4  # Given constant\n",
    "\n",
    "#     # Ensure constraints are met:\n",
    "#     if mu_1 <= mu_2 + mu_3:\n",
    "#         mu_1 = mu_2 + mu_3 + 1e-6  # Adjust to satisfy condition\n",
    "    \n",
    "#     if mu_2 / mu_1 >= 1:\n",
    "#         mu_2 = 0.99 * mu_1  # Slightly reduce mu_2 to satisfy ratio condition\n",
    "\n",
    "#     P_mu_3 = max(1 - (P_mu_1 + P_mu_2), 1e-6)  # Ensure P_mu_3 > 0\n",
    "#     P_Z = max(1 - P_X, 1e-6)  # Ensure non-negative probability\n",
    "\n",
    "#     # Re-apply constraints for consistency\n",
    "#     if P_mu_1 + P_mu_2 + P_mu_3 > 1:\n",
    "#         P_mu_1 /= (P_mu_1 + P_mu_2 + P_mu_3)\n",
    "#         P_mu_2 /= (P_mu_1 + P_mu_2 + P_mu_3)\n",
    "#         P_mu_3 = 1 - P_mu_1 - P_mu_2  # Adjusted sum exactly to 1\n",
    "\n",
    "#     if mu_2 <= mu_3:\n",
    "#         mu_2 = mu_3 + 1e-6  # Ensure mu_2 > mu_3\n",
    "\n",
    "#     # Store corrected parameters\n",
    "#     predicted_params_list[i] = [mu_1, mu_2, P_mu_1, P_mu_2, P_X, P_mu_3, P_Z]\n",
    "\n",
    "# print(\"✅ Constraints have been enforced on all predicted parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# from QKD_Functions.QKD_Functions import objective\n",
    "\n",
    "# # ✅ Load the trained model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = BB84NN().to(device)\n",
    "# checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "# model.load_state_dict(checkpoint)\n",
    "# model.eval()\n",
    "\n",
    "# # ✅ Load the dataset with optimized key rates\n",
    "# with open(\"../Training_Data/qkd_grouped_dataset_20250206_173005.json\", 'r') as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# # ✅ Select an n_X value to compare (change as needed)\n",
    "# target_nx = 1e6  # Adjust as needed\n",
    "# nx_key = str(float(target_nx))\n",
    "\n",
    "# if nx_key not in dataset:\n",
    "#     raise ValueError(f\"No data found for n_X = {target_nx}\")\n",
    "\n",
    "# optimized_data = dataset[nx_key]  # Extract data for the selected n_X\n",
    "\n",
    "# # ✅ Extract fiber lengths and optimized key rates\n",
    "# fiber_lengths = np.array([entry[\"fiber_length\"] for entry in optimized_data])\n",
    "# optimized_key_rates = np.array([entry[\"key_rate\"] for entry in optimized_data])\n",
    "\n",
    "# # ✅ Predict parameters using the trained model\n",
    "# predicted_params_list = []\n",
    "# predicted_key_rates = []\n",
    "\n",
    "# for L in fiber_lengths:\n",
    "#     e_1 = L / 100  # Normalized fiber length\n",
    "#     e_2 = -np.log10(6e-7)  # Dark count processing (P_dc_value = 6e-7)\n",
    "#     e_3 = 5e-3 * 100  # Misalignment error\n",
    "#     e_4 = np.log10(target_nx)  # Log-transformed detected events\n",
    "\n",
    "#     # Construct input tensor\n",
    "#     X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "\n",
    "#     # Perform prediction\n",
    "#     with torch.no_grad():\n",
    "#         params = model(X).cpu().numpy()[0]\n",
    "#         predicted_params_list.append(params)\n",
    "\n",
    "#     # ✅ Calculate key rate using objective function\n",
    "#     key_rate = objective(\n",
    "#         params,  # Predicted parameters\n",
    "#         L,       # Current fiber length\n",
    "#         target_nx,\n",
    "#         alpha=0.2, eta_Bob=0.1, P_dc_value=6e-7,\n",
    "#         epsilon_sec=1e-10, epsilon_cor=1e-15, f_EC=1.16,\n",
    "#         e_mis=5e-3, P_ap=4e-2, n_event=1\n",
    "#     )[0]  # Extract key rate from the objective output\n",
    "\n",
    "#     predicted_key_rates.append(key_rate)\n",
    "\n",
    "# # ✅ Convert predicted key rates to numpy array\n",
    "# predicted_key_rates = np.array(predicted_key_rates)\n",
    "\n",
    "# # ✅ Plot the comparison\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plt.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
    "# plt.plot(fiber_lengths, np.log10(predicted_key_rates), 'r:', label=\"Predicted Key Rate (NN)\")\n",
    "\n",
    "# plt.xlabel(\"Fiber Length (km)\")\n",
    "# plt.ylabel(\"log10(Key Rate)\")\n",
    "# plt.title(f\"Comparison of Key Rates (n_X = {target_nx:.0e})\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # ✅ Print sample values for debugging\n",
    "# print(\"\\nSample Comparison:\")\n",
    "# print(\"Fiber Length | Optimized Key Rate | Predicted Key Rate\")\n",
    "# print(\"-\" * 60)\n",
    "# for i in range(0, len(fiber_lengths), max(len(fiber_lengths)//10, 1)):  # Print 10 evenly spaced samples\n",
    "#     print(f\"{fiber_lengths[i]:10.2f} km | {optimized_key_rates[i]:.2e} | {predicted_key_rates[i]:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#     # Store all results\n",
    "#     predicted_key_rates.append(penalized_key_rate)\n",
    "#     eta_ch_list.append(eta_ch)\n",
    "#     S_X_0_list.append(S_X_0)\n",
    "#     S_Z_0_list.append(S_Z_0)\n",
    "#     S_X_1_list.append(S_X_1)\n",
    "#     S_Z_1_list.append(S_Z_1)\n",
    "#     tau_0_list.append(tau_0)\n",
    "#     tau_1_list.append(tau_1)\n",
    "#     e_mu_k_list.append(e_mu_k)\n",
    "#     e_obs_X_list.append(e_obs_X)\n",
    "#     v_Z_1_list.append(v_Z_1)\n",
    "#     gamma_list.append(gamma)\n",
    "#     Phi_X_list.append(Phi_X)\n",
    "#     binary_entropy_Phi_list.append(binary_entropy_Phi)\n",
    "#     lambda_EC_list.append(lambda_EC)\n",
    "#     l_calculated_list.append(l_calculated)\n",
    "\n",
    "# # Convert to numpy arrays\n",
    "# predicted_params_array = np.array(predicted_params_list)\n",
    "\n",
    "# # Create multiple subplots for all the metrics\n",
    "# plt.figure(figsize=(20, 25))\n",
    "\n",
    "# # Plot 1: Key Rate\n",
    "# plt.subplot(5, 2, 1)\n",
    "# plt.plot(fiber_lengths, predicted_key_rates, 'b-', label='Key Rate')\n",
    "# plt.xlabel('Fiber Length (km)')\n",
    "# plt.ylabel('Key Rate')\n",
    "# plt.yscale('log')\n",
    "# plt.title('Predicted Key Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot 2: Parameters\n",
    "# plt.subplot(5, 2, 2)\n",
    "# param_names = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X_value']\n",
    "# for i in range(5):\n",
    "#     plt.plot(fiber_lengths, predicted_params_array[:, i], label=param_names[i])\n",
    "# plt.xlabel('Fiber Length (km)')\n",
    "# plt.ylabel('Parameter Value')\n",
    "# plt.title('Predicted Parameters')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot additional metrics\n",
    "# metrics = [\n",
    "#     (eta_ch_list, 'Channel Transmittance'),\n",
    "#     (S_X_0_list, 'S_X_0'),\n",
    "#     (S_Z_0_list, 'S_Z_0'),\n",
    "#     (tau_0_list, 'tau_0'),\n",
    "#     (e_obs_X_list, 'e_obs_X'),\n",
    "#     (v_Z_1_list, 'v_Z_1'),\n",
    "#     (gamma_list, 'gamma'),\n",
    "#     (l_calculated_list, 'l_calculated')\n",
    "# ]\n",
    "\n",
    "# for i, (metric, title) in enumerate(metrics, 3):\n",
    "#     plt.subplot(5, 2, i)\n",
    "#     plt.plot(fiber_lengths, metric, 'g-')\n",
    "#     plt.xlabel('Fiber Length (km)')\n",
    "#     plt.ylabel(title)\n",
    "#     plt.title(title)\n",
    "#     plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('comprehensive_predictions_nx_1e12.png')\n",
    "# plt.show()\n",
    "\n",
    "# # Print some values at specific distances\n",
    "# distances = [0,20, 40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "# print(\"\\nPredicted Values at Specific Distances:\")\n",
    "# print(\"Distance (km) | Key Rate | eta_ch | S_X_0 | e_obs_X\")\n",
    "# print(\"-\" * 60)\n",
    "# for d in distances:\n",
    "#     idx = np.abs(fiber_lengths - d).argmin()\n",
    "#     print(f\"{d:11.0f} | {predicted_key_rates[idx]:8.2e} | {eta_ch_list[idx]:6.4f} | {S_X_0_list[idx]:6.4f} | {e_obs_X_list[idx]:6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at a small number of predictions and comparing them with the ground truth, verify if the network is producing reasonable outputs (e.g., no extreme or unrealistic values). \n",
    "\n",
    "\n",
    "If the predictions look incorrect (e.g., constant values, extreme outliers, or all zeros), adjust the training process accordingly.\n",
    "\n",
    "\n",
    "\t1.\tsample_predictions:\n",
    "\t•\tThis contains the predictions for the first 10 samples from the validation dataset (X_val[:10]).\n",
    "\t•\tIt helps seeing the model’s behavior for a subset of the data.\n",
    "\t2.\tY_val[:10]:\n",
    "\t•\tGround truth values corresponding to the same subset.\n",
    "\t3.\tWhy Add This?\n",
    "\t•\tIf the predictions are drastically different from the ground truth or have unexpected behavior (e.g., constant predictions, all zeros, or extreme values), it can indicate issues in:\n",
    "\t•\tNetwork architecture.\n",
    "\t•\tData preprocessing (e.g., scaling).\n",
    "\t•\tTraining process (e.g., learning rate, exploding gradients).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from QKD_Functions.QKD_Functions import objective  # Make sure this is imported\n",
    "\n",
    "# # Load the trained model correctly\n",
    "# model = BB84NN().to(device)\n",
    "# checkpoint = torch.load('best_model.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.eval()\n",
    "\n",
    "# # Fixed parameters for key rate calculation\n",
    "# alpha = 0.2\n",
    "# eta_Bob = 0.1\n",
    "# P_dc_value = 6e-7\n",
    "# epsilon_sec = 1e-10\n",
    "# epsilon_cor = 1e-15\n",
    "# f_EC = 1.16\n",
    "# e_mis = 5e-3\n",
    "# P_ap = 4e-2\n",
    "# n_event = 1\n",
    "\n",
    "# # Set n_X = 10^12\n",
    "# target_nx = 1e12\n",
    "# e_4 = np.log10(target_nx)\n",
    "\n",
    "# # Generate fiber lengths\n",
    "# fiber_lengths = np.linspace(0.1, 200, 1000)\n",
    "\n",
    "# # Lists to store results\n",
    "# predicted_key_rates = []\n",
    "# predicted_params_list = []\n",
    "\n",
    "# # For each fiber length\n",
    "# for L in fiber_lengths:\n",
    "#     # Prepare input for neural network\n",
    "#     e_1 = L / 100\n",
    "#     e_2 = -np.log10(P_dc_value)\n",
    "#     e_3 = e_mis * 100\n",
    "    \n",
    "#     # Neural network input\n",
    "#     X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "#     # Get predicted parameters\n",
    "#     with torch.no_grad():\n",
    "#         params = model(X).cpu().numpy()[0]\n",
    "#         predicted_params_list.append(params)\n",
    "    \n",
    "#     # Calculate key rate using the objective function\n",
    "#     key_rate = objective(\n",
    "#         params,  # predicted parameters\n",
    "#         L,       # current fiber length\n",
    "#         target_nx,\n",
    "#         alpha, eta_Bob, P_dc_value, \n",
    "#         epsilon_sec, epsilon_cor, f_EC, \n",
    "#         e_mis, P_ap, n_event\n",
    "#     )[0]  # Get first element which is the key rate\n",
    "    \n",
    "#     predicted_key_rates.append(key_rate)\n",
    "\n",
    "# # Convert to numpy arrays\n",
    "# predicted_params_array = np.array(predicted_params_list)\n",
    "# predicted_key_rates = np.array(predicted_key_rates)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# # Plot 1: Key Rate\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(fiber_lengths, predicted_key_rates, 'b-', label='Predicted Key Rate')\n",
    "# plt.xlabel('Fiber Length (km)', fontsize=14)\n",
    "# plt.ylabel('Key Rate', fontsize=14)\n",
    "# plt.title(f'Predicted Key Rate for n_X = {target_nx:.0e}', fontsize=16)\n",
    "# plt.yscale('log')\n",
    "# plt.ylim(1e-11, 1e-6)\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot 2: Parameters\n",
    "# plt.subplot(2, 1, 2)\n",
    "# param_names = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X_value']\n",
    "# for i in range(5):\n",
    "#     plt.plot(fiber_lengths, predicted_params_array[:, i], label=param_names[i])\n",
    "# plt.xlabel('Fiber Length (km)', fontsize=14)\n",
    "# plt.ylabel('Parameter Value', fontsize=14)\n",
    "# plt.title('Predicted Parameters vs Fiber Length', fontsize=16)\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('predictions_nx_1e12.png')\n",
    "# plt.show()\n",
    "\n",
    "# # Print some values at specific distances\n",
    "# distances = [0, 50, 100, 150, 200]\n",
    "# print(\"\\nPredicted Values at Specific Distances:\")\n",
    "# print(\"Distance (km) |    mu_1    |    mu_2    |   P_mu_1   |   P_mu_2   | P_X_value  | Key Rate\")\n",
    "# print(\"-\" * 95)\n",
    "# for d in distances:\n",
    "#     idx = np.abs(fiber_lengths - d).argmin()\n",
    "#     params = predicted_params_array[idx]\n",
    "#     key_rate = predicted_key_rates[idx]\n",
    "#     print(f\"{d:11.0f} | {params[0]:9.6f} | {params[1]:9.6f} | {params[2]:9.6f} | {params[3]:9.6f} | {params[4]:9.6f} | {key_rate:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# # from QKD_Functions.QKD_Functions import compute_loss, objective  # Ensure this is imported correctly\n",
    "\n",
    "# def compute_loss(predictions, targets, bounds):\n",
    "#     # Calculate standard loss (e.g., MSE)\n",
    "#     loss = criterion(predictions, targets)\n",
    "    \n",
    "#     # Add penalties for out-of-bounds predictions\n",
    "#     lower_penalties = torch.sum(torch.relu(1e-4 - predictions[:, :2]))  # For mu_1 and mu_2\n",
    "#     upper_penalties = torch.sum(torch.relu(predictions - 1))            # For mu_1 and mu_2\n",
    "#     loss += 0.1 * (lower_penalties + upper_penalties)\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "# # Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Fixed parameters\n",
    "# alpha = 0.2\n",
    "# eta_Bob = 0.1\n",
    "# P_dc_value = 6e-7\n",
    "# epsilon_sec = 1e-10\n",
    "# epsilon_cor = 1e-15\n",
    "# f_EC = 1.16\n",
    "# e_mis = 5e-3\n",
    "# P_ap = 4e-2\n",
    "# n_event = 1\n",
    "\n",
    "# # Define the model architecture (ensure this is correctly defined)\n",
    "# class BB84NN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BB84NN, self).__init__()\n",
    "#         # Example layers, adjust as needed\n",
    "#         self.fc1 = torch.nn.Linear(4, 64)\n",
    "#         self.fc2 = torch.nn.Linear(64, 32)\n",
    "#         self.fc3 = torch.nn.Linear(32, 5)  # Assuming 5 parameters to predict\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         return self.fc3(x)\n",
    "\n",
    "# # Initialize the model and move it to the device\n",
    "# model = BB84NN().to(device)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = compute_loss  # Custom loss function\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# grad_clip_norm = 1.0\n",
    "\n",
    "# # Load training data (ensure this is correctly loaded)\n",
    "# X_train, Y_train = load_training_data()  # Implement this function\n",
    "# X_val, Y_val = load_validation_data()    # Implement this function\n",
    "\n",
    "# # Data preprocessing\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_Y = MinMaxScaler()\n",
    "\n",
    "# X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "# Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "# Y_val_scaled = scaler_Y.transform(Y_val)\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32), \n",
    "#                                                torch.tensor(Y_train_scaled, dtype=torch.float32))\n",
    "# val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val_scaled, dtype=torch.float32), \n",
    "#                                              torch.tensor(Y_val_scaled, dtype=torch.float32))\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 1000\n",
    "# patience = 20\n",
    "# best_val_loss = float('inf')\n",
    "# no_improvement_count = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "    \n",
    "#     for batch_X, batch_Y in train_loader:\n",
    "#         batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = criterion(outputs, batch_Y)\n",
    "        \n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss += loss.item()\n",
    "    \n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "    \n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_X, batch_Y in val_loader:\n",
    "#             batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "            \n",
    "#             outputs = model(batch_X)\n",
    "#             loss = criterion(outputs, batch_Y)\n",
    "            \n",
    "#             val_loss += loss.item()\n",
    "    \n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         no_improvement_count = 0\n",
    "        \n",
    "#         # Save the model\n",
    "#         torch.save({\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict()\n",
    "#         }, 'best_model.pth')\n",
    "#     else:\n",
    "#         no_improvement_count += 1\n",
    "#         if no_improvement_count >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # Load the best model for evaluation\n",
    "# model = BB84NN().to(device)\n",
    "# checkpoint = torch.load('best_model.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.eval()\n",
    "\n",
    "# # Define fiber length range and fixed n_X value\n",
    "# fiber_lengths = np.linspace(0.1, 200, 1000)  # Fiber lengths from 0.1 km to 200 km\n",
    "# target_nx = 1e13  # Fixed n_X value\n",
    "\n",
    "# # Prepare inputs for the neural network\n",
    "# predicted_params_list = []\n",
    "# predicted_key_rates = []\n",
    "\n",
    "# for L in fiber_lengths:\n",
    "#     e_1 = L / 100  # Normalized fiber length\n",
    "#     e_2 = -np.log10(P_dc_value)  # Dark count processing\n",
    "#     e_3 = e_mis * 100  # Misalignment error\n",
    "#     e_4 = np.log10(target_nx)  # Log-scaled detected events\n",
    "    \n",
    "#     # Construct input tensor\n",
    "#     X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "#     # Perform prediction\n",
    "#     with torch.no_grad():\n",
    "#         params = model(X).cpu().numpy()[0]\n",
    "#         predicted_params_list.append(params)\n",
    "    \n",
    "#     # Calculate all values using objective function\n",
    "#     result = objective(\n",
    "#         params,  # predicted parameters\n",
    "#         L,       # current fiber length\n",
    "#         target_nx,\n",
    "#         alpha, eta_Bob, P_dc_value, \n",
    "#         epsilon_sec, epsilon_cor, f_EC, \n",
    "#         e_mis, P_ap, n_event\n",
    "#     )\n",
    "    \n",
    "#     # Unpack all results\n",
    "#     (penalized_key_rate, eta_ch, S_X_0, S_Z_0, S_X_1, S_Z_1, \n",
    "#      tau_0, tau_1, e_mu_k, e_obs_X, v_Z_1, gamma, Phi_X,\n",
    "#      binary_entropy_Phi, lambda_EC, l_calculated) = result\n",
    "    \n",
    "#     # Store all results\n",
    "#     predicted_key_rates.append(penalized_key_rate)\n",
    "\n",
    "# # Convert predicted parameters to numpy array\n",
    "# predicted_params_array = np.array(predicted_params_list)\n",
    "# predicted_key_rates_array = np.array(predicted_key_rates)\n",
    "\n",
    "# # Sample predictions for verification\n",
    "# sample_predictions = scaler_Y.inverse_transform(model(torch.tensor(X_val_scaled[:10], dtype=torch.float32).to(device)).cpu().numpy())\n",
    "# ground_truth = scaler_Y.inverse_transform(Y_val_scaled[:10])\n",
    "\n",
    "# print(\"Sample Predictions:\\n\", sample_predictions)\n",
    "# print(\"Ground Truth:\\n\", ground_truth)\n",
    "\n",
    "# # Plotting (optional)\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(fiber_lengths, predicted_key_rates_array, label='Predicted Key Rate')\n",
    "# plt.xlabel('Fiber Length (km)')\n",
    "# plt.ylabel('Key Rate')\n",
    "# plt.title('Predicted Key Rate vs Fiber Length')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Load and Plot Dataset\n",
    "# def plot_for_nx(data, target_nx):\n",
    "#     \"\"\"\n",
    "#     Plot results for a specific n_X value\n",
    "#     \"\"\"\n",
    "#     # Convert target_nx to string for dictionary key\n",
    "#     nx_key = str(float(target_nx))\n",
    "    \n",
    "#     if nx_key not in data:\n",
    "#         print(f\"No data found for n_X = {target_nx}\")\n",
    "#         return\n",
    "        \n",
    "#     filtered_data = data[nx_key]\n",
    "    \n",
    "#     if not filtered_data:\n",
    "#         print(f\"No valid results for n_X = {target_nx}\")\n",
    "#         return\n",
    "    \n",
    "#     # Extract data\n",
    "#     fiber_lengths = [entry[\"fiber_length\"] for entry in filtered_data]\n",
    "#     key_rates = [entry[\"key_rate\"] for entry in filtered_data]\n",
    "    \n",
    "#     # Create figure\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "    \n",
    "#     # Plot key rates\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(fiber_lengths, np.log10([max(kr, 1e-30) for kr in key_rates]))\n",
    "#     plt.xlabel(\"Fiber Length (km)\")\n",
    "#     plt.ylabel(\"log10(Key Rate)\")\n",
    "#     plt.title(f\"Key Rate vs Fiber Length (n_X = {target_nx:.0e})\")\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     # Plot parameters\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     params = [\"mu_1\", \"mu_2\", \"P_mu_1\", \"P_mu_2\", \"P_X_value\"]\n",
    "#     for param in params:\n",
    "#         values = [entry[\"optimized_params\"][param] for entry in filtered_data]\n",
    "#         plt.plot(fiber_lengths, values, label=param)\n",
    "    \n",
    "#     plt.xlabel(\"Fiber Length (km)\")\n",
    "#     plt.ylabel(\"Parameter Value\")\n",
    "#     plt.title(f\"Optimized Parameters (n_X = {target_nx:.0e})\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"qkd_results_nx_{target_nx:.0e}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "#     plt.show()\n",
    "\n",
    "# # # Load the saved dataset\n",
    "# # with open(\"qkd_dataset_high_nx.json\", 'r') as f:\n",
    "# #     dataset = json.load(f)\n",
    "\n",
    "# # Load the saved dataset\n",
    "# with open(\"../Training_Data/qkd_dataset_comprehensive_20250122_004748.json\", 'r') as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# # Plot results for each n_X value\n",
    "# for nx in [10**s for s in range(11, 15, 1)]:\n",
    "#     print(f\"\\nPlotting results for n_X = {nx:.0e}\")\n",
    "#     plot_for_nx(dataset, nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter data for specific n_X (10^12)\n",
    "with open(\"../Training_Data/qkd_dataset_comprehensive_20250122_004740.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "target_nx = \"1e8\"  # or \"1000000000000.0\" depending on your data format\n",
    "filtered_data = []\n",
    "\n",
    "# Handle the dictionary structure where n_X values are keys\n",
    "if isinstance(dataset, dict):\n",
    "    # Get data for specific n_X\n",
    "    for n_x_key, entries in dataset.items():\n",
    "        if float(n_x_key) == 1e12:  # Check for 10^12\n",
    "            filtered_data.extend(entries)\n",
    "\n",
    "print(f\"Number of entries for n_X = 10^12: {len(filtered_data)}\")\n",
    "\n",
    "# Plot comparison for n_X = 10^12\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Extract data for plotting\n",
    "fiber_lengths = [entry['fiber_length'] for entry in filtered_data]\n",
    "optimal_key_rates = [entry['key_rate'] for entry in filtered_data]\n",
    "\n",
    "# Get predictions for the same fiber lengths\n",
    "test_inputs = []\n",
    "for entry in filtered_data:\n",
    "    test_inputs.append([\n",
    "        entry['e_1'],\n",
    "        entry['e_2'],\n",
    "        entry['e_3'],\n",
    "        entry['e_4']\n",
    "    ])\n",
    "\n",
    "# Convert to tensor and get predictions\n",
    "test_tensor = torch.tensor(test_inputs, dtype=torch.float32).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_tensor).cpu().numpy()\n",
    "\n",
    "# Plot results\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(fiber_lengths, np.log10(optimal_key_rates), 'b-', label='Optimal Key Rate')\n",
    "plt.plot(fiber_lengths, np.log10(predictions[:, 0]), 'r--', label='Predicted Key Rate')\n",
    "plt.xlabel('Fiber Length (km)')\n",
    "plt.ylabel('log10(Key Rate)')\n",
    "plt.title('Key Rate Comparison for n_X = 10^12')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot parameters\n",
    "plt.subplot(2, 1, 2)\n",
    "param_names = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X_value']\n",
    "optimal_params = np.array([list(entry['optimized_params'].values()) for entry in filtered_data])\n",
    "predicted_params = predictions[:, 1:]  # Skip key rate column\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(fiber_lengths, optimal_params[:, i], '-', label=f'Optimal {param_names[i]}')\n",
    "    plt.plot(fiber_lengths, predicted_params[:, i], '--', label=f'Predicted {param_names[i]}')\n",
    "\n",
    "plt.xlabel('Fiber Length (km)')\n",
    "plt.ylabel('Parameter Value')\n",
    "plt.title('Parameter Comparison for n_X = 10^12')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nStatistics for n_X = 10^12:\")\n",
    "mse_key_rate = np.mean((np.log10(optimal_key_rates) - np.log10(predictions[:, 0]))**2)\n",
    "print(f\"MSE for log10(Key Rate): {mse_key_rate:.6f}\")\n",
    "\n",
    "for i in range(5):\n",
    "    mse_param = np.mean((optimal_params[:, i] - predicted_params[:, i])**2)\n",
    "    print(f\"MSE for {param_names[i]}: {mse_param:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset for the optimal key rates and parameters\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"../Training_Data/total_training_dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Filter for n_X = 10^6 (e_4 = log10(10^6) = 6)\n",
    "filtered_data = [entry for entry in dataset if np.isclose(entry[\"e_4\"], 6, atol=1e-2)]\n",
    "\n",
    "print(f\"Number of entries for n_X = 10^6: {len(filtered_data)}\")\n",
    "\n",
    "# Extract fiber lengths and optimized parameters\n",
    "Ls_training = np.array([item[\"e_1\"] * 100 for item in training_data])  # Convert normalized to km\n",
    "optimal_params = np.array([item[\"optimized_params\"] for item in training_data])  # Extract optimal parameters\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\")['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_Y = model(torch.tensor(X_val, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "    # Debugging: Check a few sample predictions\n",
    "    sample_predictions = model(torch.tensor(X_val[:10], dtype=torch.float32).to(device)).cpu().numpy()\n",
    "    print(\"Sample Predictions:\\n\", sample_predictions)\n",
    "    print(\"Sample Ground Truth:\\n\", Y_val[:10])\n",
    "\n",
    "# Extract distances (fiber lengths) from validation set\n",
    "distances_km = X_val[:, 0] * 100  # Convert normalized distance back to km\n",
    "\n",
    "# Convert normalized e_1 back to kilometers and clip negatives\n",
    "distances_km = np.clip(X_val[:, 0] * 100, a_min=0, a_max=None)  # Ensure no negative distances\n",
    "Ls_training = np.clip([item[\"e_1\"] * 100 for item in training_data], a_min=0, a_max=None)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot the line for the optimal key rate from the training dataset\n",
    "plt.plot(Ls, np.log10(optimal_key_rates), 'b-', label=\"Optimal (Training Dataset)\")\n",
    "\n",
    "# Plot the predicted key rates for validation data\n",
    "plt.scatter(distances_km, np.log10(key_rate_predicted), color='r', label=\"NN Predicted\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Fiber Length (km)\")\n",
    "plt.ylabel(\"log_{10}(Key Rate)\")\n",
    "plt.title(\"Key Rate vs Distance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 2: Parameter Comparison ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Extract optimized parameters from the training data\n",
    "optimized_params = np.array([list(item[\"optimized_params\"].values()) for item in training_data], dtype=np.float32)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(5):  # For each parameter\n",
    "    # Extract parameter values for plotting\n",
    "    optimized_values = optimized_params[:, i]  # Optimal parameters from training data\n",
    "    predicted_values = predicted_Y[:, i]  # Predicted parameters from NN\n",
    "\n",
    "    # Plot the optimal parameter as a line across all distances\n",
    "    plt.plot(Ls_training, optimized_values, label=f\"Optimized Param {i+1}\", linestyle='--')\n",
    "\n",
    "    # Plot the predicted parameter as points across validation distances\n",
    "    plt.scatter(distances_km, predicted_values, label=f\"NN Predicted Param {i+1}\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Fiber Length (km)\")\n",
    "plt.ylabel(\"Parameter Value\")\n",
    "plt.title(\"Predicted vs Optimal Parameters Across Distance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "\n",
    "# # --- Step 1: Load the dataset and filter for n_X = 10^6 ---\n",
    "# with open(\"../Training_Data/total_training_dataset.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# # Filter dataset for n_X = 10^6 (e_4 = log10(10^6) = 6)\n",
    "# filtered_data = [entry for entry in dataset if np.isclose(entry[\"e_4\"], 6, atol=1e-2)]\n",
    "# print(f\"Number of entries for n_X = 10^6: {len(filtered_data)}\")\n",
    "\n",
    "# # Extract fiber lengths (e_1 in km) and optimal key rates\n",
    "# fiber_lengths_km = np.array([entry[\"e_1\"] * 100 for entry in filtered_data])  # Convert normalized to km\n",
    "# optimal_key_rates = np.array([entry[\"key_rate\"] for entry in filtered_data])  # Optimal key rates\n",
    "\n",
    "# # Extract optimal parameters\n",
    "# optimal_params = np.array([list(entry[\"optimized_params\"].values()) for entry in filtered_data], dtype=np.float32)\n",
    "\n",
    "# # --- Step 2: Load the trained model and make predictions ---\n",
    "# # Load the trained model\n",
    "# model = BB84NN()\n",
    "# state_dict = torch.load(\"best_model.pth\")['model_state_dict']  # Load the state dictionary\n",
    "# model.load_state_dict(state_dict)  # Load the state dictionary into the model\n",
    "# model.eval()\n",
    "\n",
    "# # Prepare input features for filtered data\n",
    "# X_filtered = np.array([[entry[\"e_1\"], entry[\"e_2\"], entry[\"e_3\"], entry[\"e_4\"]] for entry in filtered_data])\n",
    "# X_filtered_tensor = torch.tensor(X_filtered, dtype=torch.float32)\n",
    "\n",
    "# # Make predictions\n",
    "# with torch.no_grad():\n",
    "#     predicted_Y = model(X_filtered_tensor).numpy()\n",
    "\n",
    "# predicted_key_rates = predicted_Y[:, 0]  # First output is the predicted key rate\n",
    "# predicted_params = predicted_Y[:, 1:]   # Remaining outputs are the predicted parameters\n",
    "\n",
    "# # --- Step 3: Plot Key Rate Comparisons ---\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(fiber_lengths_km, np.log10(optimal_key_rates), 'b-', label=\"Optimal Key Rate (log10)\", linewidth=2)\n",
    "# plt.scatter(fiber_lengths_km, np.log10(predicted_key_rates), color='r', label=\"Predicted Key Rate (log10)\", alpha=0.5)\n",
    "# plt.xlabel(\"Fiber Length (km)\")\n",
    "# plt.ylabel(\"log10(Key Rate)\")\n",
    "# plt.title(\"Key Rate vs Fiber Length (n_X = 10^6)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # --- Step 4: Plot Parameter Comparisons ---\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# param_names = [\"mu_1\", \"mu_2\", \"P_mu_1\", \"P_mu_2\", \"P_X_value\"]\n",
    "\n",
    "# for i in range(optimal_params.shape[1]):  # Iterate over parameters\n",
    "#     plt.plot(fiber_lengths_km, optimal_params[:, i], label=f\"Optimal {param_names[i]}\", linestyle='--', linewidth=2)\n",
    "#     plt.scatter(fiber_lengths_km, predicted_params[:, i], label=f\"Predicted {param_names[i]}\", alpha=0.5)\n",
    "\n",
    "# plt.xlabel(\"Fiber Length (km)\")\n",
    "# plt.ylabel(\"Parameter Value\")\n",
    "# plt.title(\"Predicted vs Optimal Parameters Across Fiber Length (n_X = 10^6)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the features and targets (X_train and Y_train) to ensure there is a meaningful relationship to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[:, 0], Y_train[:, 0])\n",
    "# plt.xlabel(\"Feature 1\")\n",
    "# plt.ylabel(\"Target Param 1\")\n",
    "# plt.title(\"Feature vs Target\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the ranges of the preprocessed inputs (e_1, e_2, e_3, e_4) to confirm they align with the expected ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Input Feature Ranges:\")\n",
    "# print(f\"e_1 (L/100): Min={X[:, 0].min()}, Max={X[:, 0].max()}\")\n",
    "# print(f\"e_2 (-log10(Y_0)): Min={X[:, 1].min()}, Max={X[:, 1].max()}\")\n",
    "# print(f\"e_3 (e_d * 100): Min={X[:, 2].min()}, Max={X[:, 2].max()}\")\n",
    "# print(f\"e_4 (log10(N)): Min={X[:, 3].min()}, Max={X[:, 3].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include both training and validation losses in the output for better monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Epoch {epoch + 1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, check if tensors and model weights are on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çprint(next(model.parameters()).device)  # Should print 'mps:0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkd-training_set",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

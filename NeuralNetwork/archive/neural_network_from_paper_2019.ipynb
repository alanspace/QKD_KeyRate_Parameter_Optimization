{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F  # Add this import at the top\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "# Get the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Add parent directory to path\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " checking if the MPS (Metal Performance Shaders) backend is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    raise RuntimeError(\"MPS device not available. Check if PyTorch and macOS set up correctly.\")\n",
    "\n",
    "# Set the device to MPS\n",
    "device = torch.device(\"mps\")  # Use GPU on M2 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daai6ga1hou2/anaconda3/envs/qkd-training_set/lib/python3.9/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from QKD_Functions.QKD_Functions import (\n",
    "    calculate_factorial,\n",
    "    calculate_tau_n,\n",
    "    calculate_eta_ch,\n",
    "    calculate_eta_sys,\n",
    "    calculate_D_mu_k,\n",
    "    calculate_n_X_total,\n",
    "    calculate_N,\n",
    "    calculate_n_Z_total,\n",
    "    calculate_e_mu_k,\n",
    "    calculate_e_obs,\n",
    "    calculate_h,\n",
    "    calculate_lambda_EC,\n",
    "    calculate_sqrt_term,\n",
    "    calculate_tau_n,\n",
    "    calculate_n_pm, \n",
    "    calculate_S_0,\n",
    "    calculate_S_1,\n",
    "    calculate_m_mu_k,\n",
    "    calculate_m_pm,\n",
    "    calculate_v_1,\n",
    "    calculate_gamma,\n",
    "    calculate_Phi,\n",
    "    calculate_LastTwoTerm,\n",
    "    calculate_l,\n",
    "    calculate_R,\n",
    "    experimental_parameters,\n",
    "    other_parameters,\n",
    "    calculate_key_rates_and_metrics,\n",
    "    penalty, \n",
    "    objective,\n",
    "    objective_with_logging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BB84NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB84NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,128)\n",
    "        self.fc2 = nn.Linear(128,256)\n",
    "        self.fc3 = nn.Linear(256, 512)  # Change 64 -> 32 to match checkpoint\n",
    "        self.fc4 = nn.Linear(512, 1024)  # Change 64 -> 16 to match checkpoint\n",
    "        self.fc5 = nn.Linear(1024, 512)\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)  # Change 32 -> 16 to match checkpoint\n",
    "        self.fc9 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall dataset contains 4 entries.\n",
      "The number of entries associated with the first key (1000000.0) is: 1000\n",
      "Filtered dataset contains 4000 entries.\n",
      "\n",
      "Sample entry from the cleaned dataset:\n",
      "{\n",
      "  \"fiber_length\": 0.1,\n",
      "  \"e_1\": 0.001,\n",
      "  \"e_2\": 6.221848749616356,\n",
      "  \"e_3\": 0.5,\n",
      "  \"e_4\": 6.0,\n",
      "  \"key_rate\": 0.0036303286417213275,\n",
      "  \"optimized_params\": {\n",
      "    \"mu_1\": 0.5549018921354658,\n",
      "    \"mu_2\": 0.26969689565760935,\n",
      "    \"P_mu_1\": 0.12707388827527158,\n",
      "    \"P_mu_2\": 0.7359624876233963,\n",
      "    \"P_X_value\": 0.662917960144376\n",
      "  }\n",
      "}\n",
      "\n",
      "Number of unique n_X values: 4\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "with open('../Training_Data/combined_datasets.json', 'r') as f:\n",
    "    data_by_nx = json.load(f)\n",
    "\n",
    "print(f\"The overall dataset contains {len(data_by_nx)} entries.\")\n",
    "\n",
    "# Verify the length of the list associated with the first key\n",
    "first_key = list(data_by_nx.keys())[0]\n",
    "print(f\"The number of entries associated with the first key ({first_key}) is: {len(data_by_nx[first_key])}\")\n",
    "\n",
    "# Flatten the data structure and filter\n",
    "cleaned_data = []\n",
    "for n_x, entries in data_by_nx.items():\n",
    "    cleaned_data.extend([\n",
    "        item for item in entries\n",
    "# if item[\"key_rate\"] > 0 and \n",
    "if item[\"e_1\"] * 100 <= 200  # Only positive key rates and fiber lengths <= 200 km\n",
    "    ])\n",
    "\n",
    "# Optional: Verify the cleaned dataset\n",
    "if not cleaned_data:\n",
    "    print(\"No valid data after filtering.\")\n",
    "else:\n",
    "    print(f\"Filtered dataset contains {len(cleaned_data)} entries.\")\n",
    "    print(\"\\nSample entry from the cleaned dataset:\")\n",
    "    print(json.dumps(cleaned_data[0], indent=2))\n",
    "    print(\"\\nNumber of unique n_X values:\", len(data_by_nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for item in cleaned_data:\n",
    "    mu_1, mu_2, P_mu_1, P_mu_2, P_X = item['optimized_params'].values()\n",
    "    # Constraints applied but not stored in Y\n",
    "    # P_mu_3 = max(1 - (P_mu_1 + P_mu_2), 1e-6)\n",
    "    # P_Z = max(1 - P_X, 1e-6)\n",
    "    \n",
    "    # Store only the first five parameters\n",
    "    Y.append([mu_1, mu_2, P_mu_1, P_mu_2, P_X])\n",
    "\n",
    "Y = np.array(Y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2800, 4), Y_train shape: (2800, 5)\n",
      "X_val shape: (1200, 4), Y_val shape: (1200, 5)\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and targets (Y)\n",
    "X = np.array([[item['e_1'], item['e_2'], item['e_3'], item['e_4']] for item in cleaned_data], dtype=np.float32)\n",
    "Y = np.array([list(item['optimized_params'].values()) for item in cleaned_data ], dtype=np.float32)  # Flatten dictionary\n",
    "\n",
    "# Shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
    "X_val = scaler.transform(X_val)  # Transform validation data using the same scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_scaler = MinMaxScaler()  # Scale targets to [0, 1]\n",
    "Y_train = y_scaler.fit_transform(Y_train)\n",
    "Y_val = y_scaler.transform(Y_val)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Save StandardScaler\n",
    "joblib.dump(y_scaler, 'y_scaler.pkl')  # Save MinMaxScaler\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, Y_val shape: {Y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32))\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Initialize model\n",
    "model = BB84NN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Adam optimizer\n",
    "\n",
    "# Learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_check_constraints(model, val_loader, criterion, device, bounds):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    constraint_violations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, Y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Check constraints\n",
    "            for i, bound in enumerate(bounds):\n",
    "                lower, upper = bound\n",
    "                # Check if any predictions are out of the specified bounds\n",
    "                if (predictions[:, i] < lower).any() or (predictions[:, i] > upper).any():\n",
    "                    constraint_violations += 1\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    if constraint_violations == 0:\n",
    "        print(\"All constraints satisfied.\")\n",
    "    else:\n",
    "        print(f\"Constraints violated in {constraint_violations} batches.\")\n",
    "\n",
    "    return avg_loss, constraint_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "best_loss = float('inf')  # Initialize best loss to infinity\n",
    "patience = 20 # Number of epochs to wait before stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stopping_patience = 100  # Early stopping patience\n",
    "\n",
    "# Initialize placeholders for final outputs\n",
    "final_train_loss = None\n",
    "final_val_loss = None\n",
    "\n",
    "# Bounds for predicted parameters (adjust as needed)\n",
    "bounds = [\n",
    "    (4e-4, 0.9),  \n",
    "    (2e-4, 0.5),  \n",
    "    (1e-12, 1.0 - 1e-12),  \n",
    "    (1e-12, 1.0- 1e-12),  \n",
    "    (1e-12, 1.0- 1e-12),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed QKD Parameters (create this OUTSIDE the loss function)\n",
    "# qkd_params = (0.2, 0.1, 6e-7, 1e-10, 1e-15, 1.16, 0.01, 1) #alpha, eta_Bob, P_dc_value, epsilon_sec, \n",
    "\n",
    "# Fixed parameters\n",
    "alpha = 0.2\n",
    "eta_Bob = 0.1\n",
    "P_dc_value = 6e-7\n",
    "epsilon_sec = 1e-10\n",
    "epsilon_cor = 1e-15\n",
    "f_EC = 1.16\n",
    "e_mis = 5e-3\n",
    "P_ap = 0 #4e-2\n",
    "n_event = 1\n",
    "\n",
    "parameter_criterion = nn.MSELoss()\n",
    "\n",
    "def compute_loss(predictions, targets, X_batch, n_X):\n",
    "    # Calculate standard loss (e.g., MSE)\n",
    "    # loss = criterion(predictions, targets)\n",
    "    \n",
    "    parameter_loss = nn.MSELoss()(predictions, targets)\n",
    "    \n",
    "    return parameter_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform validation and calculate average loss.\n",
    "    Args:\n",
    "        model (nn.Module): The model to validate.\n",
    "        val_loader (DataLoader): DataLoader for the validation set.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to perform computation.\n",
    "    Returns:\n",
    "        float: Average validation loss.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, Y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)  # Average validation loss\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4586,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5266, 0.9327, 0.1295, 0.9278, 0.9867], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3363,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8947, 0.6432, 0.0014, 0.9470, 0.7196], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1071,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7452,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0310, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2011, 0.8048, 0.4795, 0.4591, 0.8519], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4385,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5067, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5290, 0.9622, 0.0927, 0.9872, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0965, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1841, 0.7572, 0.5335, 0.4077, 0.8336], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5654,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5372, 0.9510, 0.1006, 0.9791, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0726,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2688, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6523, 0.8692, 0.0662, 0.9874, 0.9274], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6332,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9388, 0.6522, 0.0131, 0.9301, 0.6944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2896, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0678, 0.5464, 0.5974, 0.3270, 0.6123], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7366,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9174, 0.6476, 0.0098, 0.9347, 0.7018], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.0207,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3267, 0.7274, 0.1766, 0.6663, 0.6570], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 1/5000 [00:01<1:31:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000, Train Loss: 0.0041, Val Loss: 0.0855\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9675,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8889, 0.6415, 0.0050, 0.9415, 0.7121], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7404, 0.7671, 0.0383, 0.9433, 0.8240], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2826,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5481,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5451, 0.9804, 0.0858, 0.9943, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3931,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5230, 0.9337, 0.1335, 0.9222, 0.9844], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6343, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7321, 0.7646, 0.0347, 0.9491, 0.8294], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5286, 0.9370, 0.1115, 0.9570, 0.9940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6855, 0.7884, 0.0757, 0.8756, 0.7629], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7758, 0.7727, 0.0386, 0.9726, 0.8303], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6132, 0.8801, 0.0602, 0.9937, 0.9309], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 2/5000 [00:01<55:04,  1.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3964, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7575, 0.7713, 0.0451, 0.9320, 0.8119], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7401,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9167, 0.6475, 0.0097, 0.9349, 0.7021], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3350, 0.7327, 0.1710, 0.6705, 0.6618], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0828,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2288, 0.8626, 0.4067, 0.5283, 0.8734], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.1309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6167, 0.8776, 0.0611, 0.9928, 0.9304], device='mps:0')\n",
      "Epoch 2/5000, Train Loss: 0.0014, Val Loss: 0.0236\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7518, 0.7728, 0.0364, 0.9753, 0.8340], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1382, 0.3349, 0.8471, 0.1202, 0.6073], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5290, 0.9622, 0.0927, 0.9872, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5195,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9694, 0.6588, 0.0182, 0.9232, 0.6829], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7357, 0.7657, 0.0363, 0.9465, 0.8271], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3069, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1424, 0.4839, 0.7604, 0.1963, 0.7072], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6758, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4655,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6292,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5576e-01, 6.5795e-01, 2.1116e-04, 9.4960e-01, 7.2232e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7312, 0.7750, 0.0340, 0.9785, 0.8380], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5861, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7623, 0.7723, 0.0470, 0.9289, 0.8082], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6895,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8865,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 3/5000 [00:01<43:57,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7353, 0.7732, 0.0503, 0.9155, 0.8032], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6378,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6936,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2826, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5812, 1.0000, 0.0816, 0.9990, 1.0000], device='mps:0')\n",
      "Epoch 3/5000, Train Loss: 0.0005, Val Loss: 0.0093\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1102,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6183, 0.8768, 0.0614, 0.9924, 0.9302], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1792, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2611,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8480, 0.6590, 0.0245, 0.8468, 0.6470], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5072, 0.9458, 0.0947, 0.9762, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5000,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6347, 0.8646, 0.0718, 0.9625, 0.9199], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0035,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2099, 0.8252, 0.4548, 0.4826, 0.8595], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0728, 0.4852, 0.4862, 0.3956, 0.4392], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3713,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8751, 0.6494, 0.0146, 0.8712, 0.6709], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0240,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9457, 0.0948, 0.9760, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5295, 0.9593, 0.0944, 0.9855, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6189, 0.8654, 0.0823, 0.9393, 0.9099], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6045, 0.8659, 0.0602, 0.9781, 0.9293], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6241,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6191, 0.8651, 0.0665, 0.9697, 0.9245], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6550,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6067, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5383, 0.9503, 0.1012, 0.9785, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 4/5000 [00:02<38:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8792,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6530, 0.8691, 0.0663, 0.9873, 0.9273], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3208,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.7930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5163, 0.9402, 0.1040, 0.9655, 0.9961], device='mps:0')\n",
      "Epoch 4/5000, Train Loss: 0.0003, Val Loss: 0.0049\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6373, 0.8644, 0.0727, 0.9614, 0.9191], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1576, 0.6364, 0.6485, 0.2991, 0.7838], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8172, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0623, 0.1132, 0.9016, 0.0627, 0.1292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7997, 0.7730, 0.0408, 0.9698, 0.8265], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7085,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9859, 0.6652, 0.0000, 0.9503, 0.7229], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1655,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5897, 0.8718, 0.1006, 0.9120, 0.8906], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3412, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4550,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5341, 0.9716, 0.0886, 0.9915, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0516,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6242, 0.8748, 0.0624, 0.9914, 0.9297], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5378,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5436, 0.9793, 0.0861, 0.9940, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3757,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5296, 0.9653, 0.0912, 0.9888, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6998, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8417,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1491,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3187, 0.5355, 0.1671, 0.6257, 0.4097], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4724, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0623, 0.1132, 0.9016, 0.0627, 0.1292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3398, 0.7357, 0.1679, 0.6728, 0.6644], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1137,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6180, 0.8769, 0.0614, 0.9925, 0.9303], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.5482, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 5/5000 [00:02<35:33,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5000, Train Loss: 0.0001, Val Loss: 0.0024\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3448,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6180, 0.8657, 0.0831, 0.9381, 0.9091], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5057,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9736, 0.6597, 0.0189, 0.9222, 0.6811], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3138, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0587, 0.5038, 0.6398, 0.2884, 0.5819], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1276,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2314, 0.6623, 0.2515, 0.6059, 0.5994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4161,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8726, 0.6459, 0.0119, 0.8764, 0.6778], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5964, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7068,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9999,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6310, 0.8730, 0.0634, 0.9904, 0.9291], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6206,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6195, 0.8651, 0.0667, 0.9695, 0.9244], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6586,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7445, 0.7682, 0.0400, 0.9406, 0.8213], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0215,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4297, 0.5925, 0.1090, 0.6672, 0.4862], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0422,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4152, 0.5854, 0.1157, 0.6630, 0.4766], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6074, 0.8656, 0.0618, 0.9761, 0.9282], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1069,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3638, 0.7506, 0.1525, 0.6838, 0.6779], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5378,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.0922,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4916, 0.6224, 0.0821, 0.6822, 0.5273], device='mps:0')\n",
      "Epoch 6/5000, Train Loss: 0.0001, Val Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 6/5000 [00:02<34:51,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0353,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4202, 0.5878, 0.1134, 0.6644, 0.4799], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1792, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3482,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6144, 0.8872, 0.0585, 0.9956, 0.9319], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1861,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6136, 0.8797, 0.0603, 0.9936, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5315, 0.9558, 0.0968, 0.9831, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0690, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1952, 0.7648, 0.3322, 0.5702, 0.7513], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2207,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6014, 0.8699, 0.0943, 0.9214, 0.8978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5114, 0.9357, 0.1424, 0.9093, 0.9781], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5240, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2516, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0621, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1988, 0.7685, 0.3273, 0.5745, 0.7535], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 7/5000 [00:03<33:57,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3481,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3102,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5291, 0.9605, 0.0937, 0.9862, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2972,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1091, 0.3850, 0.3617, 0.4529, 0.1989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1827,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5359, 0.9519, 0.0998, 0.9800, 0.9977], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4385,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5075, 0.9449, 0.0958, 0.9749, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7312, 0.7750, 0.0340, 0.9785, 0.8380], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0276,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3301, 0.7296, 0.1743, 0.6680, 0.6590], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5394, 0.9496, 0.1019, 0.9779, 0.9975], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.3688, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Epoch 7/5000, Train Loss: 0.0000, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3516, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0698,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3941, 0.5748, 0.1258, 0.6562, 0.4624], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6758, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8004,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8469,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9006, 0.6440, 0.0072, 0.9385, 0.7076], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5144,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7438, 0.7731, 0.0357, 0.9763, 0.8353], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4558,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5659, 0.9923, 0.0830, 0.9973, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3748,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8749, 0.6491, 0.0144, 0.8717, 0.6715], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6325, 0.8727, 0.0636, 0.9902, 0.9290], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 8/5000 [00:03<33:15,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5000,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6347, 0.8646, 0.0718, 0.9625, 0.9199], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5291, 0.9630, 0.0923, 0.9876, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7136,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6109, 0.8654, 0.0634, 0.9740, 0.9271], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6517,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8069, 0.7731, 0.0415, 0.9689, 0.8253], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4161,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8726, 0.6459, 0.0119, 0.8764, 0.6778], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.7137, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Epoch 8/5000, Train Loss: 0.0000, Val Loss: 0.0009\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5344, 0.9719, 0.0885, 0.9916, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1069,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5731, 0.8738, 0.1087, 0.9001, 0.8807], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1103,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4797, 0.9373, 0.1579, 0.8868, 0.9640], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5642, 0.9914, 0.0832, 0.9971, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7535, 0.7704, 0.0436, 0.9346, 0.8149], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4793,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5594, 0.9297, 0.1282, 0.9380, 0.9889], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6654, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5082, 0.9440, 0.0971, 0.9734, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2034, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1589, 0.6454, 0.6409, 0.3063, 0.7878], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6274, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1138, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1701, 0.7374, 0.3676, 0.5381, 0.7350], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5895, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0732,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3912, 0.5734, 0.1272, 0.6553, 0.4605], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5051,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2177e-01, 6.4976e-01, 6.2920e-04, 9.4857e-01, 7.2132e-01],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 9/5000 [00:04<31:57,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3517, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0504, 0.4263, 0.7080, 0.2271, 0.5222], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7598, 0.7727, 0.0372, 0.9744, 0.8327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1999,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5344, 0.9530, 0.0989, 0.9809, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1387,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3300, 0.5416, 0.1603, 0.6310, 0.4179], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.0447, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Epoch 9/5000, Train Loss: 0.0000, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4310, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0562, 0.2275, 0.8422, 0.1110, 0.3241], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7319, 0.7747, 0.0342, 0.9783, 0.8378], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0818, 0.5017, 0.4655, 0.4145, 0.4547], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0861, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3656,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6861,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6730, 0.9157, 0.0551, 0.9996, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0292, 0.3649, 0.6178, 0.2764, 0.3162], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3723, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7299, 0.7765, 0.0335, 0.9792, 0.8389], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8965,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5102, 0.9426, 0.0993, 0.9709, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0069,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2108, 0.8271, 0.4524, 0.4848, 0.8602], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2122,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8855, 0.6409, 0.0023, 0.9456, 0.7178], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6459, 0.8639, 0.0754, 0.9577, 0.9164], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5826,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6451, 0.9042, 0.0562, 0.9983, 0.9329], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4481, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 10/5000 [00:04<32:31,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2345,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6038, 0.8694, 0.0928, 0.9235, 0.8994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0723,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5074, 0.9470, 0.0934, 0.9776, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8986,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8947, 0.6427, 0.0062, 0.9399, 0.7097], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.6689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 10/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2852,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8534, 0.6563, 0.0218, 0.8515, 0.6527], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5128, 0.9414, 0.1015, 0.9684, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2276,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1410, 0.5819, 0.3583, 0.5119, 0.5278], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2742,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8891, 0.6418, 0.0018, 0.9464, 0.7187], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5398, 0.9494, 0.1021, 0.9777, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5341, 0.9532, 0.0987, 0.9811, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2777,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8894, 0.6419, 0.0018, 0.9464, 0.7188], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1054,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0033, 0.9441, 0.7158], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4730,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9137,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6458, 0.8702, 0.0654, 0.9883, 0.9279], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3552,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1519,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2000, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1172, 0.6651, 0.4605, 0.4528, 0.6907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2214,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2265, 0.4807, 0.2345, 0.5690, 0.3358], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5878,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4283e-01, 6.5484e-01, 3.3732e-04, 9.4926e-01, 7.2200e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9124,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8934, 0.6424, 0.0059, 0.9403, 0.7102], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3438,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8766, 0.6516, 0.0165, 0.8678, 0.6660], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7586,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5192, 0.9394, 0.1059, 0.9634, 0.9956], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6152, 0.8785, 0.0608, 0.9931, 0.9306], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8124,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9052, 0.6450, 0.0079, 0.9374, 0.7060], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.6034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 11/5000 [00:04<31:29,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0801,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3855, 0.5705, 0.1301, 0.6533, 0.4566], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1641, 0.6750, 0.6148, 0.3308, 0.8005], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8211,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0222, 0.3336, 0.6467, 0.2507, 0.2792], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6688,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1877, 0.7570, 0.3423, 0.5610, 0.7466], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1827,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4973, 0.9368, 0.1500, 0.8982, 0.9717], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0552,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3429, 0.7376, 0.1659, 0.6743, 0.6662], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3171, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6989, 0.7853, 0.0696, 0.8850, 0.7734], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4724,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6389, 0.8644, 0.0732, 0.9607, 0.9186], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 12/5000 [00:05<31:05,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1783,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5236, 0.6375, 0.0683, 0.6884, 0.5494], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4672,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.1399e-01, 6.4788e-01, 7.8343e-04, 9.4824e-01, 7.2097e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8469,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9006, 0.6440, 0.0072, 0.9385, 0.7076], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0000, 0.1974, 0.7519, 0.1588, 0.0309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5344,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6298, 0.8648, 0.0702, 0.9647, 0.9214], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7486, 0.7866, 0.0320, 0.9814, 0.8411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1999, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.3172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7353, 0.7732, 0.0503, 0.9155, 0.8032], device='mps:0')\n",
      "Epoch 12/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2517, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1500, 0.5773, 0.6955, 0.2555, 0.7564], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1620,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5379, 0.9505, 0.1010, 0.9787, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7346, 0.7806, 0.0326, 0.9804, 0.8402], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7723,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5180, 0.9397, 0.1051, 0.9643, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5446, 0.9800, 0.0859, 0.9942, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0227,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8858, 0.6408, 0.0043, 0.9427, 0.7137], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2345, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1530, 0.6030, 0.6757, 0.2738, 0.7686], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7102, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0793,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2608, 0.8259, 0.2551, 0.6384, 0.7871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8482,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6039, 0.8660, 0.0598, 0.9787, 0.9296], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6201, 0.8649, 0.0813, 0.9408, 0.9108], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1494, 0.0835, 0.9654, 0.0253, 0.3154], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3845,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9005, 0.6446, 0.0012, 0.9475, 0.7201], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3517,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0350, 0.3874, 0.5958, 0.2962, 0.3411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5805, 0.8730, 0.1051, 0.9053, 0.8851], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 13/5000 [00:05<30:31,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4259,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9067, 0.6461, 0.0010, 0.9479, 0.7206], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1896,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4987, 0.9367, 0.1493, 0.8992, 0.9723], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1689, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6964, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2585,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6121, 0.8827, 0.0595, 0.9945, 0.9314], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.8482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 13/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3207, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0566, 0.4907, 0.6521, 0.2773, 0.5722], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2422, 0.6704, 0.2416, 0.6143, 0.6065], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1425, 0.1928, 0.9171, 0.0625, 0.4716], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0483, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1966, 0.7935, 0.4928, 0.4464, 0.8476], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5344,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0552,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2519, 0.8182, 0.2646, 0.6302, 0.7826], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7417, 0.7839, 0.0322, 0.9810, 0.8407], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6293, 0.8648, 0.0701, 0.9649, 0.9215], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5136, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5454,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8176,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0137,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6290, 0.8735, 0.0631, 0.9907, 0.9292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5688,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6421, 0.9029, 0.0564, 0.9981, 0.9329], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3318, 0.7307, 0.1732, 0.6689, 0.6599], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1605,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8840, 0.6405, 0.0027, 0.9449, 0.7169], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6826, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1521, 0.0185, 0.9925, 0.0054, 0.1691], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 14/5000 [00:05<30:03,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5812, 1.0000, 0.0816, 0.9990, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.4862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0000, 0.1974, 0.7519, 0.1588, 0.0309], device='mps:0')\n",
      "Epoch 14/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0413,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6254, 0.8744, 0.0626, 0.9912, 0.9296], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0190, 0.3174, 0.6608, 0.2382, 0.2588], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7650, 0.7924, 0.0315, 0.9821, 0.8416], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5136, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3776,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8996, 0.6444, 0.0012, 0.9474, 0.7201], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8310, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2105,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5206,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5411, 0.9776, 0.0866, 0.9935, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7758,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6072, 0.8656, 0.0617, 0.9762, 0.9283], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3398, 0.7357, 0.1679, 0.6728, 0.6644], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 15/5000 [00:06<30:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3466,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8958, 0.6435, 0.0014, 0.9471, 0.7197], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3937,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1993, 0.6369, 0.2840, 0.5779, 0.5769], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8211,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4241,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6471, 0.8639, 0.0758, 0.9572, 0.9160], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3696,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0618, 0.3308, 0.4284, 0.3908, 0.0982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2593,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1691, 0.4392, 0.2900, 0.5191, 0.2788], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8228,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9037, 0.6447, 0.0077, 0.9377, 0.7065], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5310,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5494, 0.9321, 0.1229, 0.9440, 0.9906], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.7171, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 15/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3241, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0557, 0.4839, 0.6583, 0.2717, 0.5672], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9934,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6121, 0.8826, 0.0595, 0.9945, 0.9313], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3586, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1385, 0.3805, 0.8223, 0.1415, 0.6414], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8100, 0.8069, 0.0307, 0.9836, 0.8425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2378,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5317, 0.9555, 0.0969, 0.9829, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9999,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6310, 0.8730, 0.0634, 0.9904, 0.9291], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7401,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9167, 0.6475, 0.0097, 0.9349, 0.7021], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5155,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2408e-01, 6.5032e-01, 5.8952e-04, 9.4866e-01, 7.2141e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6955, 0.7861, 0.0712, 0.8826, 0.7707], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2757, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 16/5000 [00:06<29:38,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6861, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1993, 0.6369, 0.2840, 0.5779, 0.5769], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8435,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9010, 0.6441, 0.0072, 0.9384, 0.7074], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5295, 0.9593, 0.0944, 0.9855, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7263,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9192, 0.6480, 0.0101, 0.9343, 0.7012], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0069,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2108, 0.8271, 0.4524, 0.4848, 0.8602], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.2473,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8446, 0.6606, 0.0261, 0.8440, 0.6434], device='mps:0')\n",
      "Epoch 16/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1519,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5161,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9704, 0.6590, 0.0184, 0.9230, 0.6824], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7329, 0.7743, 0.0519, 0.9131, 0.8010], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2206,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6125, 0.8811, 0.0599, 0.9941, 0.9311], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3001,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9378, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7100, 0.7823, 0.0642, 0.8933, 0.7821], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3724, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1382, 0.3504, 0.8388, 0.1273, 0.6193], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1276,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2314, 0.6623, 0.2515, 0.6059, 0.5994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2817,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8527, 0.6566, 0.0222, 0.8509, 0.6520], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3931,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5230, 0.9337, 0.1335, 0.9222, 0.9844], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3207,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0561, 0.4491, 0.5294, 0.3563, 0.4044], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0508,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 17/5000 [00:06<30:17,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4721, 0.6131, 0.0904, 0.6780, 0.5143], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3688,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6156, 0.8883, 0.0583, 0.9958, 0.9320], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1163,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5016, 0.6271, 0.0778, 0.6843, 0.5341], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2310,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5060, 0.9362, 0.1456, 0.9047, 0.9756], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5275, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1521, 0.0185, 0.9925, 0.0054, 0.1691], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.5695,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 17/5000, Train Loss: 0.0000, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3277,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2965,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5147, 0.9352, 0.1402, 0.9124, 0.9798], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5723,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1130, 0.6578, 0.4696, 0.4444, 0.6861], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0585,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6234, 0.8750, 0.0623, 0.9916, 0.9297], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6757,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5722, 0.9956, 0.0824, 0.9981, 0.9999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6137,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5109,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7434, 0.7731, 0.0356, 0.9764, 0.8354], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5137,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5403, 0.9770, 0.0868, 0.9933, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0483,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2493, 0.8159, 0.2675, 0.6277, 0.7813], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0172, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2212, 0.7904, 0.2995, 0.5995, 0.7663], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0931,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2577, 0.6815, 0.2281, 0.6255, 0.6164], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7698, 0.7726, 0.0381, 0.9732, 0.8312], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5350,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1171,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6178, 0.8770, 0.0613, 0.9926, 0.9303], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8952,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8951, 0.6428, 0.0062, 0.9398, 0.7096], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 18/5000 [00:07<29:52,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4817, 0.9373, 0.1570, 0.8880, 0.9649], device='mps:0')\n",
      "Epoch 18/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7763,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4826,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1309, 0.5706, 0.3739, 0.4979, 0.5177], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8865,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6292, 0.8968, 0.0571, 0.9973, 0.9326], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3225,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.6429, 0.0015, 0.9469, 0.7194], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1345, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1745, 0.7230, 0.5691, 0.3740, 0.8202], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6654,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5694, 0.9942, 0.0827, 0.9977, 0.9999], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 19/5000 [00:07<29:58,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5344, 0.9719, 0.0885, 0.9916, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3517,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0350, 0.3874, 0.5958, 0.2962, 0.3411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0033, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3586,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0311, 0.3725, 0.6105, 0.2830, 0.3247], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6545, 0.8689, 0.0665, 0.9871, 0.9272], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5316,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1690,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4945, 0.9369, 0.1514, 0.8962, 0.9704], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7299, 0.7768, 0.0334, 0.9793, 0.8390], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.5378,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 19/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9965,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6315, 0.8729, 0.0635, 0.9903, 0.9290], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6798,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6361,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5809e-01, 6.5851e-01, 1.9129e-04, 9.4966e-01, 7.2237e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0517, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1957, 0.7911, 0.4955, 0.4438, 0.8467], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9723, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3122,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8923, 0.6426, 0.0016, 0.9468, 0.7193], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6110, 0.8678, 0.0882, 0.9304, 0.9041], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6160,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9430, 0.6531, 0.0138, 0.9292, 0.6929], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5109, 0.9357, 0.1427, 0.9089, 0.9779], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2794,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4999, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1519, 0.0278, 0.9887, 0.0081, 0.1951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2766,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1419, 0.4163, 0.3208, 0.4908, 0.2462], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7797,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0965, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 20/5000 [00:08<29:28,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1800, 0.7486, 0.3531, 0.5513, 0.7417], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4190,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9056, 0.6459, 0.0010, 0.9478, 0.7205], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1931, 0.6318, 0.2908, 0.5720, 0.5723], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3162,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8595, 0.6529, 0.0187, 0.8571, 0.6594], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5320, 0.9693, 0.0894, 0.9906, 0.9990], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1130, 0.6578, 0.4696, 0.4444, 0.6861], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4558,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.3172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5169, 0.9349, 0.1387, 0.9147, 0.9809], device='mps:0')\n",
      "Epoch 20/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6144, 0.8790, 0.0606, 0.9933, 0.9307], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 8.6235e-04,  0.0000e+00,  0.0000e+00, -1.3484e+00], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4430, 0.5990, 0.1030, 0.6708, 0.4950], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7300, 0.7771, 0.0333, 0.9794, 0.8391], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3412, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3586,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5206, 0.9343, 0.1358, 0.9189, 0.9829], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0520, 0.2922, 0.8037, 0.1434, 0.3988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1553,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5291, 0.9635, 0.0921, 0.9879, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2414, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0924, 0.6172, 0.5188, 0.3991, 0.6601], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7593, 0.7904, 0.0317, 0.9819, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8797,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9951,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8872, 0.6411, 0.0046, 0.9421, 0.7130], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2990,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8563, 0.6547, 0.0204, 0.8541, 0.6558], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7548, 0.7888, 0.0318, 0.9817, 0.8413], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8590,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7586,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 21/5000 [00:08<29:23,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6082, 0.8655, 0.0621, 0.9756, 0.9280], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4447, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4688,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6253, 0.8947, 0.0573, 0.9969, 0.9325], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.0758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 21/5000, Train Loss: 0.0001, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9034,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5099, 0.9428, 0.0990, 0.9712, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6124, 0.8842, 0.0591, 0.9949, 0.9316], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7323, 0.7647, 0.0348, 0.9489, 0.8292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7363, 0.7728, 0.0497, 0.9165, 0.8041], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3317,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0568, 0.3243, 0.4360, 0.3838, 0.0828], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5446, 0.9800, 0.0859, 0.9942, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5678,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9555, 0.6558, 0.0158, 0.9264, 0.6883], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6173, 0.8659, 0.0837, 0.9373, 0.9086], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6350,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1655, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1387, 0.6978, 0.4189, 0.4911, 0.7110], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6166, 0.8662, 0.0842, 0.9365, 0.9081], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7366, 0.7737, 0.0349, 0.9774, 0.8366], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4086,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9040, 0.6455, 0.0011, 0.9477, 0.7204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4550,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7491, 0.7868, 0.0320, 0.9814, 0.8411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1192,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8836, 0.6404, 0.0031, 0.9443, 0.7160], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6051, 0.8658, 0.0606, 0.9777, 0.9291], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7508, 0.7728, 0.0363, 0.9755, 0.8342], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1404,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5108, 0.6315, 0.0739, 0.6861, 0.5404], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.0758,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6215, 0.8756, 0.0620, 0.9919, 0.9299], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 22/5000 [00:08<29:09,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5324, 0.9548, 0.0974, 0.9824, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2413, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5224,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2567e-01, 6.5070e-01, 5.6358e-04, 9.4872e-01, 7.2147e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6930, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8590,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4171,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6195, 0.8912, 0.0578, 0.9964, 0.9322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5102,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5398, 0.9766, 0.0869, 0.9932, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6895,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5761, 0.9975, 0.0820, 0.9985, 0.9999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7241, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3757,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6161, 0.8887, 0.0582, 0.9959, 0.9320], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 23/5000 [00:09<29:43,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7103,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6115, 0.8654, 0.0636, 0.9737, 0.9269], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5792,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4724,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5272, 0.9325, 0.1287, 0.9289, 0.9871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2176, 0.8412, 0.4346, 0.5018, 0.8655], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7783, 0.7968, 0.0312, 0.9826, 0.8419], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1000,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2326, 0.8693, 0.3977, 0.5368, 0.8759], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3208,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1494, 0.0835, 0.9654, 0.0253, 0.3154], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7324, 0.7745, 0.0522, 0.9126, 0.8006], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1163,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5016, 0.6271, 0.0778, 0.6843, 0.5341], device='mps:0')\n",
      "Epoch 23/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2723, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7866,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6740,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7185e-01, 6.6182e-01, 8.7321e-05, 9.4998e-01, 7.2265e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1773, 0.6179, 0.3094, 0.5557, 0.5600], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5085, 0.9437, 0.0974, 0.9730, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1858, 0.7549, 0.3449, 0.5587, 0.7454], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5551,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2231,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8380, 0.6636, 0.0292, 0.8387, 0.6367], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5387, 0.9501, 0.1014, 0.9783, 0.9975], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4137, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1054,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0033, 0.9441, 0.7158], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 24/5000 [00:09<30:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4127,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8728, 0.6462, 0.0121, 0.8760, 0.6773], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6998,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9176,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9245,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1691,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7407, 0.7733, 0.0353, 0.9768, 0.8358], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.0344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 24/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2241,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5049, 0.9363, 0.1462, 0.9038, 0.9751], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1967,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5302, 0.9576, 0.0955, 0.9844, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7354, 0.7656, 0.0362, 0.9467, 0.8272], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5136, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5398, 0.9494, 0.1021, 0.9777, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6574,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9333, 0.6510, 0.0123, 0.9313, 0.6964], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1714,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5214, 0.6364, 0.0693, 0.6880, 0.5478], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7413, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9103, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6068, 0.8656, 0.0615, 0.9765, 0.9285], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7317, 0.7788, 0.0330, 0.9800, 0.8397], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7388, 0.7666, 0.0376, 0.9443, 0.8250], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3122,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8923, 0.6426, 0.0016, 0.9468, 0.7193], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6895, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7723, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6826,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8050, 0.8053, 0.0308, 0.9834, 0.8424], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 25/5000 [00:09<30:06,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4378,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6216, 0.8926, 0.0576, 0.9966, 0.9323], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6051, 0.8658, 0.0606, 0.9777, 0.9291], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.6792,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 25/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7366,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9174, 0.6476, 0.0098, 0.9347, 0.7018], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2620, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1484, 0.5611, 0.7075, 0.2444, 0.7484], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3937,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1467,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8838, 0.6405, 0.0029, 0.9447, 0.7166], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3127,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8589, 0.6533, 0.0190, 0.8565, 0.6587], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4954,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9768, 0.6603, 0.0195, 0.9215, 0.6798], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3207,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6156, 0.8665, 0.0850, 0.9353, 0.9073], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5240,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5416, 0.9780, 0.0865, 0.9936, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1930,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6133, 0.8799, 0.0603, 0.9937, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7723,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5180, 0.9397, 0.1051, 0.9643, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7506, 0.7697, 0.0424, 0.9366, 0.8170], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0690,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2257, 0.8569, 0.4143, 0.5211, 0.8713], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5757,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5497, 0.9833, 0.0851, 0.9952, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1172, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1680, 0.7351, 0.3706, 0.5353, 0.7336], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5751, 0.9970, 0.0821, 0.9984, 0.9999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7081, 0.7828, 0.0652, 0.8919, 0.7806], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0405,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4667, 0.6105, 0.0927, 0.6767, 0.5107], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3412, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.6309,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7881, 0.8000, 0.0311, 0.9829, 0.8421], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 26/5000 [00:10<29:38,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3673,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8983, 0.6441, 0.0013, 0.9473, 0.7199], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5419, 0.9482, 0.1032, 0.9765, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2507,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8455, 0.6602, 0.0257, 0.8447, 0.6443], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7535, 0.7704, 0.0436, 0.9346, 0.8149], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7341, 0.7803, 0.0327, 0.9803, 0.8401], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8139, 0.8081, 0.0307, 0.9837, 0.8425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1724,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4952, 0.9369, 0.1510, 0.8967, 0.9707], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5802, 0.9995, 0.0817, 0.9989, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7407, 0.7672, 0.0384, 0.9431, 0.8237], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2758,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6101, 0.8680, 0.0889, 0.9295, 0.9035], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 27/5000 [00:10<29:33,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5394, 0.9496, 0.1019, 0.9779, 0.9975], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5896,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8310, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6861,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6730, 0.9157, 0.0551, 0.9996, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7860, 0.7993, 0.0311, 0.9829, 0.8421], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8779,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8969, 0.6432, 0.0065, 0.9394, 0.7089], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5086,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2253e-01, 6.4995e-01, 6.1594e-04, 9.4860e-01, 7.2135e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5475, 0.9326, 0.1219, 0.9452, 0.9909], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.2551, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0847, 0.5988, 0.5402, 0.3795, 0.6480], device='mps:0')\n",
      "Epoch 27/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6136, 0.8863, 0.0587, 0.9954, 0.9318], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1207,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4826, 0.9373, 0.1566, 0.8885, 0.9653], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5206,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5513, 0.9317, 0.1239, 0.9429, 0.9903], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3731,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0824, 0.3559, 0.3983, 0.4188, 0.1492], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0069, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2073, 0.8194, 0.4619, 0.4758, 0.8573], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5333,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9653, 0.6579, 0.0175, 0.9242, 0.6845], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6158, 0.8885, 0.0582, 0.9959, 0.9320], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7347, 0.7740, 0.0346, 0.9777, 0.8370], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1404,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5108, 0.6315, 0.0739, 0.6861, 0.5404], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1000, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1832, 0.7543, 0.5366, 0.4048, 0.8325], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0103, 0.2671, 0.7016, 0.2023, 0.1866], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6209, 0.8921, 0.0577, 0.9965, 0.9323], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1398,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 28/5000 [00:10<29:22,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8837, 0.6404, 0.0029, 0.9446, 0.7165], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1858, 0.7549, 0.3449, 0.5587, 0.7454], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7309,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5827,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5274, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.5971,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 28/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5067, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0353,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4202, 0.5878, 0.1134, 0.6644, 0.4799], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5896, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0944, 0.5222, 0.4389, 0.4387, 0.4738], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5275,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0240, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4403,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9951, 0.6643, 0.0230, 0.9169, 0.6717], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5189,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2487e-01, 6.5051e-01, 5.7659e-04, 9.4869e-01, 7.2144e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7042, 0.7839, 0.0671, 0.8889, 0.7775], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3570,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8970, 0.6438, 0.0013, 0.9472, 0.7198], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7328, 0.7796, 0.0328, 0.9802, 0.8399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7100, 0.7823, 0.0642, 0.8933, 0.7821], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4999,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5386, 0.9757, 0.0872, 0.9929, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7502, 0.7696, 0.0422, 0.9368, 0.8173], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2059,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8328, 0.6657, 0.0315, 0.8347, 0.6314], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8758, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 29/5000 [00:11<29:59,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3688,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5295, 0.9647, 0.0915, 0.9885, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.2344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 29/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2241, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1549, 0.6177, 0.6640, 0.2847, 0.7754], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6100, 0.8654, 0.0629, 0.9745, 0.9274], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3196,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8601, 0.6525, 0.0184, 0.8577, 0.6601], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5338, 0.9714, 0.0887, 0.9914, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6482, 0.9056, 0.0561, 0.9984, 0.9330], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7445, 0.7682, 0.0400, 0.9406, 0.8213], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8383,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0416,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0690, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1952, 0.7648, 0.3322, 0.5702, 0.7513], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5092,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9725, 0.6594, 0.0187, 0.9225, 0.6816], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0077, 0.2499, 0.7146, 0.1909, 0.1572], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6326,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5692e-01, 6.5823e-01, 2.0117e-04, 9.4963e-01, 7.2234e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5688, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0137,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9454, 0.0951, 0.9757, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2826, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4889, 0.9371, 0.1539, 0.8925, 0.9680], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5296, 0.9588, 0.0947, 0.9852, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7607, 0.7909, 0.0316, 0.9820, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7311, 0.7784, 0.0330, 0.9798, 0.8396], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4379, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0575, 0.2087, 0.8527, 0.1023, 0.2992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.6464,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6168e-01, 6.5937e-01, 1.6204e-04, 9.4975e-01, 7.2244e-01],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 30/5000 [00:11<29:31,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0190, 0.3174, 0.6608, 0.2382, 0.2588], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2944, 0.7065, 0.1993, 0.6488, 0.6385], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1420, 0.2016, 0.9130, 0.0657, 0.4817], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8331,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9023, 0.6444, 0.0075, 0.9381, 0.7070], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1413, 0.4645, 0.7727, 0.1852, 0.6959], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6688,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8002, 0.8038, 0.0309, 0.9833, 0.8423], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6625,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0102, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5812, 1.0000, 0.0816, 0.9990, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8710,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8977, 0.6434, 0.0067, 0.9392, 0.7086], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7502, 0.7696, 0.0422, 0.9368, 0.8173], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6998,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8113, 0.8073, 0.0307, 0.9836, 0.8425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7381, 0.7823, 0.0324, 0.9807, 0.8405], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 31/5000 [00:11<29:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4741,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.1532e-01, 6.4821e-01, 7.5434e-04, 9.4830e-01, 7.2104e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8585, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7300, 0.7761, 0.0336, 0.9790, 0.8387], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2570,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8879, 0.6415, 0.0020, 0.9462, 0.7185], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1723, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2507,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8455, 0.6602, 0.0257, 0.8447, 0.6443], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.5516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 31/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5757, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1846,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8845, 0.6407, 0.0025, 0.9453, 0.7173], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2862, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1449, 0.5210, 0.7358, 0.2185, 0.7277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4137, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7567, 0.7895, 0.0317, 0.9818, 0.8414], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5757,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7730, 0.7951, 0.0314, 0.9824, 0.8418], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6775,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7319e-01, 6.6214e-01, 7.8216e-05, 9.5001e-01, 7.2267e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9792,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6341, 0.8723, 0.0638, 0.9899, 0.9288], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2766,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1419, 0.4163, 0.3208, 0.4908, 0.2462], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1690,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7052, 0.7836, 0.0666, 0.8897, 0.7783], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6654,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6665, 0.9131, 0.0554, 0.9994, 0.9333], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1524, 0.0000, 1.0000, 0.0000, 0.1065], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5274, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7502, 0.7872, 0.0319, 0.9815, 0.8411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2673,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8886, 0.6417, 0.0019, 0.9463, 0.7186], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6413, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9417,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 32/5000 [00:12<29:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7607, 0.7909, 0.0316, 0.9820, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7598, 0.7727, 0.0372, 0.9744, 0.8327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6998, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.6205,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7850, 0.7990, 0.0311, 0.9828, 0.8421], device='mps:0')\n",
      "Epoch 32/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5383, 0.9503, 0.1012, 0.9785, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9158,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8931, 0.6424, 0.0059, 0.9403, 0.7104], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5999, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1206, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8861,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6515, 0.8693, 0.0661, 0.9875, 0.9274], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6033,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0206,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9456, 0.0949, 0.9759, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5913,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4384e-01, 6.5508e-01, 3.2635e-04, 9.4929e-01, 7.2203e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6270, 0.8649, 0.0693, 0.9659, 0.9222], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6723, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8965,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5102, 0.9426, 0.0993, 0.9709, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8314,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9896, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2724,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6096, 0.8681, 0.0892, 0.9290, 0.9032], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3896, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1384, 0.3111, 0.8595, 0.1097, 0.5880], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.6177,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 33/5000 [00:12<28:48,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0620, 0.1227, 0.8969, 0.0664, 0.1521], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6205,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5586, 0.9884, 0.0839, 0.9964, 0.9997], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6484, 0.8638, 0.0762, 0.9566, 0.9156], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6378,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5861,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1192,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8836, 0.6404, 0.0031, 0.9443, 0.7160], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7343, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4558,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7401,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9167, 0.6475, 0.0097, 0.9349, 0.7021], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3482, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0508, 0.4339, 0.7018, 0.2326, 0.5284], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 34/5000 [00:12<28:32,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7323, 0.7746, 0.0342, 0.9782, 0.8377], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0103,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2336, 0.8019, 0.2849, 0.6124, 0.7731], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6177, 0.8652, 0.0660, 0.9704, 0.9250], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2724,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6096, 0.8681, 0.0892, 0.9290, 0.9032], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3550,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5292, 0.9637, 0.0920, 0.9880, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0744,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8841, 0.6405, 0.0036, 0.9436, 0.7151], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.9206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 34/5000, Train Loss: 0.0000, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1240,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5424, 0.9480, 0.1034, 0.9763, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7325, 0.7794, 0.0328, 0.9801, 0.8399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1620,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6148, 0.8787, 0.0607, 0.9932, 0.9307], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3551, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1387, 0.3879, 0.8181, 0.1451, 0.6466], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1654,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5376, 0.9507, 0.1008, 0.9789, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7302, 0.7758, 0.0337, 0.9789, 0.8385], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9779,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8882, 0.6413, 0.0049, 0.9418, 0.7124], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6464,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6168e-01, 6.5937e-01, 1.6204e-04, 9.4975e-01, 7.2244e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3344,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6137, 0.8864, 0.0586, 0.9954, 0.9318], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6999, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2206, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3834,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6625,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6764, 0.9170, 0.0550, 0.9998, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0103,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2336, 0.8019, 0.2849, 0.6124, 0.7731], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3964, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 35/5000 [00:13<28:22,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6132, 0.8801, 0.0602, 0.9937, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.2679,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8496, 0.6582, 0.0237, 0.8482, 0.6487], device='mps:0')\n",
      "Epoch 35/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3232, 0.7252, 0.1789, 0.6646, 0.6551], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1458, 0.5328, 0.7277, 0.2259, 0.7340], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3966,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1858, 0.7549, 0.3449, 0.5587, 0.7454], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8883,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8958, 0.6429, 0.0064, 0.9396, 0.7093], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1387,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3300, 0.5416, 0.1603, 0.6310, 0.4179], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6508, 0.8694, 0.0660, 0.9876, 0.9275], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5290, 0.9617, 0.0930, 0.9869, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0690, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1913, 0.7788, 0.5096, 0.4304, 0.8420], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5481, 0.9324, 0.1222, 0.9448, 0.9908], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0930, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6384,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5516,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6387, 0.9014, 0.0565, 0.9979, 0.9328], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3350, 0.7327, 0.1710, 0.6705, 0.6618], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0690, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1952, 0.7648, 0.3322, 0.5702, 0.7513], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1895, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0709,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8842, 0.6405, 0.0037, 0.9435, 0.7150], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5023,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9747, 0.6599, 0.0191, 0.9220, 0.6807], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 36/5000 [00:13<29:49,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7194,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9205, 0.6483, 0.0103, 0.9340, 0.7008], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.3351,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1200, 0.3959, 0.3476, 0.4659, 0.2159], device='mps:0')\n",
      "Epoch 36/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7586,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7782, 0.7727, 0.0388, 0.9723, 0.8299], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1206, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7722, 0.7948, 0.0314, 0.9824, 0.8418], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9020,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8944, 0.6426, 0.0061, 0.9400, 0.7099], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0206,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9456, 0.0949, 0.9759, 0.9985], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3414,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6177, 0.8658, 0.0834, 0.9377, 0.9089], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3585, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5338, 0.9714, 0.0887, 0.9914, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7344, 0.7736, 0.0509, 0.9146, 0.8024], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3085, 0.7158, 0.1891, 0.6567, 0.6467], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5081, 0.9360, 0.1444, 0.9064, 0.9765], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4068, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7300, 0.7771, 0.0333, 0.9794, 0.8391], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4265,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([1.0000, 0.6653, 0.0239, 0.9156, 0.6694], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6479, 0.8699, 0.0657, 0.9880, 0.9277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6499,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6291e-01, 6.5967e-01, 1.5239e-04, 9.4978e-01, 7.2247e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1002,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.1654,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5376, 0.9507, 0.1008, 0.9789, 0.9976], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 37/5000 [00:14<29:41,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2294,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8863, 0.6411, 0.0022, 0.9458, 0.7181], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3068, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0345, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2002, 0.8026, 0.4821, 0.4566, 0.8510], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7556,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1984,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8850, 0.6408, 0.0024, 0.9454, 0.7176], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7241, 0.7778, 0.0569, 0.9049, 0.7935], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6275,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6188, 0.8651, 0.0664, 0.9699, 0.9246], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7608, 0.7720, 0.0464, 0.9299, 0.8094], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4792,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5363, 0.9738, 0.0878, 0.9922, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2413,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6122, 0.8820, 0.0597, 0.9943, 0.9313], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 38/5000 [00:14<29:16,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6344,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2171, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7309,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5729,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6481,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5650, 0.9919, 0.0831, 0.9972, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3378,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6139, 0.8866, 0.0586, 0.9955, 0.9318], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.5896, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 38/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7949, 0.7729, 0.0404, 0.9703, 0.8273], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6551,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5065, 0.9361, 0.1453, 0.9051, 0.9758], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6341, 0.8646, 0.0717, 0.9627, 0.9201], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5383, 0.9503, 0.1012, 0.9785, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0646,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4789, 0.6164, 0.0874, 0.6795, 0.5188], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1577,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5168, 0.6343, 0.0713, 0.6872, 0.5446], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5081, 0.9360, 0.1444, 0.9064, 0.9765], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6302, 0.8648, 0.0704, 0.9645, 0.9212], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6067, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7548, 0.7707, 0.0441, 0.9338, 0.8140], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4885,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9790, 0.6608, 0.0199, 0.9209, 0.6789], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5255, 0.9330, 0.1309, 0.9258, 0.9859], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0692,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1741, 0.7420, 0.3616, 0.5435, 0.7377], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5092,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9725, 0.6594, 0.0187, 0.9225, 0.6816], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4758,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 39/5000 [00:14<29:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0141,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6358, 0.8720, 0.0641, 0.9897, 0.9287], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6209, 0.8921, 0.0577, 0.9965, 0.9323], device='mps:0')\n",
      "Epoch 39/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0077, 0.2499, 0.7146, 0.1909, 0.1572], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1485,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1345, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1578, 0.7227, 0.3867, 0.5207, 0.7262], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5919,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9491, 0.6544, 0.0148, 0.9279, 0.6907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7127, 0.7815, 0.0629, 0.8954, 0.7842], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6688,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5703, 0.9946, 0.0826, 0.9979, 0.9999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6057,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9456, 0.6537, 0.0142, 0.9286, 0.6920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5812, 1.0000, 0.0816, 0.9990, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5826,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6451, 0.9042, 0.0562, 0.9983, 0.9329], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1276,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5795, 0.8731, 0.1056, 0.9046, 0.8845], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8034, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2448,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6055, 0.8691, 0.0918, 0.9251, 0.9005], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8159,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9047, 0.6449, 0.0078, 0.9375, 0.7062], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6270, 0.8649, 0.0693, 0.9659, 0.9222], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4730,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5185, 0.9346, 0.1374, 0.9165, 0.9818], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4412, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1094,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4988, 0.6258, 0.0790, 0.6837, 0.5322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.5551,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 40/5000 [00:15<28:53,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/5000, Train Loss: 0.0000, Val Loss: 0.0007\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6654, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6241,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5344, 0.9356, 0.1148, 0.9533, 0.9930], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5481,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5451, 0.9804, 0.0858, 0.9943, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5240,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6336, 0.8990, 0.0568, 0.9976, 0.9327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2826, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3868,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1206, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 41/5000 [00:15<29:14,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7205, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0038, 0.2237, 0.7335, 0.1745, 0.1043], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0103,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6295, 0.8734, 0.0632, 0.9906, 0.9292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5310, 0.9565, 0.0963, 0.9836, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5481,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6380, 0.9011, 0.0566, 0.9979, 0.9328], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8620,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5119, 0.9418, 0.1007, 0.9693, 0.9970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0256, 0.3495, 0.6324, 0.2635, 0.2983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1414,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6967, 0.7858, 0.0706, 0.8834, 0.7716], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.9758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7415, 0.7732, 0.0354, 0.9766, 0.8357], device='mps:0')\n",
      "Epoch 41/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6826,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6719, 0.9153, 0.0552, 0.9996, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3225,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.6429, 0.0015, 0.9469, 0.7194], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8969,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5447,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6374, 0.9008, 0.0566, 0.9978, 0.9328], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6464,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.6168e-01, 6.5937e-01, 1.6204e-04, 9.4975e-01, 7.2244e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0930, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0621,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2545, 0.8205, 0.2618, 0.6326, 0.7840], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3449,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6120,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5016e-01, 6.5660e-01, 2.6235e-04, 9.4946e-01, 7.2219e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2137, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3448, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0513, 0.4413, 0.6956, 0.2381, 0.5343], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6757,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 42/5000 [00:15<28:53,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7763,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2309, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1105,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.2447,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6122, 0.8821, 0.0596, 0.9944, 0.9313], device='mps:0')\n",
      "Epoch 42/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2414, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1518, 0.5929, 0.6836, 0.2665, 0.7639], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5137,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6319, 0.8982, 0.0569, 0.9975, 0.9327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1276,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2314, 0.6623, 0.2515, 0.6059, 0.5994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6868, 0.7881, 0.0751, 0.8765, 0.7640], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2757,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5300, 0.9581, 0.0952, 0.9847, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1353,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3336, 0.5435, 0.1582, 0.6327, 0.4205], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8159,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9047, 0.6449, 0.0078, 0.9375, 0.7062], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1207,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5775, 0.8734, 0.1066, 0.9031, 0.8833], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6677,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9310, 0.6505, 0.0119, 0.9318, 0.6972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0497, 0.3451, 0.7689, 0.1735, 0.4514], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3472,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8765, 0.6513, 0.0162, 0.8682, 0.6667], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5678,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9555, 0.6558, 0.0158, 0.9264, 0.6883], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7438, 0.7731, 0.0357, 0.9763, 0.8353], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6258, 0.8950, 0.0573, 0.9970, 0.9325], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8056,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9062, 0.6452, 0.0081, 0.9372, 0.7057], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1726,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6109, 0.8654, 0.0634, 0.9740, 0.9271], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.1364,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0030, 0.9446, 0.7164], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 43/5000 [00:16<28:39,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0623, 0.1132, 0.9016, 0.0627, 0.1292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3102,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7337, 0.7801, 0.0327, 0.9803, 0.8400], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3068, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5488, 0.9323, 0.1225, 0.9444, 0.9907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8331,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9023, 0.6444, 0.0075, 0.9381, 0.7070], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2231,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8380, 0.6636, 0.0292, 0.8387, 0.6367], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1425, 0.1928, 0.9171, 0.0625, 0.4716], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0414,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2465, 0.8135, 0.2704, 0.6251, 0.7799], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2972,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1091, 0.3850, 0.3617, 0.4529, 0.1989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8075, 0.8061, 0.0307, 0.9835, 0.8424], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9830,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4896,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5573, 0.9302, 0.1271, 0.9393, 0.9892], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4138,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5243, 0.9334, 0.1322, 0.9240, 0.9852], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 44/5000 [00:16<28:29,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6918,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9260, 0.6495, 0.0111, 0.9329, 0.6989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2551, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1495, 0.5720, 0.6995, 0.2518, 0.7538], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4368,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9963, 0.6645, 0.0232, 0.9166, 0.6711], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6237, 0.8650, 0.0682, 0.9675, 0.9232], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7483, 0.7729, 0.0361, 0.9758, 0.8346], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.4000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0117, 0.2757, 0.6950, 0.2081, 0.2001], device='mps:0')\n",
      "Epoch 44/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1964, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5695,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5861,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1364,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0030, 0.9446, 0.7164], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5109, 0.9357, 0.1427, 0.9089, 0.9779], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7608, 0.7720, 0.0464, 0.9299, 0.8094], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1137,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5437, 0.9473, 0.1041, 0.9756, 0.9972], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1508,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5145, 0.6332, 0.0723, 0.6868, 0.5430], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7338, 0.7651, 0.0355, 0.9478, 0.8283], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3621,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0552,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3429, 0.7376, 0.1659, 0.6743, 0.6662], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7949, 0.7729, 0.0404, 0.9703, 0.8273], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0483, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1966, 0.7935, 0.4928, 0.4464, 0.8476], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7068,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5242, 0.9380, 0.1089, 0.9599, 0.9947], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7279, 0.7764, 0.0548, 0.9083, 0.7967], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 45/5000 [00:16<28:57,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5430,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.3068e-01, 6.5191e-01, 4.8842e-04, 9.4889e-01, 7.2164e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2176, 0.8412, 0.4346, 0.5018, 0.8655], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.7999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 45/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2068,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6129, 0.8805, 0.0601, 0.9939, 0.9310], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7539, 0.7727, 0.0366, 0.9751, 0.8336], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6292,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5576e-01, 6.5795e-01, 2.1116e-04, 9.4960e-01, 7.2232e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8107,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2483,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6061, 0.8690, 0.0915, 0.9256, 0.9008], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7362, 0.7814, 0.0325, 0.9806, 0.8403], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7792, 0.7971, 0.0312, 0.9826, 0.8420], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1398,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0029, 0.9446, 0.7165], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5084, 0.9438, 0.0973, 0.9732, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2345,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6038, 0.8694, 0.0928, 0.9235, 0.8994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3068,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6128, 0.8850, 0.0589, 0.9951, 0.9317], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0353,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4202, 0.5878, 0.1134, 0.6644, 0.4799], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3207, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1410, 0.4579, 0.7768, 0.1815, 0.6920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4551,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6417, 0.8642, 0.0741, 0.9594, 0.9177], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7517,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5198, 0.9392, 0.1063, 0.9630, 0.9955], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1413,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6160, 0.8779, 0.0610, 0.9929, 0.9305], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0485,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4412, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 46/5000 [00:17<29:34,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1999,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6131, 0.8802, 0.0602, 0.9938, 0.9310], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.7792,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6070, 0.8656, 0.0616, 0.9764, 0.9284], device='mps:0')\n",
      "Epoch 46/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3626, 0.7498, 0.1533, 0.6833, 0.6772], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9723, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0345, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2129, 0.7825, 0.3095, 0.5905, 0.7617], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6918,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9260, 0.6495, 0.0111, 0.9329, 0.6989], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2034, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1589, 0.6454, 0.6409, 0.3063, 0.7878], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2414,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6049, 0.8692, 0.0921, 0.9246, 0.9001], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6931, 0.7867, 0.0722, 0.8809, 0.7689], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0887,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4901, 0.6217, 0.0827, 0.6819, 0.5263], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0112,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4365, 0.5959, 0.1059, 0.6691, 0.4907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7302, 0.7757, 0.0337, 0.9789, 0.8385], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 47/5000 [00:17<29:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5471,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9613, 0.6570, 0.0168, 0.9251, 0.6861], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5757, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7711,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9115, 0.6463, 0.0089, 0.9360, 0.7038], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7815, 0.7727, 0.0391, 0.9719, 0.8294], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6620,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5294, 0.9368, 0.1120, 0.9565, 0.9938], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2309, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0310, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2146, 0.7841, 0.3074, 0.5924, 0.7626], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4092,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8730, 0.6465, 0.0123, 0.8756, 0.6768], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3826,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5299, 0.9658, 0.0910, 0.9890, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1999,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5344, 0.9530, 0.0989, 0.9809, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.1344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5411, 0.9487, 0.1027, 0.9770, 0.9974], device='mps:0')\n",
      "Epoch 47/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2964, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6275,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6188, 0.8651, 0.0664, 0.9699, 0.9246], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2363,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8867, 0.6412, 0.0021, 0.9459, 0.7182], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1930,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6133, 0.8799, 0.0603, 0.9937, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7580, 0.7727, 0.0370, 0.9746, 0.8330], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0709,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8842, 0.6405, 0.0037, 0.9435, 0.7150], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5051,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2177e-01, 6.4976e-01, 6.2920e-04, 9.4857e-01, 7.2132e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2206, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2309, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 48/5000 [00:17<28:54,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4982,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2027e-01, 6.4940e-01, 6.5623e-04, 9.4851e-01, 7.2126e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6136,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3318, 0.7307, 0.1732, 0.6689, 0.6599], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5274, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0555, 0.2369, 0.8369, 0.1155, 0.3358], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2404,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8428, 0.6615, 0.0270, 0.8426, 0.6416], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6655,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6151, 0.8652, 0.0651, 0.9717, 0.9257], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.3593,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0877, 0.3619, 0.3909, 0.4258, 0.1602], device='mps:0')\n",
      "Epoch 48/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6741, 0.9161, 0.0551, 0.9997, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5930,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6474, 0.9052, 0.0561, 0.9984, 0.9330], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3964,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6176, 0.8900, 0.0580, 0.9961, 0.9321], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4863, 0.9372, 0.1550, 0.8908, 0.9669], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1964, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5619, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0491,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4101, 0.5829, 0.1181, 0.6614, 0.4732], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1111,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3577, 0.5563, 0.1446, 0.6429, 0.4375], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2432,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8871, 0.6413, 0.0021, 0.9460, 0.7183], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5861, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2654,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5304, 0.9574, 0.0956, 0.9842, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2620, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1484, 0.5611, 0.7075, 0.2444, 0.7484], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7336, 0.7743, 0.0345, 0.9779, 0.8373], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5138,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 49/5000 [00:18<28:47,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2447,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6122, 0.8821, 0.0596, 0.9944, 0.9313], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2260,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8861, 0.6411, 0.0022, 0.9458, 0.7180], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.9206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 49/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6792,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6110, 0.8678, 0.0882, 0.9304, 0.9041], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4862,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3862,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5226, 0.9338, 0.1339, 0.9215, 0.9841], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1525,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3149, 0.5334, 0.1695, 0.6238, 0.4069], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0930, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0793,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2608, 0.8259, 0.2551, 0.6384, 0.7871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0621, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1988, 0.7685, 0.3273, 0.5745, 0.7535], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7400, 0.7734, 0.0353, 0.9769, 0.8360], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0620, 0.1227, 0.8969, 0.0664, 0.1521], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8792,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6530, 0.8691, 0.0663, 0.9873, 0.9273], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4334,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9976, 0.6648, 0.0234, 0.9163, 0.6706], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1483, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1712, 0.7092, 0.5827, 0.3611, 0.8146], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7763,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0077, 0.2499, 0.7146, 0.1909, 0.1572], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7103,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5239, 0.9381, 0.1087, 0.9601, 0.9948], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7307, 0.7780, 0.0331, 0.9797, 0.8394], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1241,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5785, 0.8732, 0.1061, 0.9038, 0.8839], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.9072,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 50/5000, Train Loss: 0.0000, Val Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 50/5000 [00:18<28:51,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0654,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9468, 0.0936, 0.9774, 0.9988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1414,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4881, 0.9371, 0.1543, 0.8920, 0.9676], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9999, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6929,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8087, 0.8065, 0.0307, 0.9835, 0.8425], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4309,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7456, 0.7854, 0.0321, 0.9812, 0.8409], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6688,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4299,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9988, 0.6650, 0.0237, 0.9159, 0.6700], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5482,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7467, 0.7688, 0.0408, 0.9391, 0.8198], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0158,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8861, 0.6409, 0.0043, 0.9425, 0.7136], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7160,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9212, 0.6484, 0.0104, 0.9339, 0.7005], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5070, 0.9361, 0.1450, 0.9056, 0.9761], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3517,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5200, 0.9344, 0.1362, 0.9182, 0.9826], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 51/5000 [00:18<28:38,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0043,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4409, 0.5980, 0.1040, 0.6702, 0.4936], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5302, 0.9576, 0.0955, 0.9844, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2345,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1343, 0.5745, 0.3686, 0.5026, 0.5211], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3690,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7580, 0.7714, 0.0453, 0.9317, 0.8116], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7539, 0.7727, 0.0366, 0.9751, 0.8336], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.0447, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 51/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6686, 0.9140, 0.0553, 0.9994, 0.9333], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1069,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3638, 0.7506, 0.1525, 0.6838, 0.6779], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5481,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5451, 0.9804, 0.0858, 0.9943, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5281,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8034, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3398, 0.7357, 0.1679, 0.6728, 0.6644], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6757,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0137, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0801,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3855, 0.5705, 0.1301, 0.6533, 0.4566], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3309, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3207, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0566, 0.4907, 0.6521, 0.2773, 0.5722], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5398, 0.9494, 0.1021, 0.9777, 0.9974], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7354, 0.7656, 0.0362, 0.9467, 0.8272], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5482, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1690,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5905, 0.8717, 0.1002, 0.9126, 0.8911], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4420,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0241,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2395, 0.8072, 0.2782, 0.6182, 0.7762], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 52/5000 [00:19<29:06,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7694,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0000, 0.1974, 0.7519, 0.1588, 0.0309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5378, 0.9750, 0.0874, 0.9927, 0.9992], device='mps:0')\n",
      "Epoch 52/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7022,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9239, 0.6490, 0.0108, 0.9333, 0.6996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0198,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4553, 0.6050, 0.0976, 0.6740, 0.5031], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3517, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1388, 0.3952, 0.8140, 0.1487, 0.6517], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3696,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0618, 0.3308, 0.4284, 0.3908, 0.0982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5354, 0.9354, 0.1153, 0.9526, 0.9929], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9641,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8892, 0.6415, 0.0051, 0.9415, 0.7120], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4282,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6293, 0.8648, 0.0701, 0.9649, 0.9215], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7062, 0.7834, 0.0661, 0.8904, 0.7791], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6309,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5457, 0.9807, 0.0857, 0.9944, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0227,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8858, 0.6408, 0.0043, 0.9427, 0.7137], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3420,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5171,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6325, 0.8984, 0.0569, 0.9975, 0.9327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5072, 0.9461, 0.0943, 0.9766, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 53/5000 [00:19<29:30,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5169, 0.9400, 0.1044, 0.9651, 0.9960], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.4241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 53/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2329,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8865, 0.6412, 0.0021, 0.9459, 0.7181], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1758,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5365, 0.9514, 0.1002, 0.9796, 0.9977], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2748,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8512, 0.6574, 0.0229, 0.8496, 0.6503], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0985,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0034, 0.9440, 0.7156], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0102, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6293, 0.8648, 0.0701, 0.9649, 0.9215], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2000,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5007, 0.9366, 0.1484, 0.9006, 0.9732], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1344,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6165, 0.8777, 0.0611, 0.9928, 0.9305], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7997, 0.7730, 0.0408, 0.9698, 0.8265], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7394, 0.7829, 0.0323, 0.9808, 0.8406], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3122,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8923, 0.6426, 0.0016, 0.9468, 0.7193], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9103, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3619, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7068,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5242, 0.9380, 0.1089, 0.9599, 0.9947], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5325, 0.9360, 0.1137, 0.9545, 0.9933], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2068,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6129, 0.8805, 0.0601, 0.9939, 0.9310], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.5523,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 54/5000 [00:20<29:27,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5319, 0.9553, 0.0971, 0.9827, 0.9981], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4833,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3931,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6530, 0.8634, 0.0775, 0.9547, 0.9142], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1353,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3336, 0.5435, 0.1582, 0.6327, 0.4205], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7366,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9174, 0.6476, 0.0098, 0.9347, 0.7018], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9930,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5075, 0.9449, 0.0958, 0.9749, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2593,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1691, 0.4392, 0.2900, 0.5191, 0.2788], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2191,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8858, 0.6410, 0.0022, 0.9457, 0.7179], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6619,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5070, 0.9361, 0.1450, 0.9056, 0.9761], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3748,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8749, 0.6491, 0.0144, 0.8717, 0.6715], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 55/5000 [00:20<29:02,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6855, 0.7884, 0.0757, 0.8756, 0.7629], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3242,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9917,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8874, 0.6411, 0.0047, 0.9421, 0.7129], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0620, 0.1227, 0.8969, 0.0664, 0.1521], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2214,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2265, 0.4807, 0.2345, 0.5690, 0.3358], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2448, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1512, 0.5878, 0.6875, 0.2628, 0.7614], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.3896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6217, 0.8643, 0.0799, 0.9430, 0.9121], device='mps:0')\n",
      "Epoch 55/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1454, 0.5269, 0.7318, 0.2222, 0.7309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7127, 0.7815, 0.0629, 0.8954, 0.7842], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7474, 0.7690, 0.0411, 0.9386, 0.8192], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6553, 0.8687, 0.0666, 0.9870, 0.9271], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0552,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2836, 0.6994, 0.2074, 0.6424, 0.6322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3696,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0618, 0.3308, 0.4284, 0.3908, 0.0982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7952,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9077, 0.6455, 0.0083, 0.9369, 0.7051], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7068,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2137, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7341, 0.7803, 0.0327, 0.9803, 0.8401], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0095,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4493, 0.6021, 0.1003, 0.6724, 0.4991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0072,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1655, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1672, 0.6907, 0.6003, 0.3444, 0.8071], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3570,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8970, 0.6438, 0.0013, 0.9472, 0.7198], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4138,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5243, 0.9334, 0.1322, 0.9240, 0.9852], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6361,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5809e-01, 6.5851e-01, 1.9129e-04, 9.4966e-01, 7.2237e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3757, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 56/5000 [00:20<28:44,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6033, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8314,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.3654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 56/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3033, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3655, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1383, 0.3656, 0.8305, 0.1344, 0.6306], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5034,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5546, 0.9309, 0.1256, 0.9409, 0.9897], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2207,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5043, 0.9363, 0.1465, 0.9034, 0.9748], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5051,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2177e-01, 6.4976e-01, 6.2920e-04, 9.4857e-01, 7.2132e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6860,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0344,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5072, 0.9460, 0.0945, 0.9764, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7274, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7022,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9239, 0.6490, 0.0108, 0.9333, 0.6996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7033,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6688,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6676, 0.9136, 0.0553, 0.9994, 0.9333], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0175, 0.3092, 0.6678, 0.2320, 0.2480], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7228,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9199, 0.6481, 0.0102, 0.9342, 0.7010], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5551, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6032, 0.8695, 0.0932, 0.9230, 0.8990], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6136, 0.8671, 0.0865, 0.9331, 0.9059], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5213, 0.9341, 0.1351, 0.9199, 0.9833], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6124, 0.8842, 0.0591, 0.9949, 0.9316], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5072, 0.9458, 0.0947, 0.9762, 0.9985], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 57/5000 [00:21<29:10,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.4689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5271, 0.9325, 0.1289, 0.9287, 0.9870], device='mps:0')\n",
      "Epoch 57/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0497, 0.3451, 0.7689, 0.1735, 0.4514], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7650, 0.7924, 0.0315, 0.9821, 0.8416], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2517, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0866, 0.6035, 0.5347, 0.3845, 0.6511], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7241, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0160, 0.3009, 0.6747, 0.2259, 0.2368], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5362,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2897e-01, 6.5150e-01, 5.1302e-04, 9.4883e-01, 7.2158e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7502, 0.7696, 0.0422, 0.9368, 0.8173], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3826, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3207,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7358, 0.7730, 0.0500, 0.9160, 0.8036], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7723,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5180, 0.9397, 0.1051, 0.9643, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6479, 0.8699, 0.0657, 0.9880, 0.9277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4861, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 58/5000 [00:21<29:04,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6378,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7902, 0.8006, 0.0310, 0.9830, 0.8422], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2111,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2412, 0.4902, 0.2222, 0.5798, 0.3486], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5072, 0.9463, 0.0941, 0.9769, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7309,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1517,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5862, 0.8723, 0.1023, 0.9094, 0.8885], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9275, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7297,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9186, 0.6479, 0.0100, 0.9345, 0.7014], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.5585,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6400, 0.9020, 0.0565, 0.9980, 0.9328], device='mps:0')\n",
      "Epoch 58/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6689, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4179,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7860, 0.7993, 0.0311, 0.9829, 0.8421], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2275, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1576, 0.6364, 0.6485, 0.2991, 0.7838], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0482,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6246, 0.8746, 0.0625, 0.9914, 0.9296], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1758, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1323, 0.6886, 0.4308, 0.4802, 0.7053], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7758,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6072, 0.8656, 0.0617, 0.9762, 0.9283], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2415,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9466, 0.0938, 0.9772, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6843,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.7590e-01, 6.6279e-01, 6.0335e-05, 9.5007e-01, 7.2272e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0275, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2688, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 59/5000 [00:21<28:42,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4471,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9928, 0.6638, 0.0225, 0.9175, 0.6728], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3621,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2611,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8480, 0.6590, 0.0245, 0.8468, 0.6470], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7723,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5180, 0.9397, 0.1051, 0.9643, 0.9958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.6005,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 59/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7354, 0.7810, 0.0326, 0.9805, 0.8402], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0999,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5456, 0.9464, 0.1050, 0.9746, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1345,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4863, 0.9372, 0.1550, 0.8908, 0.9669], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7884, 0.7728, 0.0398, 0.9711, 0.8283], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6574,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9333, 0.6510, 0.0123, 0.9313, 0.6964], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8607,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8989, 0.6436, 0.0069, 0.9389, 0.7082], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5245, 0.9333, 0.1320, 0.9243, 0.9853], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1861, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6167, 0.8776, 0.0611, 0.9928, 0.9304], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7309,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6298,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9396, 0.6524, 0.0133, 0.9299, 0.6941], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2800,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1364, 0.4113, 0.3273, 0.4848, 0.2390], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3593,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0877, 0.3619, 0.3909, 0.4258, 0.1602], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5626,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1690,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5905, 0.8717, 0.1002, 0.9126, 0.8911], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5274, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8241, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0750,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4838, 0.6187, 0.0854, 0.6806, 0.5221], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5930, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1521, 0.0185, 0.9925, 0.0054, 0.1691], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6309, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 60/5000 [00:22<28:38,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.5913,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4384e-01, 6.5508e-01, 3.2635e-04, 9.4929e-01, 7.2203e-01],\n",
      "       device='mps:0')\n",
      "Epoch 60/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3868,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0508,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4721, 0.6131, 0.0904, 0.6780, 0.5143], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1458, 0.5328, 0.7277, 0.2259, 0.7340], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9466, 0.0938, 0.9772, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6120,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.5016e-01, 6.5660e-01, 2.6235e-04, 9.4946e-01, 7.2219e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4224,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9061, 0.6460, 0.0010, 0.9478, 0.7205], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6884,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9267, 0.6496, 0.0112, 0.9327, 0.6987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3724,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6204, 0.8648, 0.0811, 0.9412, 0.9110], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0310, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2011, 0.8048, 0.4795, 0.4591, 0.8519], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2863,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 61/5000 [00:22<28:28,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7039,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4240, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6550, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3277,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1241,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5785, 0.8732, 0.1061, 0.9038, 0.8839], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7486, 0.7866, 0.0320, 0.9814, 0.8411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6379, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5128, 0.9414, 0.1015, 0.9684, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8952,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8951, 0.6428, 0.0062, 0.9398, 0.7096], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3309,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5290, 0.9620, 0.0929, 0.9870, 0.9986], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4412,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5330, 0.9705, 0.0890, 0.9910, 0.9991], device='mps:0')\n",
      "Epoch 61/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6550,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5668, 0.9928, 0.0829, 0.9974, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3317,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0568, 0.3243, 0.4360, 0.3838, 0.0828], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3799,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1200, 0.3959, 0.3476, 0.4659, 0.2159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7349, 0.7807, 0.0326, 0.9804, 0.8402], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6448, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7168, 0.7803, 0.0608, 0.8987, 0.7875], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1655,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5897, 0.8718, 0.1006, 0.9120, 0.8906], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2792, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5126,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9715, 0.6592, 0.0185, 0.9227, 0.6820], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7354, 0.7656, 0.0362, 0.9467, 0.8272], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7171, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 62/5000 [00:22<29:20,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5862,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5401, 0.9343, 0.1178, 0.9497, 0.9921], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6832,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9965,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5075, 0.9450, 0.0957, 0.9750, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3655,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6198, 0.8650, 0.0816, 0.9404, 0.9106], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4586, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1459, 0.1388, 0.9415, 0.0434, 0.4027], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6068, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6965, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4517, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0599, 0.1706, 0.8729, 0.0857, 0.2427], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6978, 0.7855, 0.0701, 0.8842, 0.7725], device='mps:0')\n",
      "Epoch 62/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6040,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3455,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0373, 0.2978, 0.4665, 0.3556, 0.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9464, 0.0940, 0.9770, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1585,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5383, 0.9503, 0.1012, 0.9785, 0.9976], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6586,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6158, 0.8652, 0.0653, 0.9714, 0.9256], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9465, 0.0939, 0.9771, 0.9987], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6309,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5609, 0.9897, 0.0836, 0.9967, 0.9997], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1724,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4952, 0.9369, 0.1510, 0.8967, 0.9707], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4558,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7815, 0.7727, 0.0391, 0.9719, 0.8294], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4102,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6188, 0.8908, 0.0579, 0.9963, 0.9322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2793,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6106, 0.8679, 0.0886, 0.9300, 0.9038], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3179,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0772, 0.3498, 0.4058, 0.4119, 0.1377], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6654,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6665, 0.9131, 0.0554, 0.9994, 0.9333], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 63/5000 [00:23<28:52,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6689,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5286, 0.9370, 0.1115, 0.9570, 0.9940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1586,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5880, 0.8720, 0.1015, 0.9107, 0.8896], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6929,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6057,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9456, 0.6537, 0.0142, 0.9286, 0.6920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.5333,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9653, 0.6579, 0.0175, 0.9242, 0.6845], device='mps:0')\n",
      "Epoch 63/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5523,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0793,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2608, 0.8259, 0.2551, 0.6384, 0.7871], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5452, 0.9466, 0.1048, 0.9749, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9516,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6387, 0.8714, 0.0645, 0.9893, 0.9284], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0215,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4297, 0.5925, 0.1090, 0.6672, 0.4862], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7434, 0.7845, 0.0322, 0.9811, 0.8408], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3171, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7311, 0.7751, 0.0340, 0.9785, 0.8380], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0586, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1940, 0.7863, 0.5011, 0.4386, 0.8449], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7952,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9077, 0.6455, 0.0083, 0.9369, 0.7051], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8641,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8985, 0.6435, 0.0068, 0.9390, 0.7083], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5619, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5802, 0.9995, 0.0817, 0.9989, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3930, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3284, 0.7285, 0.1754, 0.6672, 0.6580], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2862, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1449, 0.5210, 0.7358, 0.2185, 0.7277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2053,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8852, 0.6409, 0.0024, 0.9455, 0.7177], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6654,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6665, 0.9131, 0.0554, 0.9994, 0.9333], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0912, 0.5173, 0.4454, 0.4328, 0.4692], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.0483,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3398, 0.7357, 0.1679, 0.6728, 0.6644], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 64/5000 [00:23<28:47,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1069, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1815, 0.7484, 0.5429, 0.3988, 0.8302], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0813,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8840, 0.6404, 0.0035, 0.9437, 0.7152], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5457, 0.9807, 0.0857, 0.9944, 0.9995], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6135, 0.8798, 0.0603, 0.9936, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5861, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0026,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4451, 0.6001, 0.1021, 0.6714, 0.4964], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5130, 0.9413, 0.1017, 0.9682, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7347, 0.7740, 0.0346, 0.9777, 0.8370], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0977, 0.5271, 0.4325, 0.4446, 0.4782], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6378,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 65/5000 [00:23<28:59,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1524, 0.5980, 0.6796, 0.2702, 0.7663], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8607,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8989, 0.6436, 0.0069, 0.9389, 0.7082], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5296, 0.9588, 0.0947, 0.9852, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4052,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9035, 0.6453, 0.0011, 0.9477, 0.7204], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7384,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1621,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7032, 0.7842, 0.0675, 0.8882, 0.7767], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6586,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5299, 0.9367, 0.1122, 0.9562, 0.9938], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1964,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7728,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7447, 0.7851, 0.0321, 0.9812, 0.8409], device='mps:0')\n",
      "Epoch 65/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0347,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2447,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6122, 0.8821, 0.0596, 0.9944, 0.9313], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1585, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4826, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3794,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0690, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1913, 0.7788, 0.5096, 0.4304, 0.8420], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0813,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8840, 0.6404, 0.0035, 0.9437, 0.7152], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1071,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2283,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2165, 0.4740, 0.2434, 0.5612, 0.3266], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5308, 0.9567, 0.0961, 0.9837, 0.9982], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3420,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2985, 0.7093, 0.1962, 0.6512, 0.6409], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2862, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1449, 0.5210, 0.7358, 0.2185, 0.7277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7359, 0.7813, 0.0326, 0.9805, 0.8403], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5517, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 66/5000 [00:24<28:54,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9606,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8894, 0.6416, 0.0051, 0.9414, 0.7119], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1620,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6148, 0.8787, 0.0607, 0.9932, 0.9307], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0069, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2073, 0.8194, 0.4619, 0.4758, 0.8573], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 1.2516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Epoch 66/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4792,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5363, 0.9738, 0.0878, 0.9922, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6085,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4908e-01, 6.5634e-01, 2.7278e-04, 9.4943e-01, 7.2216e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5965, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7004,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4517,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0728, 0.4852, 0.4862, 0.3956, 0.4392], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2965, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0649, 0.5347, 0.6093, 0.3161, 0.6042], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9917,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8874, 0.6411, 0.0047, 0.9421, 0.7129], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6522,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5419, 0.9482, 0.1032, 0.9765, 0.9973], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5413,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7610, 0.7726, 0.0373, 0.9743, 0.8325], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0759,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2699, 0.6900, 0.2181, 0.6337, 0.6239], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6757,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9585, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0517,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2506, 0.8170, 0.2660, 0.6289, 0.7820], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8659,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8007, 0.7730, 0.0409, 0.9697, 0.8263], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 67/5000 [00:24<29:10,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3619, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.6488,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Epoch 67/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5861, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1517, 0.0371, 0.9848, 0.0109, 0.2189], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4757,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6262, 0.8952, 0.0572, 0.9970, 0.9325], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3937,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7368, 0.7817, 0.0325, 0.9806, 0.8404], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6102,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6034,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5374, 0.9349, 0.1164, 0.9514, 0.9925], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1829,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4620,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0000, 0.1974, 0.7519, 0.1588, 0.0309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1869, 0.6264, 0.2980, 0.5657, 0.5675], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5169, 0.9349, 0.1387, 0.9147, 0.9809], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4851,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9801, 0.6611, 0.0201, 0.9207, 0.6784], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9193,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8928, 0.6423, 0.0058, 0.9404, 0.7105], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4724,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6861,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9675,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8889, 0.6415, 0.0050, 0.9415, 0.7121], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6978, 0.7855, 0.0701, 0.8842, 0.7725], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0621,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2545, 0.8205, 0.2618, 0.6326, 0.7840], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.3103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1420, 0.4775, 0.7645, 0.1926, 0.7036], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 68/5000 [00:24<29:47,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5586,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6266, 0.8649, 0.0692, 0.9661, 0.9223], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1869, 0.6264, 0.2980, 0.5657, 0.5675], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.5654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7323, 0.7647, 0.0348, 0.9489, 0.8292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 8.6235e-04,  0.0000e+00,  0.0000e+00, -1.3484e+00], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4430, 0.5990, 0.1030, 0.6708, 0.4950], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2895, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5051,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2177e-01, 6.4976e-01, 6.2920e-04, 9.4857e-01, 7.2132e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9447,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6399, 0.8712, 0.0646, 0.9891, 0.9284], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0862, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1858, 0.7549, 0.3449, 0.5587, 0.7454], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4161,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8726, 0.6459, 0.0119, 0.8764, 0.6778], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7896, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0198,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4553, 0.6050, 0.0976, 0.6740, 0.5031], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8027, 0.7730, 0.0411, 0.9694, 0.8260], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 69/5000 [00:25<29:39,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2611,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8480, 0.6590, 0.0245, 0.8468, 0.6470], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6110, 0.8678, 0.0882, 0.9304, 0.9041], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1930,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6133, 0.8799, 0.0603, 0.9937, 0.9309], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0103, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2244, 0.7934, 0.2957, 0.6029, 0.7681], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7191, 0.7795, 0.0596, 0.9007, 0.7894], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5221, 0.9386, 0.1077, 0.9613, 0.9951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4309,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5323, 0.9696, 0.0893, 0.9907, 0.9990], device='mps:0')\n",
      "Epoch 69/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7125,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9219, 0.6486, 0.0105, 0.9338, 0.7003], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3379, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0525, 0.4560, 0.6831, 0.2493, 0.5458], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7623, 0.7723, 0.0470, 0.9289, 0.8082], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5281,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6205,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6541, 0.9081, 0.0558, 0.9987, 0.9331], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9827,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6336, 0.8725, 0.0638, 0.9900, 0.9289], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2105,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.7067,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5812, 1.0000, 0.0816, 0.9990, 1.0000], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4069,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7540, 0.7705, 0.0437, 0.9344, 0.8146], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6121, 0.8832, 0.0593, 0.9947, 0.9314], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6379, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3363,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8947, 0.6432, 0.0014, 0.9470, 0.7196], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7401, 0.7670, 0.0382, 0.9435, 0.8242], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7067,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5000,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 70/5000 [00:25<29:30,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6896,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5261, 0.9376, 0.1101, 0.9586, 0.9944], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4586,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7478, 0.7690, 0.0413, 0.9384, 0.8190], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2249, 0.8554, 0.4162, 0.5193, 0.8707], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0240, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2586,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1108, 0.5456, 0.4078, 0.4671, 0.4951], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4964,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5382, 0.9753, 0.0873, 0.9928, 0.9993], device='mps:0')\n",
      "Epoch 70/5000, Train Loss: 0.0000, Val Loss: 0.0005\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6293, 0.8648, 0.0701, 0.9649, 0.9215], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0302,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4611, 0.6078, 0.0951, 0.6754, 0.5070], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5206,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5513, 0.9317, 0.1239, 0.9429, 0.9903], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0931,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3586, 0.7474, 0.1558, 0.6815, 0.6750], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2366, 0.8046, 0.2815, 0.6154, 0.7747], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6999,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2731,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1473, 0.4211, 0.3143, 0.4968, 0.2532], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0038, 0.2237, 0.7335, 0.1745, 0.1043], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1723,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1310,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6931, 0.7867, 0.0722, 0.8809, 0.7689], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2452, 0.8123, 0.2720, 0.6238, 0.7792], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6508, 0.8694, 0.0660, 0.9876, 0.9275], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5642, 0.9914, 0.0832, 0.9971, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5137,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5526, 0.9314, 0.1246, 0.9421, 0.9900], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1370,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5095, 0.6309, 0.0744, 0.6858, 0.5395], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5448,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5469, 0.9327, 0.1215, 0.9455, 0.9910], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 71/5000 [00:26<29:58,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4206, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9055,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8941, 0.6426, 0.0060, 0.9401, 0.7100], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4034, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1390, 0.2785, 0.8760, 0.0959, 0.5596], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.6240,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6550, 0.9084, 0.0558, 0.9988, 0.9331], device='mps:0')\n",
      "Epoch 71/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6930, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5178,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6586,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5299, 0.9367, 0.1122, 0.9562, 0.9938], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4730,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5792,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6005,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7614, 0.7911, 0.0316, 0.9820, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0371, 0.3947, 0.5884, 0.3029, 0.3489], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4937, 0.9369, 0.1517, 0.8957, 0.9701], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4207,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5247, 0.9333, 0.1317, 0.9246, 0.9854], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2341, 0.6644, 0.2489, 0.6081, 0.6012], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3033,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6127, 0.8849, 0.0590, 0.9951, 0.9316], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9417,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6344, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1586, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1430, 0.7037, 0.4114, 0.4980, 0.7146], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5481, 0.9324, 0.1222, 0.9448, 0.9908], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6379,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6177, 0.8652, 0.0660, 0.9704, 0.9250], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7409, 0.7835, 0.0323, 0.9809, 0.8407], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5057,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9736, 0.6597, 0.0189, 0.9222, 0.6811], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.1482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5394, 0.9496, 0.1019, 0.9779, 0.9975], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 72/5000 [00:26<29:46,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9830,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1950,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8849, 0.6408, 0.0024, 0.9454, 0.7175], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6401,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9372, 0.6519, 0.0129, 0.9305, 0.6950], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4368,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9963, 0.6645, 0.0232, 0.9166, 0.6711], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9378, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4523,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3868,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7401, 0.7670, 0.0382, 0.9435, 0.8242], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7311, 0.7751, 0.0340, 0.9785, 0.8380], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 73/5000 [00:26<29:38,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7137, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6412,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5634, 0.9910, 0.0833, 0.9970, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6689,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6148, 0.8653, 0.0649, 0.9718, 0.9258], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3000,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7329, 0.7743, 0.0519, 0.9131, 0.8010], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4999, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1102, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1105,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5082, 0.9440, 0.0971, 0.9734, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.2214,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2265, 0.4807, 0.2345, 0.5690, 0.3358], device='mps:0')\n",
      "Epoch 73/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4171,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6195, 0.8912, 0.0578, 0.9964, 0.9322], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7068, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4069, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1392, 0.2702, 0.8802, 0.0925, 0.5520], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5471,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9613, 0.6570, 0.0168, 0.9251, 0.6861], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8469,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9006, 0.6440, 0.0072, 0.9385, 0.7076], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5689,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1054,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8837, 0.6404, 0.0033, 0.9441, 0.7158], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6343,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6577, 0.9096, 0.0557, 0.9989, 0.9332], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0663,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3968, 0.5762, 0.1245, 0.6572, 0.4643], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1887,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8272, 0.6680, 0.0340, 0.8305, 0.6256], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2275,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5324, 0.9548, 0.0974, 0.9824, 0.9980], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0965, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1841, 0.7572, 0.5335, 0.4077, 0.8336], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5269, 0.9326, 0.1291, 0.9284, 0.9869], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9275, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6482, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9861, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3001,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|         | 74/5000 [00:27<29:25,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4569,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.1205e-01, 6.4742e-01, 8.2803e-04, 9.4815e-01, 7.2087e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2329,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8865, 0.6412, 0.0021, 0.9459, 0.7181], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0347,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1689, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1664, 0.6869, 0.6039, 0.3410, 0.8055], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1724,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5914, 0.8716, 0.0997, 0.9133, 0.8916], device='mps:0')\n",
      "Epoch 74/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3085, 0.7158, 0.1891, 0.6567, 0.6467], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3378,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6139, 0.8866, 0.0586, 0.9955, 0.9318], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2793,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5127, 0.9355, 0.1416, 0.9105, 0.9788], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7438, 0.7847, 0.0321, 0.9811, 0.8408], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7607, 0.7909, 0.0316, 0.9820, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2378, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5137,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1931,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7118, 0.7818, 0.0634, 0.8947, 0.7835], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5362,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2897e-01, 6.5150e-01, 5.1302e-04, 9.4883e-01, 7.2158e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3793,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7575, 0.7713, 0.0451, 0.9320, 0.8119], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.7240,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9693,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5430,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.3068e-01, 6.5191e-01, 4.8842e-04, 9.4889e-01, 7.2164e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4173,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6867,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5102,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5398, 0.9766, 0.0869, 0.9932, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 75/5000 [00:27<28:55,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4378,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6216, 0.8926, 0.0576, 0.9966, 0.9323], device='mps:0')\n",
      "Epoch 75/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2964,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5294, 0.9595, 0.0943, 0.9856, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0517,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3414, 0.7367, 0.1669, 0.6735, 0.6653], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7357, 0.7657, 0.0363, 0.9465, 0.8271], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6240,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5594, 0.9889, 0.0838, 0.9965, 0.9997], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.4551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0012, 0.2062, 0.7458, 0.1640, 0.0591], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4310,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6459, 0.8639, 0.0754, 0.9577, 0.9164], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0931,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2656, 0.8299, 0.2501, 0.6427, 0.7895], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7127, 0.7815, 0.0629, 0.8954, 0.7842], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4379,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5256, 0.9330, 0.1307, 0.9261, 0.9860], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5689,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 76/5000 [00:27<28:48,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7417, 0.7674, 0.0388, 0.9424, 0.8231], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2413, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0275,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6271, 0.8739, 0.0628, 0.9910, 0.9294], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2352,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2063, 0.4669, 0.2527, 0.5528, 0.3170], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7673, 0.7932, 0.0315, 0.9822, 0.8417], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8366,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9019, 0.6443, 0.0074, 0.9382, 0.7071], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3896, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1384, 0.3111, 0.8595, 0.1097, 0.5880], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3626, 0.7498, 0.1533, 0.6833, 0.6772], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1862,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7100, 0.7823, 0.0642, 0.8933, 0.7821], device='mps:0')\n",
      "Epoch 76/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5370, 0.9744, 0.0876, 0.9925, 0.9992], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5206,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7607, 0.7909, 0.0316, 0.9820, 0.8415], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5000,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5553, 0.9307, 0.1260, 0.9405, 0.9896], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5550, 0.9864, 0.0843, 0.9960, 0.9996], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2552,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7254, 0.7773, 0.0562, 0.9061, 0.7946], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5757,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6436, 0.9036, 0.0563, 0.9982, 0.9329], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5952, 0.8710, 0.0977, 0.9163, 0.8940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5069,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6336, 0.8646, 0.0715, 0.9630, 0.9202], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7407, 0.7672, 0.0384, 0.9431, 0.8237], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2404,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8428, 0.6615, 0.0270, 0.8426, 0.6416], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1896,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1773, 0.6179, 0.3094, 0.5557, 0.5600], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8965,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5102, 0.9426, 0.0993, 0.9709, 0.9973], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 77/5000 [00:28<29:42,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6016,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4695e-01, 6.5583e-01, 2.9396e-04, 9.4938e-01, 7.2211e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2069,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5988, 0.8704, 0.0957, 0.9192, 0.8962], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4896,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8310,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5137, 0.9411, 0.1021, 0.9676, 0.9966], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7405, 0.7834, 0.0323, 0.9809, 0.8407], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2266,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8390, 0.6631, 0.0287, 0.8395, 0.6377], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.6688,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8002, 0.8038, 0.0309, 0.9833, 0.8423], device='mps:0')\n",
      "Epoch 77/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5344,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6160,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9430, 0.6531, 0.0138, 0.9292, 0.6929], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6466, 0.9049, 0.0561, 0.9984, 0.9330], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9447,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5085, 0.9437, 0.0974, 0.9730, 0.9978], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6723, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5448,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6122, 0.8834, 0.0593, 0.9947, 0.9315], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6171, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6929, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5171,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4988,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9757, 0.6601, 0.0193, 0.9217, 0.6803], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1654,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6146, 0.8789, 0.0606, 0.9933, 0.9307], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6033, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1103, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1806, 0.7454, 0.5461, 0.3958, 0.8290], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2366, 0.8046, 0.2815, 0.6154, 0.7747], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3225,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8933, 0.6429, 0.0015, 0.9469, 0.7194], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8861,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5107, 0.9424, 0.0997, 0.9704, 0.9972], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 78/5000 [00:28<29:37,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9137,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6458, 0.8702, 0.0654, 0.9883, 0.9279], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0516, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.6413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5321, 0.9361, 0.1135, 0.9547, 0.9934], device='mps:0')\n",
      "Epoch 78/5000, Train Loss: 0.0000, Val Loss: 0.0006\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3828,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2915,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8904, 0.6422, 0.0017, 0.9466, 0.7190], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2944, 0.7065, 0.1993, 0.6488, 0.6385], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1382, 0.3427, 0.8430, 0.1237, 0.6134], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9761,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8344, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3558,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0772, 0.3498, 0.4058, 0.4119, 0.1377], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1877, 0.7683, 0.5213, 0.4193, 0.8380], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3294,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8940, 0.6430, 0.0015, 0.9470, 0.7195], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2792,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5298, 0.9583, 0.0950, 0.9849, 0.9983], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.2895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0629,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3996, 0.5776, 0.1231, 0.6581, 0.4661], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5034,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7431, 0.7678, 0.0394, 0.9415, 0.8222], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2103,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7160, 0.7805, 0.0612, 0.8981, 0.7869], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0414, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1984, 0.7981, 0.4874, 0.4516, 0.8493], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1102,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6183, 0.8768, 0.0614, 0.9924, 0.9302], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0654, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0103, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2244, 0.7934, 0.2957, 0.6029, 0.7681], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1655,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1993, 0.6369, 0.2840, 0.5779, 0.5769], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6929, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.0129,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 79/5000 [00:28<29:30,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4513, 0.6031, 0.0994, 0.6730, 0.5005], device='mps:0')\n",
      "Epoch 79/5000, Train Loss: 0.0000, Val Loss: 0.0010\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5481,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5451, 0.9804, 0.0858, 0.9943, 0.9994], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7413, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.4895, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.1309, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7763,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5643,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9565, 0.6560, 0.0160, 0.9262, 0.6879], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0207,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3046, 0.7132, 0.1919, 0.6546, 0.6444], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0095,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4493, 0.6021, 0.1003, 0.6724, 0.4991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4619,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5347, 0.9722, 0.0884, 0.9917, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2482,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6121, 0.8823, 0.0596, 0.9944, 0.9313], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 80/5000 [00:29<28:57,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4379,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7502, 0.7696, 0.0422, 0.9368, 0.8173], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8952,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8951, 0.6428, 0.0062, 0.9398, 0.7096], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9620, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0571,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8845, 0.6405, 0.0038, 0.9433, 0.7146], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6505,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9348, 0.6514, 0.0125, 0.9310, 0.6958], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6929,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6752, 0.9166, 0.0551, 0.9997, 0.9334], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6929,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2516, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([1.6343, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Epoch 80/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2724,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0977, 0.5271, 0.4325, 0.4446, 0.4782], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5482, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4517,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7486, 0.7692, 0.0416, 0.9379, 0.8184], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7345, 0.7741, 0.0346, 0.9777, 0.8371], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0379, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1993, 0.8004, 0.4847, 0.4541, 0.8502], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2000, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1172, 0.6651, 0.4605, 0.4528, 0.6907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7350, 0.7740, 0.0347, 0.9776, 0.8370], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0112,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4365, 0.5959, 0.1059, 0.6691, 0.4907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6724,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5282, 0.9371, 0.1112, 0.9573, 0.9941], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4550,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5341, 0.9716, 0.0886, 0.9915, 0.9991], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8930,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6500, 0.8695, 0.0659, 0.9877, 0.9276], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7343, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4948,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.1953e-01, 6.4922e-01, 6.6994e-04, 9.4848e-01, 7.2123e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5275,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7407, 0.7672, 0.0384, 0.9431, 0.8237], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1551,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7068,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 81/5000 [00:29<28:40,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0520, 0.2922, 0.8037, 0.1434, 0.3988], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5073, 0.9455, 0.0950, 0.9758, 0.9984], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5069,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6336, 0.8646, 0.0715, 0.9630, 0.9202], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6206,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6195, 0.8651, 0.0667, 0.9695, 0.9244], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.4172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0051, 0.2325, 0.7273, 0.1799, 0.1235], device='mps:0')\n",
      "Epoch 81/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3792,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6163, 0.8889, 0.0582, 0.9959, 0.9320], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0610, 0.5165, 0.6275, 0.2996, 0.5911], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4964,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5382, 0.9753, 0.0873, 0.9928, 0.9993], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5155,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.2408e-01, 6.5032e-01, 5.8952e-04, 9.4866e-01, 7.2141e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6413,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8620,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6569, 0.8685, 0.0669, 0.9867, 0.9270], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7004,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0828,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2288, 0.8626, 0.4067, 0.5283, 0.8734], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6895,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5761, 0.9975, 0.0820, 0.9985, 0.9999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.2482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1208, 0.5585, 0.3904, 0.4829, 0.5068], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7137, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5827,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5406, 0.9342, 0.1181, 0.9494, 0.9920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1930,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4138,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5243, 0.9334, 0.1322, 0.9240, 0.9852], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4018,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9030, 0.6452, 0.0011, 0.9477, 0.7203], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0827,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2651, 0.6867, 0.2220, 0.6305, 0.6209], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5344,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6298, 0.8648, 0.0702, 0.9647, 0.9214], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3363,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8947, 0.6432, 0.0014, 0.9470, 0.7196], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0560,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4049, 0.5803, 0.1206, 0.6598, 0.4697], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 82/5000 [00:29<29:17,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0138,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3085, 0.7158, 0.1891, 0.6567, 0.6467], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.2145,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2364, 0.4871, 0.2262, 0.5763, 0.3444], device='mps:0')\n",
      "Epoch 82/5000, Train Loss: 0.0000, Val Loss: 0.0004\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2655,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5109, 0.9357, 0.1427, 0.9089, 0.9779], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9309, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5965,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7348, 0.7655, 0.0359, 0.9471, 0.8276], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6241,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7328, 0.7648, 0.0350, 0.9485, 0.8289], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.7274, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8620,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5119, 0.9418, 0.1007, 0.9693, 0.9970], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6172, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0222, 0.3336, 0.6467, 0.2507, 0.2792], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1345, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1578, 0.7227, 0.3867, 0.5207, 0.7262], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9827, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4540,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9904, 0.6632, 0.0220, 0.9181, 0.6739], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5827,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5406, 0.9342, 0.1181, 0.9494, 0.9920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0112,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4365, 0.5959, 0.1059, 0.6691, 0.4907], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5947,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4487e-01, 6.5533e-01, 3.1547e-04, 9.4932e-01, 7.2206e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6378, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0405,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4667, 0.6105, 0.0927, 0.6767, 0.5107], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5309,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6348, 0.8996, 0.0567, 0.9977, 0.9327], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7388, 0.7666, 0.0376, 0.9443, 0.8250], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1896,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4987, 0.9367, 0.1493, 0.8992, 0.9723], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7068, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 83/5000 [00:30<30:02,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.3895,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6171, 0.8895, 0.0581, 0.9961, 0.9321], device='mps:0')\n",
      "Epoch 83/5000, Train Loss: 0.0000, Val Loss: 0.0003\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3241, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1407, 0.4512, 0.7809, 0.1779, 0.6879], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1939,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2646, 0.5046, 0.2039, 0.5955, 0.3681], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7487,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7366,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9174, 0.6476, 0.0098, 0.9347, 0.7018], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.4896, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1509, 0.0557, 0.9771, 0.0166, 0.2612], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4000,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5235, 0.9336, 0.1330, 0.9228, 0.9846], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4241,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5249, 0.9332, 0.1315, 0.9249, 0.9855], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8693,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6309, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.3466,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8958, 0.6435, 0.0014, 0.9471, 0.7197], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 84/5000 [00:30<29:31,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3207, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1410, 0.4579, 0.7768, 0.1815, 0.6920], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1896,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5952, 0.8710, 0.0977, 0.9163, 0.8940], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9378,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6827,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5269, 0.9374, 0.1105, 0.9581, 0.9943], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8413,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5130, 0.9413, 0.1017, 0.9682, 0.9967], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2171, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.1758, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1648, 0.6791, 0.6112, 0.3342, 0.8022], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3403,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8768, 0.6519, 0.0167, 0.8673, 0.6654], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2723, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.6310, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.1172,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5764, 0.8735, 0.1071, 0.9024, 0.8826], device='mps:0')\n",
      "Epoch 84/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0899,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1723,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6142, 0.8791, 0.0605, 0.9934, 0.9308], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7172,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.8004,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0405,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4667, 0.6105, 0.0927, 0.6767, 0.5107], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9792, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3550, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3586, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1385, 0.3805, 0.8223, 0.1415, 0.6414], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8447, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3104,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1172,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4817, 0.9373, 0.1570, 0.8880, 0.9649], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.2654, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7103, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.2552,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6071, 0.8687, 0.0908, 0.9266, 0.9015], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.5619,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7697, 0.7940, 0.0314, 0.9823, 0.8417], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 85/5000 [00:31<29:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9245,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.0862,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2632, 0.8279, 0.2526, 0.6406, 0.7884], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6033,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7802, 0.7974, 0.0312, 0.9827, 0.8420], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.8779,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8969, 0.6432, 0.0065, 0.9394, 0.7089], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4482,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5262, 0.9328, 0.1301, 0.9270, 0.9864], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3793, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0493, 0.3621, 0.7569, 0.1839, 0.4671], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-0.5482,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7388, 0.7666, 0.0376, 0.9443, 0.8250], device='mps:0')\n",
      "Epoch 85/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9934,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2965, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1436, 0.5027, 0.7481, 0.2074, 0.7178], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0585,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6234, 0.8750, 0.0623, 0.9916, 0.9297], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5344,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3378, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7556,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7103,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6115, 0.8654, 0.0636, 0.9737, 0.9269], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6412,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5634, 0.9910, 0.0833, 0.9970, 0.9998], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3438,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8766, 0.6516, 0.0165, 0.8678, 0.6660], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6412,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5275,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0827, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4471,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9928, 0.6638, 0.0225, 0.9175, 0.6728], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.5729,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.8516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.7551,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5195, 0.9393, 0.1061, 0.9632, 0.9955], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1999,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.0623,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.6033, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.2068,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6129, 0.8805, 0.0601, 0.9939, 0.9310], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 86/5000 [00:31<28:36,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.3035,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([-1.4224,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9061, 0.6460, 0.0010, 0.9478, 0.7205], device='mps:0')\n",
      "Epoch 86/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0491,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.4101, 0.5829, 0.1181, 0.6614, 0.4732], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.9896, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.0448,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2902, 0.7037, 0.2024, 0.6463, 0.6360], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6051,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([9.4801e-01, 6.5608e-01, 2.8330e-04, 9.4940e-01, 7.2213e-01],\n",
      "       device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.5609,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.9574, 0.6562, 0.0161, 0.9260, 0.6876], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.3300,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8774, 0.6527, 0.0174, 0.8659, 0.6634], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1033,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5452, 0.9466, 0.1048, 0.9749, 0.9971], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6213, 0.8651, 0.0673, 0.9686, 0.9239], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3171, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.0276, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.2020, 0.8070, 0.4769, 0.4616, 0.8527], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.5413, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5413,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0895, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9516,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5083, 0.9439, 0.0972, 0.9733, 0.9979], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.4379,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.3000, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0636, 0.5288, 0.6153, 0.3106, 0.5999], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.6758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7997, 0.7730, 0.0408, 0.9698, 0.8265], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.9034,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6479, 0.8699, 0.0657, 0.9880, 0.9277], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.1105,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.6103,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([ 0.9447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 87/5000 [00:31<29:13,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4585,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7496, 0.7870, 0.0319, 0.9815, 0.8411], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2793, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1458, 0.5328, 0.7277, 0.2259, 0.7340], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.6488,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.3102, 0.0000, 0.0000, 1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1523, 0.0092, 0.9962, 0.0027, 0.1399], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.1414,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6967, 0.7858, 0.0706, 0.8834, 0.7716], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.7516, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0433,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8850, 0.6406, 0.0040, 0.9431, 0.7143], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0068,  0.0000,  0.0000,  0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.6300, 0.8733, 0.0633, 0.9905, 0.9292], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9654,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([0.2655, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0792, 0.5841, 0.5568, 0.3642, 0.6381], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.9658,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 1.5516,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0025, 0.2150, 0.7397, 0.1692, 0.0831], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.1447,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7304, 0.7755, 0.0338, 0.9788, 0.8383], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([1.0378, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0617, 0.1323, 0.8923, 0.0702, 0.1729], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|         | 87/5000 [00:32<30:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.3351,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1200, 0.3959, 0.3476, 0.4659, 0.2159], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.0758,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7332, 0.7744, 0.0344, 0.9780, 0.8374], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-0.4138,  0.0000,  0.0000,  1.3229], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.5243, 0.9334, 0.1322, 0.9240, 0.9852], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.1387,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.3300, 0.5416, 0.1603, 0.6310, 0.4179], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.4792,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.7530, 0.7882, 0.0318, 0.9816, 0.8413], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([-1.6895,  0.0000,  0.0000, -0.4579], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.8075, 0.8061, 0.0307, 0.9835, 0.8424], device='mps:0')\n",
      "Shape of X_batch: torch.Size([128, 4])\n",
      "Shape of Y_batch: torch.Size([128, 5])\n",
      "Sample from X_batch: tensor([ 0.7556,  0.0000,  0.0000, -1.3484], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.1037, 0.3794, 0.3689, 0.4462, 0.1898], device='mps:0')\n",
      "Shape of X_batch: torch.Size([112, 4])\n",
      "Shape of Y_batch: torch.Size([112, 5])\n",
      "Sample from X_batch: tensor([0.3069, 0.0000, 0.0000, 0.4325], device='mps:0')\n",
      "Sample from Y_batch: tensor([0.0610, 0.5165, 0.6275, 0.2996, 0.5911], device='mps:0')\n",
      "Epoch 88/5000, Train Loss: 0.0000, Val Loss: 0.0002\n",
      "Early stopping triggered. Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_constraints(predictions, bounds):\n",
    "    # \"\"\"Checks if predictions satisfy the given bounds.\"\"\"\n",
    "    # for i, (lower, upper) in enumerate(bounds):\n",
    "    #     if not (torch.all(predictions[:, i] >= lower) and torch.all(predictions[:, i] <= upper)):\n",
    "    #         return False\n",
    "    return True\n",
    "\n",
    "max_retries = 1\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
    "    model.train()\n",
    "    train_loss = 0  # Track training loss for this epoch\n",
    "\n",
    "    # Inside the training\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        print(\"Shape of X_batch:\", X_batch.shape)\n",
    "        print(\"Shape of Y_batch:\", Y_batch.shape)\n",
    "        # Print the first few values to check their range\n",
    "        print(\"Sample from X_batch:\", X_batch[0])\n",
    "        print(\"Sample from Y_batch:\", Y_batch[0])\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(X_batch.to(device))\n",
    "        # batch_loss = compute_loss(predictions, Y_batch.to(device), bounds=bounds)\n",
    "        batch_loss = compute_loss(predictions, Y_batch.to(device), X_batch, 1e8)\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # Gradient clipping to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += batch_loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation step\n",
    "    current_val_loss = validate(model, val_loader, criterion, device)\n",
    "    # val_loss, violations = validate_and_check_constraints(model, val_loader, criterion, device, bounds)\n",
    "    # Print training and validation loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {current_val_loss:.4f}\")\n",
    "\n",
    "    # # Learning rate adjustment\n",
    "    scheduler.step(current_val_loss)\n",
    "        \n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        early_stop_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        \n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered. Training complete.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017304040084127338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_val_loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_68715/3831933047.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for inference\n",
    "model = BB84NN().to(device)\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluation and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predicted Parameters:\n",
      "Fiber Length 0.1 km -> [0.35578892 1.341923   0.723397   0.68539524 1.3840022 ]\n",
      "Fiber Length 1.1 km -> [0.35472682 1.3390417  0.72628105 0.6808734  1.3823754 ]\n",
      "Fiber Length 2.1 km -> [0.35348454 1.3358681  0.72961056 0.6757824  1.3805871 ]\n",
      "Fiber Length 3.1 km -> [0.35219607 1.3327045  0.7329711  0.6707268  1.378794  ]\n",
      "Fiber Length 4.1 km -> [0.35086387 1.3295122  0.73636407 0.6656081  1.3769754 ]\n",
      "Fiber Length 5.1 km -> [0.34949628 1.3262949  0.7397851  0.660436   1.3751353 ]\n",
      "Fiber Length 6.1 km -> [0.34812877 1.3230785  0.74320745 0.65526325 1.3732963 ]\n",
      "Fiber Length 7.1 km -> [0.34676427 1.3198793  0.74660337 0.65011746 1.3714582 ]\n",
      "Fiber Length 8.1 km -> [0.3454088  1.3167076  0.74995124 0.64501935 1.3696228 ]\n",
      "Fiber Length 9.1 km -> [0.34405765 1.3135519  0.75327456 0.6399507  1.367792  ]\n",
      "Fiber Length 10.1 km -> [0.34276667 1.3102802  0.7566278  0.6350663  1.3660645 ]\n",
      "Fiber Length 11.1 km -> [0.34145835 1.3070098  0.7600112  0.6302027  1.3643559 ]\n",
      "Fiber Length 12.2 km -> [0.340122   1.3037052  0.76348037 0.62524855 1.3626512 ]\n",
      "Fiber Length 13.2 km -> [0.33878267 1.3003976  0.7669465  0.62029356 1.3609422 ]\n",
      "Fiber Length 14.2 km -> [0.33744416 1.2970914  0.77040297 0.6153457  1.3592306 ]\n",
      "Fiber Length 15.2 km -> [0.3361067 1.293786  0.7738534 0.6104025 1.3575182]\n",
      "Fiber Length 16.2 km -> [0.33476916 1.2904806  0.77730405 0.6054593  1.3558056 ]\n",
      "Fiber Length 17.2 km -> [0.3334317  1.2871752  0.78075445 0.60051626 1.3540931 ]\n",
      "Fiber Length 18.2 km -> [0.3320636  1.2838857  0.78423035 0.5955602  1.3523823 ]\n",
      "Fiber Length 19.2 km -> [0.33063164 1.2804537  0.7879359  0.59033734 1.3506418 ]\n",
      "Fiber Length 20.2 km -> [0.32919148 1.2770212  0.7916263  0.5851236  1.3488952 ]\n",
      "Fiber Length 21.2 km -> [0.3277514  1.273589   0.79531443 0.57991165 1.3471482 ]\n",
      "Fiber Length 22.2 km -> [0.32628733 1.2701256  0.7990282  0.57465345 1.3453821 ]\n",
      "Fiber Length 23.2 km -> [0.3248606  1.2666461  0.8027851  0.56936747 1.3435959 ]\n",
      "Fiber Length 24.2 km -> [0.3234586  1.26317    0.80655694 0.5640813  1.3418072 ]\n",
      "Fiber Length 25.2 km -> [0.3220968  1.2596889  0.81040007 0.5587881  1.3400353 ]\n",
      "Fiber Length 26.2 km -> [0.32160327 1.255713   0.8156244  0.5534154  1.3384854 ]\n",
      "Fiber Length 27.2 km -> [0.3211522 1.2517078 0.8209386 0.5480299 1.33695  ]\n",
      "Fiber Length 28.2 km -> [0.32070154 1.2477114  0.82625896 0.54264766 1.335422  ]\n",
      "Fiber Length 29.2 km -> [0.32025087 1.243715   0.83157945 0.53726536 1.3338939 ]\n",
      "Fiber Length 30.2 km -> [0.3197957 1.2397172 0.8369405 0.5318657 1.3323745]\n",
      "Fiber Length 31.2 km -> [0.31900725 1.2357749  0.8419297  0.52732366 1.3309909 ]\n",
      "Fiber Length 32.2 km -> [0.31813717 1.2318575  0.8467848  0.52302843 1.3296481 ]\n",
      "Fiber Length 33.2 km -> [0.3172671  1.227941   0.85163844 0.5187342  1.3283058 ]\n",
      "Fiber Length 34.3 km -> [0.31639218 1.2240279  0.856491   0.51444715 1.3269626 ]\n",
      "Fiber Length 35.3 km -> [0.31543422 1.2204003  0.8611704  0.5105545  1.325645  ]\n",
      "Fiber Length 36.3 km -> [0.31447387 1.2168117  0.8658109  0.50671494 1.3243401 ]\n",
      "Fiber Length 37.3 km -> [0.3135242  1.2132812  0.8703979  0.50293356 1.32306   ]\n",
      "Fiber Length 38.3 km -> [0.3125826  1.209795   0.8749448  0.49919626 1.3217992 ]\n",
      "Fiber Length 39.3 km -> [0.31165078 1.206323   0.8794805  0.4954642  1.320556  ]\n",
      "Fiber Length 40.3 km -> [0.31074545 1.2028619  0.8839823  0.4917283  1.3193454 ]\n",
      "Fiber Length 41.3 km -> [0.30982718 1.1994164  0.8884517  0.4880409  1.3181216 ]\n",
      "Fiber Length 42.3 km -> [0.30890253 1.1959772  0.8929095  0.48437417 1.3168919 ]\n",
      "Fiber Length 43.3 km -> [0.30800173 1.1923919  0.8971833  0.4808968  1.3157189 ]\n",
      "Fiber Length 44.3 km -> [0.30710733 1.1885815  0.9012749  0.47762513 1.3145921 ]\n",
      "Fiber Length 45.3 km -> [0.30616024 1.1845922  0.90543544 0.47424752 1.3133582 ]\n",
      "Fiber Length 46.3 km -> [0.3052312  1.1802346  0.90987515 0.47055164 1.3121034 ]\n",
      "Fiber Length 47.3 km -> [0.30426005 1.1757076  0.9144757  0.46673185 1.3108453 ]\n",
      "Fiber Length 48.3 km -> [0.30327332 1.1709244  0.9195744  0.4626144  1.3094558 ]\n",
      "Fiber Length 49.3 km -> [0.30228505 1.166102   0.9247246  0.45845997 1.30802   ]\n",
      "Fiber Length 50.3 km -> [0.3012953  1.1612923  0.92981327 0.4543339  1.3065698 ]\n",
      "Fiber Length 51.3 km -> [0.30030578 1.1564837  0.9348953  0.4502104  1.305118  ]\n",
      "Fiber Length 52.3 km -> [0.29931846 1.151694   0.93995345 0.4461079  1.3036605 ]\n",
      "Fiber Length 53.3 km -> [0.29851446 1.1469458  0.9448668  0.44239157 1.3021399 ]\n",
      "Fiber Length 54.3 km -> [0.29772407 1.1422002  0.9497771  0.43869898 1.3006201 ]\n",
      "Fiber Length 55.3 km -> [0.29693413 1.137456   0.9546783  0.43500918 1.2990974 ]\n",
      "Fiber Length 56.4 km -> [0.29613912 1.1327567  0.9594557  0.43138418 1.297558  ]\n",
      "Fiber Length 57.4 km -> [0.29534245 1.1280594  0.9642308  0.42776257 1.2960186 ]\n",
      "Fiber Length 58.4 km -> [0.294547   1.1234039  0.9689442  0.42417926 1.2944814 ]\n",
      "Fiber Length 59.4 km -> [0.29374647 1.118771   0.97362626 0.42061257 1.2929412 ]\n",
      "Fiber Length 60.4 km -> [0.29294592 1.1141381  0.9783083  0.41704583 1.2914011 ]\n",
      "Fiber Length 61.4 km -> [0.29215106 1.1094867  0.9830047  0.4134597  1.2898573 ]\n",
      "Fiber Length 62.4 km -> [0.29138678 1.1049713  0.9875773  0.40996906 1.2883695 ]\n",
      "Fiber Length 63.4 km -> [0.29066008 1.100696   0.99188983 0.40667    1.2869546 ]\n",
      "Fiber Length 64.4 km -> [0.28994614 1.0964922  0.99615514 0.40341917 1.2855752 ]\n",
      "Fiber Length 65.4 km -> [0.2892381  1.0923105  1.0004213  0.40017754 1.284214  ]\n",
      "Fiber Length 66.4 km -> [0.2885302  1.0881573  1.0046508  0.39696315 1.2828583 ]\n",
      "Fiber Length 67.4 km -> [0.28782454 1.0840312  1.0088525  0.39377174 1.281511  ]\n",
      "Fiber Length 68.4 km -> [0.2871256  1.0799611  1.0130036  0.39062402 1.2801849 ]\n",
      "Fiber Length 69.4 km -> [0.28639936 1.0757432  1.0173715  0.38737786 1.2787606 ]\n",
      "Fiber Length 70.4 km -> [0.28562453 1.0713072  1.0220879  0.38398674 1.2771922 ]\n",
      "Fiber Length 71.4 km -> [0.28485018 1.0668741  1.0268055  0.380597   1.2756269 ]\n",
      "Fiber Length 72.4 km -> [0.2840817 1.062454  1.0315078 0.3772143 1.2740622]\n",
      "Fiber Length 73.4 km -> [0.2833463 1.0581837 1.0361298 0.3739038 1.272489 ]\n",
      "Fiber Length 74.4 km -> [0.28259534 1.053917   1.0407919  0.3705905  1.2709148 ]\n",
      "Fiber Length 75.4 km -> [0.28184927 1.049659   1.0454332  0.36728793 1.2693409 ]\n",
      "Fiber Length 76.4 km -> [0.28109908 1.0453883  1.0501175  0.36399356 1.2677685 ]\n",
      "Fiber Length 77.4 km -> [0.2804277 1.0414771 1.0541111 0.3610397 1.2662252]\n",
      "Fiber Length 78.5 km -> [0.27985013 1.0379789  1.0572903  0.35847616 1.2647134 ]\n",
      "Fiber Length 79.5 km -> [0.27927053 1.0344727  1.060484   0.35590583 1.2631973 ]\n",
      "Fiber Length 80.5 km -> [0.27869335 1.0309687  1.0636737  0.35333675 1.2616798 ]\n",
      "Fiber Length 81.5 km -> [0.2781199 1.0273823 1.0669758 0.3506925 1.2601537]\n",
      "Fiber Length 82.5 km -> [0.2775356  1.0236807  1.0704215  0.34794843 1.2585986 ]\n",
      "Fiber Length 83.5 km -> [0.27695125 1.0199792  1.0738672  0.3452044  1.2570435 ]\n",
      "Fiber Length 84.5 km -> [0.27669382 1.0164733  1.0771974  0.34253344 1.2554215 ]\n",
      "Fiber Length 85.5 km -> [0.27648568 1.012549   1.0808173  0.33950508 1.2534755 ]\n",
      "Fiber Length 86.5 km -> [0.27623954 1.0086207  1.0841215  0.33674976 1.251552  ]\n",
      "Fiber Length 87.5 km -> [0.275993   1.0046921  1.0874234  0.33399627 1.2496284 ]\n",
      "Fiber Length 88.5 km -> [0.27574497 1.0007745  1.0907077  0.33125386 1.2477046 ]\n",
      "Fiber Length 89.5 km -> [0.27549654 0.99686843 1.0939801  0.32852072 1.2457852 ]\n",
      "Fiber Length 90.5 km -> [0.27523118 0.9928568  1.0972761  0.3257342  1.2437893 ]\n",
      "Fiber Length 91.5 km -> [0.27493066 0.98864704 1.1006036  0.32285282 1.2416446 ]\n",
      "Fiber Length 92.5 km -> [0.27463526 0.9844547  1.1039566  0.31997257 1.2395233 ]\n",
      "Fiber Length 93.5 km -> [0.27437568 0.9796873  1.1075935  0.31670815 1.2370777 ]\n",
      "Fiber Length 94.5 km -> [0.2745488 0.974299  1.111122  0.3129603 1.2342428]\n",
      "Fiber Length 95.5 km -> [0.2747286  0.9688465  1.1147577  0.30915394 1.2313269 ]\n",
      "Fiber Length 96.5 km -> [0.27493334 0.963134   1.1187396  0.30511254 1.228177  ]\n",
      "Fiber Length 97.5 km -> [0.2751367  0.9574614  1.1226889  0.30110002 1.2250473 ]\n",
      "Fiber Length 98.5 km -> [0.27534372 0.9518387  1.1266978  0.29710293 1.2219698 ]\n",
      "Fiber Length 99.5 km -> [0.27553993 0.94625145 1.1306704  0.29314253 1.2189051 ]\n"
     ]
    }
   ],
   "source": [
    "# # Load the trained model\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define fiber length range and fixed n_X value\n",
    "fiber_lengths = np.linspace(0.1, 200, 200)  # Fiber lengths from 0.1 km to 200 km\n",
    "P_dc_value = 6e-7  # Example value (adjust as needed)\n",
    "e_mis = 5e-3       # Example misalignment error (adjust as needed)\n",
    "target_nx = 1e8   # Fixed n_X value\n",
    "\n",
    "# Prepare inputs for the neural network\n",
    "predicted_params_list = []\n",
    "\n",
    "for L in fiber_lengths:\n",
    "    e_1 = L / 100  # Normalized fiber length\n",
    "    e_2 = -np.log10(P_dc_value)  # Dark count processing\n",
    "    e_3 = e_mis * 100  # Misalignment error\n",
    "    e_4 = np.log10(target_nx)  # Log-scaled detected events\n",
    "    \n",
    "    # Construct input tensor\n",
    "    X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        params = model(X).cpu().numpy()[0]\n",
    "        predicted_params_list.append(params)\n",
    "\n",
    "# Convert predicted parameters to numpy array\n",
    "predicted_params_array = np.array(predicted_params_list)\n",
    "\n",
    "# Display example predictions\n",
    "print(\"Example Predicted Parameters:\")\n",
    "for i in range(100):\n",
    "    print(f\"Fiber Length {fiber_lengths[i]:.1f} km -> {predicted_params_array[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted_params_list)):\n",
    "    mu_1, mu_2, P_mu_1, P_mu_2, P_X = predicted_params_list[i]\n",
    "\n",
    "    # predicted_params_list[i] = [mu_1, mu_2, P_mu_1, P_mu_2, P_X, P_mu_3, P_Z]\n",
    "    predicted_params_list[i] = [mu_1, mu_2, P_mu_1, P_mu_2, P_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_68715/1272838697.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_68715/1272838697.py:54: RuntimeWarning: divide by zero encountered in log10\n",
      "  ax1.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
      "/var/folders/8m/0wg1hssn6n79tjc8mh6p_spr0000gn/T/ipykernel_68715/1272838697.py:55: RuntimeWarning: invalid value encountered in log10\n",
      "  ax1.plot(fiber_lengths, np.log10(predicted_key_rates), 'r--', label=\"Predicted Key Rate (NN)\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from QKD_Functions.QKD_Functions import objective\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = BB84NN().to(device)\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"../Training_Data/single_nx/reordered_qkd_grouped_dataset_20250224_112957.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Select an n_X value\n",
    "target_nx = 500000000\n",
    "nx_key = str(float(target_nx))\n",
    "if nx_key not in dataset:\n",
    "    raise ValueError(f\"No data found for n_X = {target_nx}\")\n",
    "\n",
    "optimized_data = dataset[nx_key]\n",
    "\n",
    "# Extract fiber lengths, optimized key rates, and parameters\n",
    "fiber_lengths = np.array([entry[\"fiber_length\"] for entry in optimized_data])\n",
    "optimized_key_rates = np.array([entry[\"key_rate\"] for entry in optimized_data])\n",
    "optimized_params_array = np.array([list(entry[\"optimized_params\"].values()) for entry in optimized_data])\n",
    "\n",
    "# Predict parameters and key rates\n",
    "predicted_params_list = []\n",
    "predicted_key_rates = []\n",
    "for L in fiber_lengths:\n",
    "    e_1 = L / 100\n",
    "    e_2 = -np.log10(6e-7)\n",
    "    e_3 = 5e-3 * 100\n",
    "    e_4 = np.log10(target_nx)\n",
    "    X = torch.tensor([[e_1, e_2, e_3, e_4]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        params = model(X).cpu().numpy()[0]\n",
    "        predicted_params_list.append(params)\n",
    "        key_rate = objective(params, L, target_nx, alpha=0.2, eta_Bob=0.1, P_dc_value=6e-7, epsilon_sec=1e-10, epsilon_cor=1e-15, f_EC=1.16, e_mis=5e-3, P_ap=4e-2, n_event=1)[0]\n",
    "        predicted_key_rates.append(key_rate)\n",
    "\n",
    "predicted_params_array = np.array(predicted_params_list)\n",
    "predicted_key_rates = np.array(predicted_key_rates)\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot key rates comparison on the left\n",
    "ax1.plot(fiber_lengths, np.log10(optimized_key_rates), 'b-', label=\"Optimized Key Rate\")\n",
    "ax1.plot(fiber_lengths, np.log10(predicted_key_rates), 'r--', label=\"Predicted Key Rate (NN)\")\n",
    "ax1.set_title('Comparison of Key Rates')\n",
    "ax1.set_xlabel('Fiber Length (km)')\n",
    "ax1.set_ylabel('log10(Key Rate)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot parameters comparison on the right\n",
    "labels = ['mu_1', 'mu_2', 'P_mu_1', 'P_mu_2', 'P_X']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "for i in range(5):\n",
    "    ax2.plot(fiber_lengths, optimized_params_array[:, i], label=f'Optimized {labels[i]}', color=colors[i], linestyle='-')\n",
    "    ax2.plot(fiber_lengths, predicted_params_array[:, i], label=f'Predicted {labels[i]}', color=colors[i], linestyle='--')\n",
    "\n",
    "ax2.set_title('Comparison of Parameters')\n",
    "ax2.set_xlabel('Fiber Length (km)')\n",
    "ax2.set_ylabel('Parameter Values')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkd-training_set",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
